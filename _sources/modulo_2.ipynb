{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Módulo 2: Estructuración y manipulación de datos con Python**\n",
    "\n",
    "El manejo de datos es el corazón de cualquier proyecto de análisis, y Python se ha consolidado como uno de los lenguajes más poderosos y versátiles para este propósito. En este módulo, nos sumergiremos en las técnicas fundamentales para la estructuración y manipulación de datos utilizando Python, proporcionando las bases necesarias para transformar datos crudos en información útil y procesable.\n",
    "\n",
    "Comenzaremos explorando las estructuras de datos disponibles en Python, como listas, dataframes, pilas, colas, árboles y grafos. Estas estructuras permiten organizar y acceder a la información de manera eficiente, lo que es crucial cuando se trabaja con grandes volúmenes de datos o datos complejos. Además, abordaremos cómo manipular y transformar datos no estructurados, como textos, imágenes y datos provenientes de redes sociales, que requieren enfoques y herramientas específicas para su análisis.\n",
    "\n",
    "El módulo también se centrará en el uso de librerías especializadas como NumPy y Pandas, que son esenciales para el análisis de datos en Python. Estas librerías ofrecen potentes funciones para la manipulación y el análisis de datos estructurados, permitiendo realizar operaciones avanzadas con facilidad y eficiencia.\n",
    "\n",
    "Además, aprenderemos a trabajar con secuencias de datos utilizando herramientas como `re`, `string` e `itertools`, que son fundamentales para el procesamiento y análisis de cadenas de texto y otras secuencias de información. La habilidad para manipular secuencias es clave en tareas como la limpieza de datos y la preparación de datos para modelos de machine learning.\n",
    "\n",
    "Finalmente, exploraremos las bases de la visualización de datos para representar de manera gráfica los resultados del análisis, facilitando la interpretación y comunicación de los hallazgos. Este módulo también incluirá casos prácticos que permitirán a los participantes aplicar las técnicas aprendidas en escenarios reales, consolidando así los conceptos y habilidades adquiridos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Archivos planos con Numpy y Pandas**\n",
    "\n",
    "En esta sección aprenderás a importar datos a Python desde todo tipo de archivos planos, que son una forma sencilla y frecuente de almacenamiento de datos. Ya has aprendido a utilizar NumPy y Pandas: aprenderás a utilizar estos paquetes para importar archivos planos y personalizar tus importaciones.\n",
    "\n",
    "### **Archivos planos**\n",
    "\n",
    "Los archivos de texto plano se pueden clasificar en dos grandes tipos:\n",
    "\n",
    "1. **Archivos que contienen texto sin formato** . Por ejemplo:\n",
    "\n",
    "  ![no estructurado](_image/noestructurado.png)\n",
    "\n",
    "2.  **Archivos que contienen registros estructurados**. Un ejemplo es el conjunto de datos del Titanic \n",
    "\n",
    "  ![estructurado](_image/estructurado.png)\n",
    "\n",
    "  En este archivo, cada columna representa una característica o rasgo, como el género, la cabina o si la persona sobrevivió, mientras que cada fila corresponde a una persona que estaba a bordo del Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fundamental que cualquier científico de datos comprenda el concepto de **archivo plano**. Estos son archivos de texto simples que contienen datos organizados en tablas, pero sin relaciones estructuradas complejas.\n",
    "\n",
    "Es probable que hayas notado que la extensión del archivo es `.csv`. Tal vez te preguntes qué significa:\n",
    "\n",
    "* `.csv` (Comma-Separated Values): Archivo en el que los valores están separados por comas.\n",
    "* `.txt`: Archivo de texto simple.\n",
    "* `.tsv` (Tab-Separated Values): Archivo en el que los valores están separados por tabulaciones.\n",
    "\n",
    "Los valores en archivos planos pueden estar separados por diferentes caracteres, como comas o tabulaciones, conocidos como **delimitadores**. Estos delimitadores permiten organizar y estructurar los datos de manera sencilla y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para consultar cualquier archivo de texto sin formato, que debemos hacer:\n",
    "* Asignar el nombre del archivo a una variable como una cadena.\n",
    "* Usamos la función básica `open` de Python para abrir una conexión al archivo y le pasamos el argumento `mode='r'`, lo que garantiza que solo podamos leerlo.\n",
    "*  Despues le asignamos el texto del archivo a una variable `text` aplicando el método `read` a la conexión al archivo. \n",
    "* Después asegúrese de cerrar la conexión al archivo usando el comando `file.close`.\n",
    "\n",
    "Miremos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '_data/elprincipito.txt'\n",
    "file = open(filename, mode='r') # 'r' es de lectura\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el texto\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: attention\n",
    "\n",
    "- Para abrir un archivo en modo de escritura, debes usar `mode='w'`\n",
    "\n",
    "```python\n",
    "filename = '_data/escritura.txt'\n",
    "file = open(filename, mode='w')  # 'w' es para escritura\n",
    "\n",
    "\n",
    "# Escribir texto en el archivo\n",
    "file.write(\"Era un pequeño príncipe que vivía en un planeta apenas más grande que él.\")\n",
    "\n",
    "# Cerrar el archivo después de escribir\n",
    "file.close()\n",
    "```\n",
    "\n",
    "- Para verificar el contenido escrito en `escritura.txt`, primero debes abrir el archivo en modo de escritura como se muestra arriba. Luego, abre el archivo en modo de lectura para ver el contenido:\n",
    "\n",
    "```python\n",
    "# Abrir el archivo en modo lectura\n",
    "file = open(filename, mode='r')  # 'r' es para lectura\n",
    "\n",
    "# Leer el contenido del archivo\n",
    "content = file.read()\n",
    "\n",
    "# Imprimir el contenido\n",
    "print(content)\n",
    "\n",
    "# Cerrar el archivo después de leer\n",
    "file.close()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes evitar tener que cerrar la conexión al archivo utilizando una declaración `with`. Esto le permite crear un contexto en el que puede ejecutar comandos con el archivo abierto. Una vez fuera de esta cláusula o contexto, el archivo ya no está abierto y, por esta razón, `with` se denomina **administrador de contexto**. Realmente asegura que el archivo se cierre correctamente, incluso si ocurre un error durante la escritura. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_data/elprincipito.txt',mode ='r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1.  Abre el archivo de texto `GabrielGarciaMarquez.txt` e imprimelo. Utiliza el administrador de contexto `with`.\n",
    "2.  En el caso de archivos grandes, puede que no queramos imprimir todo su contenido en el shell: tal vez quieras imprimir sólo las primeras líneas. Use el archivo de texto `GabrielGarciaMarquez.txt` e imprima las 3 primeras líneas. **Sugerencia**: use el método `readline()`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de archivos planos con Numpy**\n",
    "\n",
    "Ahora que sabes cómo usar la función incorporada `open` de Python para abrir archivos de texto, veamos cómo importar un archivo plano y asignarlo a una variable. Si todos los datos son numéricos, puedes usar el paquete NumPy para importarlos como una matriz NumPy. ¿Por qué querríamos hacer esto?\n",
    "\n",
    ":::{admonition} **Características de las matrices NumPy**\n",
    ":class: note\n",
    "\n",
    "1. **Eficiencia y velocidad**:  \n",
    "   - Las matrices NumPy son el estándar de Python para almacenar datos numéricos debido a su eficiencia y rapidez.  \n",
    "   - Son ideales para manejar grandes volúmenes de datos de manera limpia y ordenada.\n",
    "\n",
    "   ```{figure} /_image/NumPy.png\n",
    "   :align: center\n",
    "   :name: Imagen de numpy\n",
    "   :scale: 10\n",
    "   ```\n",
    "   \n",
    "\n",
    "2.  **Compatibilidad con otros paquetes**:\n",
    "    - NumPy es esencial para muchos otros paquetes en Python, como `scikit-learn`, un popular paquete de aprendizaje automático.\n",
    "\n",
    "    ```{figure} /_image/scikitlearn.png\n",
    "    :align: center\n",
    "    :name: Imagen de ScikitLearn\n",
    "    :scale: 40\n",
    "    ```\n",
    "    \n",
    "    - Al trabajar con scikit-learn, es común que los datos estén en formato de matriz NumPy.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` tiene varias funciones integradas que nos permiten importar datos como matrices de forma mucho más sencilla y eficiente. Aquí se encuentran las funciones `loadtxt` y `genfromtxt`.\n",
    "\n",
    "1. **loadtxt**: Importa datos de un archivo de texto como una matriz NumPy. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "# mnist es una colección de dígitos manuscritos del 0 al 9\n",
    "\n",
    "filename = '_data/mnist.csv'\n",
    "dataset = np.loadtxt(filename,delimiter=',')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos argumentos adicionales de `loadtxt`\n",
    "\n",
    "* `skiprows`: Si deseas omitir la primera fila (por ejemplo, un encabezado), puedes usar `skiprows=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/babosa.txt', delimiter='\\t', skiprows=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `usecols`: Si solo quieres importar columnas específicas, usa `usecols` con una lista de los índices de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/50_Startups.csv', delimiter=',',usecols=[0,1,2,4], skiprows=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `dtype`: Te ayuda a importar diferentes tipos de datos en matrices. `dtype=str` garantiza que todas las entradas se importen como cadenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/50_Startups.csv', delimiter=',',dtype=str)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "Aunque `loadtxt` es útil para casos básicos. Si encuentra datos que no se pueden convertir al tipo especificado (por defecto, flotantes), generará un error, lo que puede detener el proceso de carga de datos.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **genfromtxt**: Similar a `loadtxt`, pero más flexible para manejar datos mixtos. Además, cuando usamos `dtype=None` permite que NumPy adivine el tipo de datos para cada columna. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('_data/mnist.csv', delimiter=',', dtype=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "Del archivo `digitos.txt`, que tiene la primera fila con los nombres de las variables y está delimitado por tabulaciones. Importe solo las 3 primeras columnas del archivo plano. Imprime la primera fila\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar archivos planos usando `NumPy`, puedes utilizar la función `numpy.savetxt()`. Esta función es muy útil para guardar datos en un archivo de texto con un formato específico. Aquí te muestro un ejemplo básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una matriz NumPy\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Guardar la matriz en un archivo de texto\n",
    "np.savetxt('_data/archivo.txt', data, fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve explicación de los parámetros es la siguiente:\n",
    "\n",
    "* `'archivo.txt'`: Nombre del archivo en el que se guardarán los datos.\n",
    "* `data`: La matriz `NumPy` que deseas guardar.\n",
    "* `fmt='%d'`: El formato en el que los datos se guardarán (en este caso, enteros). Puedes ajustar el formato según el tipo de datos que estás manejando (por ejemplo, %.2f para números de punto flotante con dos decimales).\n",
    "* `delimiter=','`: El delimitador que separa los valores en el archivo. Aquí se usa una coma, pero puedes cambiarlo a otro carácter como un espacio `' '` o un punto y coma `';'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres agregar un encabezado al archivo, puedes hacerlo con el parámetro `header`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('_data/archivo.csv', data, fmt='%d', \n",
    "           delimiter=',', header='Columna1,Columna2,Columna3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de archivos planos con Pandas**\n",
    "\n",
    "En la ciencia de datos, se requiere manejar *estructuras de datos etiquetadas bidimensionales con columnas de tipos potencialmente diferentes*, algo que las matrices `NumPy` no pueden satisfacer completamente. Esta necesidad impulsó a **Wes McKinney** a desarrollar la biblioteca `Pandas` para `Python`, que se ha convertido en una herramienta esencial para los científicos de datos.\n",
    "\n",
    "`Pandas` es una biblioteca de `Python` que permite llevar a cabo todo el flujo de trabajo de análisis de datos sin cambiar a otro lenguaje específico como `R`. La estructura de datos más relevante en `Pandas` es el DataFrame, que es el análogo Pythonic del marco de datos en `R`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Características claves de Pandas**\n",
    ":class: note\n",
    "\n",
    "- **Importación de datos**: `Pandas` facilita la importación de archivos planos, bases de datos, archivos Excel, entre otros, como DataFrames.\n",
    "\n",
    "- **Estructuras de datos etiquetadas**: Los DataFrames permiten manipular y analizar datos con etiquetas en filas y columnas, lo que facilita el manejo de diferentes tipos de datos en un solo lugar.\n",
    "\n",
    "- **Manipulación de datos**: `Pandas` ofrece funciones para cortar, remodelar, agrupar, unir y fusionar datos de manera eficiente.\n",
    "\n",
    "- **Estadísticas y manejo de valores faltantes**: Realiza cálculos estadísticos sin afectar los valores faltantes y proporciona herramientas para manejar series temporales.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importemos un archivo plano con `Pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importar un archivo CSV como DataFrame\n",
    "filename = '_data/winequality-red.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Ver las primeras 5 filas del DataFrame\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos convertir fácilmente el DataFrame en una matriz `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = data.to_numpy()\n",
    "data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "1. `Pandas` simplifica la manipulación y análisis de datos, permitiendo realizar operaciones complejas con un código conciso y legible.\n",
    "\n",
    "2. Es compatible con muchas fuentes de datos, lo que lo convierte en una herramienta versátil para diferentes flujos de trabajo.\n",
    "\n",
    "3. `Pandas` tiene una comunidad activa y una documentación extensa, lo que facilita el aprendizaje y la resolución de problemas. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para familiarizarte más con `Pandas`, es recomendable experimentar importando archivos planos que presenten desafíos, como comentarios incrustados y cadenas que deben interpretarse como valores faltantes. Esto te permitirá dominar las herramientas de limpieza y preparación de datos que ofrece Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Importe el dataset del `titanic.csv`, guardelo en el objeto `df` y muestre las 5 ultimas filas.\n",
    "2. Completa el código:\n",
    "\n",
    "```python\n",
    "# Asignar el nombre de archivo: file\n",
    "file = 'digitos.csv'\n",
    "\n",
    "# Leer las primeras 5 filas del archivo en un DataFrame: data\n",
    "# Use nrow y header\n",
    "# TU CODIGO\n",
    "\n",
    "# Construir un de numpy a partir del DataFrame: data_array\n",
    "# TU CODIGO\n",
    "\n",
    "# Imprimir el tipo de dato de data_array en la consola\n",
    "print(type(data_array))\n",
    "```\n",
    "\n",
    "3. Complete el código:\n",
    "\n",
    "```python\n",
    "# Asignar el nombre del archivo: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Importar el archivo: data\n",
    "data = pd.read_csv(file, sep=____, comment=____, na_values=____)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "donde\n",
    "* `sep=` es el delimitador que separa los campos en el archivo (en tu caso, debería ser `'\\t'` o `','`).\n",
    "* `comment=` especifica el carácter que indica el inicio de un comentario (en tu caso, debería ser `'#'` ).\n",
    "* `na_values=` define los valores que deben ser interpretados como valores faltantes (puedes usar `'NA', 0 'NaN' o 'Nothing').\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar archivos planos usando `pandas`, puedes utilizar la función `to_csv()` para guardar datos en formato CSV. Aquí te muestro cómo hacerlo para archivos CSV y otros formatos comunes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "data = {\n",
    "    'Columna1': [1, 4, 7],\n",
    "    'Columna2': [2, 5, 8],\n",
    "    'Columna3': [3, 6, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df.to_csv('_data/archivo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve explicación de los parámetros de `to_csv()`:\n",
    "\n",
    "* `'archivo.csv'`: Nombre del archivo CSV a generar.\n",
    "* `index=False`: Evita que se guarde la columna de índices del DataFrame en el archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar `to_csv()` con diferentes delimitadores para crear archivos de texto con otros formatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('_data/archivo.txt', sep='\\t', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importación e exportación de datos de otros tipos de archivos**\n",
    "\n",
    "Como científico de datos, es crucial saber cómo importar datos desde una variedad de tipos de archivo. En esta sección, exploraremos cómo importar datos en `Python` desde varios formatos importantes. Cubriremos:\n",
    "\n",
    "* **Archivos serializados (Pickle)**: Usados para almacenar datos de manera eficiente en `Python`. El concepto de serializados (Pickle)  un archivo está motivado por lo siguiente: si bien puede ser fácil guardar una matriz `numpy` o un `dataframe` de `pandas` en un archivo plano, hay muchos otros tipos de datos, como diccionarios y listas, para los cuales no es obvio cómo almacenarlos.\n",
    "* **Hojas de Cálculo Excel**: Permiten integrar datos de análisis de hojas de cálculo comunes.\n",
    "* **Archivos SAS y Stata**: Formatoss utilizados en software de estadística y análisis de datos.\n",
    "\n",
    "Aprenderás a manejar estos formatos para que puedas trabajar con una amplia gama de datos en tus proyectos de ciencia de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de datos serializados**\n",
    "\n",
    "Los **datos serializados** es el proceso de convertir los datos que han sido convertidos de su formato original (por ejemplo, un diccionario, una lista, un objeto de clase, etc.) a una secuencia de bytes. Este proceso se llama **serialización** o **marshalling**. La serialización permite que estos datos se almacenen en un archivo, se envíen a través de una red o se transmitan entre diferentes partes de un programa de manera eficiente. En `Python`, la serialización es manejada por el módulo `pickle`.\n",
    " \n",
    ":::{admonition} ¿Por qué serializar datos?\n",
    ":class: tip dropdown\n",
    "\n",
    "1. **Almacenamiento** : Puedes guardar un objeto complejo (como un diccionario o un árbol binario) en un archivo y cargarlo más tarde sin perder su estructura.\n",
    "\n",
    "2. **Comunicación entre procesos**: Los datos serializados pueden enviarse entre diferentes procesos de un programa o entre programas diferentes (por ejemplo, entre un cliente y un servidor en una aplicación web).\n",
    "\n",
    "3. **Persistencia de objetos**: Los datos serializados permiten almacenar el estado de un objeto, de modo que pueda ser restaurado más tarde y seguir funcionando donde se dejó.\n",
    "\n",
    ":::\n",
    "\n",
    "Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('_data/data_fruta.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Características de un archivo `.pkl`**:\n",
    "\n",
    "Algunas característica son:\n",
    "\n",
    "* Almacena una representación binaria de los objetos, lo que significa que el contenido del archivo no es legible por humanos. Solo se puede interpretar correctamente mediante deserialización utilizando `pickle` u otras herramientas compatibles con el formato.\n",
    "\n",
    "* Es ideal para guardar estructuras de datos complejas, como diccionarios, listas, o incluso objetos personalizados en Python. Estos datos pueden ser restaurados más tarde a su estado original, lo que permite la persistencia de información entre sesiones de programación.\n",
    "\n",
    "* Casi cualquier objeto de `Python` puede ser serializado a un archivo `.pkl`, incluyendo funciones y clases, lo que lo hace muy versátil.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, exportemos los datos a un archivo `.pkl` usando `pickle` en `Python`, que es útil para serializar objetos de Python (como listas, diccionarios, o DataFrames). Aquí te muestro cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto (por ejemplo, un diccionario)\n",
    "data = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "# Guardar el objeto en un archivo pickle\n",
    "with open('_data/archivo.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Consideraciones**\n",
    ":class: danger\n",
    "\n",
    "1 **No cargues archivos `pickle` de fuentes no confiables**, ya que pueden ejecutar código malicioso durante la deserialización.\n",
    "\n",
    "2. Archivos `pickle` son **específicos de `Python`**, por lo que no se pueden leer fácilmente en otros lenguajes de programación sin soporte para `pickle`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Complete el código:\n",
    "```python\n",
    "# Importar el paquete pickle \n",
    "# TU CÓDIGO\n",
    "\n",
    "# Abre el archivo pickle y carga los datos llamados data: d\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Imprime y el tipo de dato de d\n",
    "# TU CÓDIGO\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de datos en Excel**\n",
    "\n",
    "Las hojas de cálculo de Excel son una herramienta universalmente conocida y ampliamente utilizada, especialmente en el ámbito del análisis de datos. Un archivo de Excel generalmente contiene múltiples hojas de cálculo, cada una de las cuales puede almacenar diferentes conjuntos de datos relacionados o independientes. En el contexto de la ciencia de datos, el manejo eficiente de estos archivos es fundamental, y la biblioteca `pandas` de `Python` se destaca como una herramienta poderosa para este propósito.\n",
    "\n",
    "`Pandas` permite importar archivos de Excel de manera sencilla y convertir sus hojas de cálculo en DataFrames, que son estructuras de datos optimizadas para el análisis y la manipulación de datos. La conversión de las hojas de Excel a DataFrames facilita enormemente el trabajo con los datos, ya que pandas proporciona una amplia gama de funciones para exploración, transformación y análisis.\n",
    "\n",
    "Para comenzar, se puede utilizar la función `ExcelFile` de pandas para cargar un archivo de Excel en una variable, generalmente llamada data o algún nombre descriptivo. Este objeto `ExcelFile` actúa como un contenedor del archivo de Excel, permitiendo el acceso a sus diferentes hojas sin necesidad de cargarlas todas en la memoria al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1960-1966', '1967-1974', '1975-2011']\n"
     ]
    }
   ],
   "source": [
    "# Especifica el nombre del archivo de Excel\n",
    "file = '_data/urbanpop.xlsx' \n",
    "\n",
    "# Carga el archivo de Excel en un objeto ExcelFile\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    "# Imprime la lista de nombres de las hojas en el archivo\n",
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto indica que el archivo contiene tres hojas de cálculo, cada una correspondiente a un rango de años diferente.\n",
    "\n",
    "Una vez que conoces los nombres de las hojas, puedes cargar cualquier hoja en particular como un DataFrame para empezar a analizar los datos. Para hacer esto, utilizas el método `parse` del objeto `ExcelFile`. Este método acepta un argumento, que puede ser el nombre de la hoja como una cadena o su índice como un número entero (no como un `float`, ya que Python no acepta índices de hojas en forma de floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una hoja usando su nombre\n",
    "df1 = data.parse('1960-1966') \n",
    "\n",
    "# Cargar una hoja usando su índice (comienza en 0)\n",
    "df2 = data.parse(0)  \n",
    "\n",
    "# imprimir las primeras filas\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` es lo suficientemente inteligente para interpretar si le estás proporcionando un nombre de hoja o un índice, por lo que puedes utilizar cualquiera de los dos métodos según tu preferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_excel()` de `pandas` es una función muy útil y versátil para leer archivos de Excel directamente en un DataFrame. A diferencia de `ExcelFile` y `parse()`, que se usan en conjunto cuando necesitas trabajar con múltiples hojas de un archivo de Excel, `read_excel()` es una función de uso directo que simplifica la lectura de una o más hojas de cálculo.\n",
    "\n",
    ":::{admonition} ¿Cuándo usar `read_excel()`?\n",
    ":class: tip dropdown\n",
    "\n",
    "1. **Lectura directa de una hoja de Excel**: Si solo necesitas cargar una hoja específica de un archivo Excel sin necesidad de explorar todas las hojas primero, `read_excel()` es la mejor opción.\n",
    "\n",
    "2. **Lectura de múltiples hojas**: Puedes leer varias hojas al mismo tiempo especificando una lista de nombres o índices de hojas.\n",
    "\n",
    "3. **Simplicidad**: `read_excel()` es más directa y menos verbosa que el uso combinado de `ExcelFile` y `parse()`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos del uso de la función `read_excel()`\n",
    "\n",
    "1. **Leer una sola hoja de cálculo**: Si sabes el nombre de la hoja que necesitas, puedes leerla directamente en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee la hoja '1960–1966' del archivo Excel y la carga en un DataFrame\n",
    "df = pd.read_excel('urbanpop.xlsx', sheet_name='1960–1966')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si prefieres usar el índice de la hoja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee la primera hoja (índice 0) del archivo Excel\n",
    "df = pd.read_excel('urbanpop.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Leer múltiples hojas al mismo tiempo**: Si necesitas cargar varias hojas de un archivo de Excel, `read_excel()` puede hacerlo en una sola llamada y devolver un diccionario donde las llaves son los nombres de las hojas y los valores son los DataFrames correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee las hojas '1960–1966' y '1975–2011' del archivo Excel\n",
    "sheets = pd.read_excel('urbanpop.xlsx', sheet_name=['1960–1966', '1975–2011'])\n",
    "\n",
    "# Accede a cada DataFrame por el nombre de la hoja\n",
    "df1 = sheets['1960–1966']\n",
    "df2 = sheets['1975–2011']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Leer todas las hojas de un archivo de Excel**: Si quieres leer todas las hojas del archivo de Excel sin tener que especificar sus nombres, puedes hacerlo pasando `None` al argumento `sheet_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee todas las hojas del archivo Excel\n",
    "all_sheets = pd.read_excel('urbanpop.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_excel()` es ideal para situaciones en las que necesitas una solución rápida y directa para leer archivos de Excel en `Python`. Su simplicidad lo hace la primera opción para la mayoría de los casos de uso, mientras que `ExcelFile` y `parse()` ofrecen más flexibilidad para tareas más complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar datos a un archivo Excel usando pandas, puedes utilizar el método `to_excel()` del DataFrame. Aquí te muestro cómo hacerlo, con opciones para personalizar la exportación. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "data = {\n",
    "    'Columna1': [1, 4, 7],\n",
    "    'Columna2': [2, 5, 8],\n",
    "    'Columna3': [3, 6, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "df.to_excel('_data/archivo_nuevo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres exportar a múltiples hojas de un archivo excel, puedes guardar diferentes DataFrames en diferentes hojas del mismo archivo Excel usando un `ExcelWriter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('_data/archivo_multihojas.xlsx') as writer:\n",
    "    df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "    df2 = pd.DataFrame({'X': [5, 6], 'Y': [7, 8]})\n",
    "    \n",
    "    # Guardar DataFrames en hojas diferentes\n",
    "    df1.to_excel(writer, sheet_name='Hoja1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Hoja2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Complete el código:\n",
    "```python\n",
    "# Asigna el nombre del archivo de excel battledeath: file\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Cargar hoja de cálculo: xls\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Imprimir nombres de hojas\n",
    "# TU CÓDIGO\n",
    "```\n",
    "\n",
    "2. Usando el punto anterior: Complete\n",
    "\n",
    "```python\n",
    "# Cargar una hoja en un DataFrame por nombre: df1\n",
    "df1 = xls.parse(__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df1\n",
    "print(__TU CÓDIGO__)\n",
    "\n",
    "# Cargar una hoja en un DataFrame por índice: df2\n",
    "df2 = xls.parse(__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df2\n",
    "print(__TU CÓDIGO__)\n",
    "```\n",
    "\n",
    "3. Usando el punto anterior. Complete en código en python. Sugerencia: Los valores pasados a `skiprows` y names deben ser todos del tipo `list`\n",
    "\n",
    "```python\n",
    "# Analizar la primera hoja y renombrar las columnas: df1\n",
    "df1 = xls.parse(__TU CÓDIGO__, skiprows=__TU CÓDIGO__, names=__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Analizar la primera columna de la segunda hoja y renombrar la columna: df2\n",
    "df2 = xls.parse(__TU CÓDIGO__, usecols=__TU CÓDIGO__, skiprows=__TU CÓDIGO__, names=__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df2\n",
    "print(df2.head())\n",
    "\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación de archivos SAS y Stata usando Pandas**\n",
    "\n",
    "Hay una amplia variedad de paquetes de software estadístico disponibles, y aunque no siempre necesites utilizarlos, como científico de datos es fundamental que puedas importar archivos de estos paquetes a tu entorno Python de manera efectiva. Esta habilidad te permitirá integrar y analizar datos de diversas fuentes, ampliando tu capacidad para realizar análisis más completos y profundos.\n",
    "\n",
    "#### **Importación de archivos SAS**.\n",
    "\n",
    "**SAS**: Acrónimo de *Statistical Analysis System* (Sistema de Análisis Estadístico). Es un software popular en análisis de negocios y bioestadística. Los archivos SAS son formatos utilizados en el software SAS para realizar análisis avanzados, multivariados, inteligencia empresarial, gestión de datos, análisis predictivos y es un estándar para que los estadísticos realicen análisis computacionales. La extensión común es `.sas7bdat` que sirve para archivos de conjunto de datos.\n",
    "\n",
    "Miremos un ejemplo de la importación de estos archivos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de usar el paquete `sas7bdat`, se debe instalar con `pip install sas7bdat` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importa la clase SAS7BDAT del paquete sas7bdat\n",
    "from sas7bdat import SAS7BDAT \n",
    "\n",
    "# Abre el archivo SAS usando un administrador de contexto\n",
    "with SAS7BDAT('_data/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# imprimir\n",
    "print(df_sas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} ¿Por qué mportar archivos SAS:?\n",
    ":class: tip dropdown\n",
    "\n",
    "SAS es un estándar en la industria para el análisis estadístico, especialmente en sectores como la bioestadística y análisis de negocios, por lo que la habilidad de importar y manejar estos archivos en Python es esencial para científicos de datos.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exportar directamente a `.sas7bdat`, *tendrás que usar herramientas externas o software como SAS* . Alternativamente, podrías buscar librerías específicas para manejar archivos SAS en lugar de intentar escribir directamente en ese formato desde pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importación de Archivos Stata**.\n",
    "\n",
    "**Stata**: Un software de análisis estadístico y gestión de datos, especialmente valorado en investigación académica, incluyendo economía y epidemiología. Su área de uso es predominantemente utilizado en ciencias sociales y en investigación académica.\n",
    "\n",
    "Los archivos Stata tienen la extensión `.dta` y podemos importarlos usando `pandas`. ¡Ni siquiera necesitamos inicializar un administrador de contexto en este caso! Simplemente pasamos el nombre del archivo a la función `read_stata` y lo asignamos a una variable, tal como se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo Stata\n",
    "df_stata = pd.read_stata('_data/disarea.dta')\n",
    "df_stata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar archivos Stata (`.dta`) desde Python, puedes usar la biblioteca `pandas`, que tiene soporte nativo para leer y escribir archivos en formato Stata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "df = pd.DataFrame({\n",
    "    'columna1': [1, 2, 3],\n",
    "    'columna2': ['A', 'B', 'C']\n",
    "})\n",
    "\n",
    "# Especifica el nombre del archivo de salida\n",
    "archivo_stata = '_data/datos_exportados.dta'\n",
    "\n",
    "# Exporta el DataFrame a un archivo Stata (.dta)\n",
    "df.to_stata(archivo_stata, write_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método te permite exportar tus datos desde un DataFrame de `pandas` a un archivo Stata (`.dta`) de manera sencilla y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Instala el paquete `h5py` y completa el código\n",
    "\n",
    "```python\n",
    "# Importar paquetes de numpy y h5py\n",
    "# TU CODIGO\n",
    "\n",
    "# Asigna el nombre del archivo a la variable file y use L-L1_LOSC_4_V1-1126259446-32\n",
    "# TU CODIGO\n",
    "\n",
    "# Carga el archivo como sólo lectura en la variable data\n",
    "data = h5py.File(__# TU CODIGO__, __# TU CODIGO__)\n",
    "\n",
    "# Imprime el tipo de dato de data\n",
    "# TU CODIGO\n",
    "\n",
    "# Imprime los nombres o claves grpde los grupos en el archivo\n",
    "for key in __# TU CODIGO__:\n",
    "    print(__# TU CODIGO__)\n",
    "```\n",
    "\n",
    "2. Instale el paquete `sqlalchemy` y complete el siguiente código\n",
    "\n",
    "```python\n",
    "# Crea el engine\n",
    "# Importa la función create_engine, inspect del módulo sqlalchemy\n",
    "# TU CODIGO\n",
    "\n",
    "# un motor que se conecte a la base de datos SQLite\n",
    "engine = create_engine('sqlite:///_data/Chinook.sqlite')\n",
    "\n",
    "# Usa el Inspector para obtener los nombres de las tablas\n",
    "inspector = # TU CODIGO\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Imprime los nombres de las tablas\n",
    "# TU CODIGO\n",
    "```\n",
    "Despues, veamos cómo hacer cada uno de estos pasos para obtener un DataFrame\n",
    "\n",
    "```python\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Abre la conexión al engine\n",
    "with engine.connect() as con:\n",
    "    # Ejecutar la consulta usando text()\n",
    "    rs = con.execute(text('SELECT * FROM Album'))\n",
    "\n",
    "    # Convertir el resultado en un DataFrame de pandas\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "\n",
    "    # Asignar los nombres de las columnas\n",
    "    df.columns = rs.keys()\n",
    "\n",
    "# Mostrar el DataFrame\n",
    "print(df.head())\n",
    "```\n",
    "Conectarse a los datos de album es más facil con `pandas`:\n",
    "\n",
    "```python\n",
    "# Ejecutar la consulta y almacenar los registros en un DataFrame: df\n",
    "df = pd.read_sql_query('SELECT * FROM Album', engine)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación de ficheros planos desde la web**\n",
    "\n",
    "Ahora puedes importar datos en Python desde todo tipo de archivos planos como `.txt`, `.csv`, otros tipos de archivos como archivos `pickled`, hojas de cálculo de Excel y archivos SAS y Stata. También has adquirido una valiosa experiencia en la consulta de bases de datos relacionales para importar datos de ellas mediante SQL. Sin embargo, *todas estas habilidades implican la importación de datos de archivos que tiene localmente*. Sin embargo, estas habilidades usualmente implican trabajar con archivos locales. En muchos casos, como científico de datos, necesitarás **importar datos directamente desde la web**.\n",
    "\n",
    "Por ejemplo, supongamos que necesitas obtener el conjunto de datos de unas campañas de marketing directo (llamadas telefónicas) de una institución bancaria portuguesa desde el repositorio de GitHub de cdeoroaguado. Aunque puedes hacerlo manualmente usando un navegador, este método no es reproducible ni escalable. Es más eficiente y profesional utilizar código Python para automatizar la descarga e importación de estos datos.\n",
    "\n",
    "Para hacer el proceso de importación desde la Web debemos tener algunos conceptos claros.\n",
    "\n",
    "El paquete `urllib` en Python proporciona una interfaz de alto nivel para obtener datos de la World Wide Web. En particular, la función `urlopen` es similar a la función integrada `open`, pero acepta URLs en lugar de nombres de archivo.\n",
    "\n",
    ":::{admonition} **Características de `urllib`**\n",
    "\n",
    "`urllib` tiene algunas funciones inmersas. Algunas son:\n",
    "\n",
    "* **urlopen**: Abre una URL y devuelve un objeto similar a un archivo.\n",
    "* **urlretrieve**: Descarga archivos directamente desde una URL y los guarda localmente.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "* Es útil para tareas sencillas de importación de datos desde la web.\n",
    "* Para tareas más complejas, podrías considerar el uso de `requests` junto con `BeautifulSoup`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el paquete\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Importar pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Asignar la URL del archivo: url\n",
    "url ='https://raw.githubusercontent.com/cdeoroaguado/jbook_ml202430/main/data/bank/bank.csv'\n",
    "\n",
    "# Guardar el archivo localmente\n",
    "urlretrieve(url,'_data/bank.csv')\n",
    "\n",
    "# Leer el archivo en un DataFrame y mostrar sus primeras filas\n",
    "df = pd.read_csv('_data/bank.csv', sep=';')\n",
    "\n",
    "# Imprimir el encabezado del dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambíen, podias hacer la lectura de los datos, *sin descargalos*. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar la URL del archivo: url\n",
    "url ='https://raw.githubusercontent.com/cdeoroaguado/jbook_ml202430/main/data/bank/bank.csv'\n",
    "\n",
    "# leer el archivo en u dataframe:df\n",
    "df = pd.read_csv(url,sep=';')\n",
    "\n",
    "# Imprimir el encabezado del dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Manipulación de datos con pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librería `pandas` (cuyo nombre deriva de *panel data*, un término utilizado para describir conjuntos de datos estructurados y multidimensionales) ofrece potentes estructuras de datos y funciones de alto nivel que facilitan el trabajo con datos estructurados de manera eficiente y cómoda. Es una herramienta esencial en el análisis de datos, ampliamente utilizada por su versatilidad y funcionalidad.\n",
    "\n",
    "   ```{figure} /_image/pandas.png\n",
    "   :align: center\n",
    "   :name: Imagen de pandas\n",
    "   :scale: 50\n",
    "   ```\n",
    "\n",
    "Entre los principales objetos que proporciona pandas se encuentran el `DataFrame`, una estructura tabular bidimensional, la `Serie`, ambos construidos sobre arrays multidimensionales de `NumPy` y el `Panel`, que representa un cubo de datos tridimensional. Aunque `NumPy` es excelente para el almacenamiento eficiente de datos con su estructura `ndarray, presenta ciertas limitaciones en análisis más complejos. Estas limitaciones incluyen la falta de flexibilidad para aplicar etiquetas a los datos, gestionar valores faltantes, realizar agrupaciones, entre otros. Pandas supera estas barreras con sus estructuras de datos avanzadas, proporcionando una mayor flexibilidad y funcionalidad.\n",
    "\n",
    "Para más información, puedes consultar la [documentación oficial de pandas](https://pandas.pydata.org/), donde encontrarás recursos y ejemplos detallados para aprovechar al máximo esta poderosa librería.\n",
    "\n",
    "**Recordemos algunas cosas de `pandas`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para iniciar el proceso de creación, manipulación, entre otras debemos instalar el ia en el terminal. **Recuerde activar el ambiente**.\n",
    "\n",
    "![installpandas](_image/installpandas.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importemos la libreria `numpy` y `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, daremos los conceptos y ejemplos de una `series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Series**\n",
    "\n",
    "Las `series` son estructuras similares a los arrays unidimensionales que ya hemos visto, con la diferencia de que también son homogéneas. Esto significa que todos sus elementos deben ser del mismo tipo y que su tamaño es fijo, es decir, no se puede modificar una vez definido.\n",
    "\n",
    "Vamos a comenzar creando una serie a partir de una lista. Primero, necesitamos definir una lista con algunos datos. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de trabajos\n",
    "trabajos = [\"Ingeniero de Software\", \"Analista de Datos\",\n",
    "            \"Diseñador UX\", \"Gerente de Producto\",\n",
    "            \"Científico de datos\"]\n",
    "\n",
    "# Creamos un índice personalizado para estos trabajos\n",
    "indices = [\"Empresa1\", \"Empresa2\", \"Empresa3\", \n",
    "           \"Empresa4\",\"Empresa5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la serie en Pandas usando estos datos y con indices personalizados, utilizamos el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una serie con los trabajos\n",
    "serie = pd.Series(data=trabajos, dtype=\"string\")\n",
    "print(serie)\n",
    "\n",
    "# Creamos una serie con el índice personalizado\n",
    "serie = pd.Series(data=trabajos, index=indices, dtype=\"string\")\n",
    "print(serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a crear una serie a partir de un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un diccionario con trabajos y sus respectivos salarios\n",
    "diccionario = {\n",
    "    \"Ingeniero de Software\": 70000,\n",
    "    \"Analista de Datos\": 60000,\n",
    "    \"Diseñador UX\": 65000,\n",
    "    \"Gerente de Producto\": 80000,\n",
    "    \"Científico de datos\": 65000\n",
    "}\n",
    "\n",
    "# Creamos una serie a partir del diccionario\n",
    "serie_diccionario = pd.Series(diccionario)\n",
    "print(serie_diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para explorar algunos atributos de la `serie`, puedes usar los siguientes métodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño de nuestra serie\n",
    "print(serie_diccionario.size)\n",
    "\n",
    "# imprimir la lista de los nombres de las filas\n",
    "print(serie_diccionario.index)\n",
    "\n",
    "# imprimir el tipo de datos\n",
    "print(serie_diccionario.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder a los elementos de la `serie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accedemos a un elemento específico usando su índice\n",
    "print(serie_diccionario[\"Ingeniero de Software\"])  \n",
    "\n",
    "# Accedemos a un rango de valores\n",
    "print(serie_diccionario[0:3])  \n",
    "\n",
    "# Accedemos a múltiples elementos usando una lista de índices\n",
    "print(serie_diccionario[[\"Diseñador UX\", \"Analista de Datos\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes utilizar algunos métodos útiles para análisis, como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos métodos para obtener estadísticas de la serie\n",
    "print(serie_diccionario.count())  # Conteo de elementos no nulos\n",
    "print(serie_diccionario.sum())  # Suma de los valores\n",
    "print(serie_diccionario.cumsum())  # Valores acumulados\n",
    "print(serie_diccionario.value_counts())  # Conteo de valores repetidos\n",
    "print(serie_diccionario.min())  # Valor mínimo\n",
    "print(serie_diccionario.max())  # Valor máximo\n",
    "print(serie_diccionario.mean())  # Media de los valores\n",
    "print(serie_diccionario.std())  # Desviación estándar\n",
    "print(serie_diccionario.quantile(0.25))  # Cuantil 1 (25%)\n",
    "print(serie_diccionario.quantile(0.75))  # Cuantil 3 (75%)\n",
    "print(serie_diccionario.describe())  # Resumen descriptivo de la serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploraremos cómo aplicar operaciones matemáticas y funciones a series de datos relacionadas con bancos, así como buscar información mediante condiciones, ordenar series y eliminar datos nulos o desconocidos.\n",
    "\n",
    "1. **Operaciones Matemáticas Básicas**\n",
    "\n",
    "Primero, veremos cómo aplicar operaciones matemáticas a una serie que representa los saldos de las cuentas bancarias. A continuación, presentamos algunos ejemplos prácticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una serie con saldos de cuentas bancarias\n",
    "\n",
    "saldos = pd.Series([1500, 2000, 2500, 3000, 3500])\n",
    "\n",
    "# Aumentar en 100 cada saldo\n",
    "saldos = saldos + 100\n",
    "print(saldos)\n",
    "\n",
    "# Restar 200 a cada saldo\n",
    "saldos = saldos - 200\n",
    "print(saldos)\n",
    "\n",
    "# Multiplicar cada saldo por 1.05 (aplicando un aumento del 5%)\n",
    "saldos = saldos * 1.05\n",
    "print(saldos)\n",
    "\n",
    "# Dividir cada saldo por 2\n",
    "saldos = saldos / 2\n",
    "print(saldos)\n",
    "\n",
    "# Comprobar si los saldos son pares o impares\n",
    "print(saldos % 2)\n",
    "\n",
    "# Aplicar la función logaritmo a cada saldo\n",
    "print(saldos.apply(lambda x: np.log(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar funciones matemáticas a los saldos usando el método `apply`.Para ello debe importar el paquete `math`. Por ejemplo, para calcular el seno de cada saldo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Calcular el seno de los salarios\n",
    "print(saldos.apply(math.sin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Operaciones con Datos de Tipo String**\n",
    "\n",
    "Supongamos que tenemos una serie con nombres de bancos y queremos repetir cada nombre un número específico de veces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una serie con nombres de bancos\n",
    "bancos = pd.Series(['banco A', 'banco B', 'banco C'])\n",
    "\n",
    "# Repetir cada nombre 3 veces\n",
    "print(bancos.apply(lambda x: x * 3))\n",
    "\n",
    "# Capitalizar el nombre de cada banco\n",
    "print(bancos.str.title())\n",
    "\n",
    "# Convertir todos los caracteres a minúsculas\n",
    "print(bancos.str.lower())\n",
    "\n",
    "# Convertir todos los caracteres a mayúsculas\n",
    "print(print(bancos.str.upper()))\n",
    "\n",
    "# Eliminar espacios en blanco al principio y al final\n",
    "print(bancos.str.strip())\n",
    "\n",
    "# Eliminar espacios en blanco al principio\n",
    "print(bancos.str.lstrip())\n",
    "\n",
    "# Eliminar espacios en blanco al final\n",
    "print(bancos.str.rstrip())\n",
    "\n",
    "# Reemplazar 'Banco' por 'Entidad'\n",
    "print(bancos.str.replace('banco', 'entidad'))\n",
    "\n",
    "# Dividir cadenas en una lista de substrings por un delimitador\n",
    "print(bancos.str.split(' '))\n",
    "\n",
    "# Unir las cadenas en una sola con un delimitador\n",
    "print(bancos.str.join(', '))\n",
    "\n",
    "# Encontrar la posición de 'Banco' en cada cadena\n",
    "print(bancos.str.find('banco'))\n",
    "\n",
    "# Verificar si cada cadena contiene 'A'\n",
    "print(bancos.str.contains('A'))\n",
    "\n",
    "# Extraer los primeros 4 caracteres de cada cadena\n",
    "print(bancos.str[:4])\n",
    "\n",
    "# Contar el número de veces que aparece 'Banco'\n",
    "print(bancos.str.count('banco'))\n",
    "\n",
    "# Verificar si cada cadena comienza con 'banco'\n",
    "bancos.str.startswith('banco')\n",
    "\n",
    "# Verificar si cada cadena termina con 'A'\n",
    "bancos.str.endswith('A')\n",
    "\n",
    "# Reemplazar dígitos por 'X'\n",
    "bancos.str.replace(r'\\d+', 'X', regex=True)\n",
    "\n",
    "# Obtener la longitud de cada cadena\n",
    "bancos.str.len()\n",
    "\n",
    "# Eliminar caracteres no alfabéticos\n",
    "bancos.str.replace(r'[^a-zA-Z\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Filtrado de Datos**\n",
    "\n",
    "El objetivo es seleccionar saldos que cumplan una condición. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar saldos mayores o iguales a 3000\n",
    "print(saldos[saldos >= 3000])\n",
    "\n",
    "# Seleccionar saldos diferentes a 3000\n",
    "print(saldos[saldos != 3000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Ordenar series**\n",
    "\n",
    "Para ordenar los saldos de manera ascendente o descendente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar los saldos de manera ascendente\n",
    "print(saldos.sort_values(ascending=True))\n",
    "\n",
    "# Ordenar los saldos de manera descendente\n",
    "print(saldos.sort_values(ascending=False))\n",
    "\n",
    "# Ordenar por índices de manera ascendente\n",
    "print(saldos.sort_index(ascending=True))\n",
    "\n",
    "# Ordenar por índices de manera descendente\n",
    "print(saldos.sort_index(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Eliminación de Datos Nulos y Desconocidos**\n",
    "\n",
    "Finalmente, para eliminar datos nulos o desconocidos en la serie de saldos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear valores nulos en la serie de saldos\n",
    "saldos = pd.Series([1500, np.nan, 2500, None, 3500])\n",
    "\n",
    "# Eliminar valores nulos\n",
    "saldos_limpios = saldos.dropna()\n",
    "print(saldos_limpios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos ejemplos, has aprendido cómo realizar diversas operaciones con series relacionadas con datos bancarios en Pandas. En la próximo sección, exploraremos cómo trabajar con DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pandas**\n",
    "\n",
    "En este módulo, profundizaremos en la creación de `DataFrames`, una de las estructuras de datos más versátiles y poderosas para la manipulación de información financiera. Exploraremos tres métodos distintos para construir DataFrames, cada uno con aplicaciones específicas en la industria bancaria.\n",
    "\n",
    "Un `DataFrame` es una estructura bidimensional, similar a una tabla, que nos permite organizar y manipular datos con facilidad. En el contexto bancario, los DataFrames son ideales para manejar información de clientes, transacciones, productos financieros, y otros tipos de datos críticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método 1: Creación de DataFrames a partir de Diccionarios**\n",
    "\n",
    "En este primer enfoque, utilizaremos un diccionario para organizar los datos de clientes bancarios. Las claves del diccionario representarán las columnas del DataFrame, tales como `Nombre`, `Edad`, `Saldo`, y `Calificación_Crédito`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de la librería pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Definición de los datos mediante un diccionario\n",
    "clientes = {\n",
    "    'Nombre': ['José', 'Rodolfo', 'María', 'Julieta'],\n",
    "    'Edad': [45, 52, 34, 29],\n",
    "    'Saldo': [50000, 70000, 60000, 15000],\n",
    "    'Calificación_Crédito': [700, 750, 680, 720]\n",
    "}\n",
    "\n",
    "# Creación del DataFrame utilizando el diccionario\n",
    "df_clientes = pd.DataFrame(clientes)\n",
    "\n",
    "# Visualización del DataFrame\n",
    "print(df_clientes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este enfoque es eficiente cuando se tiene un conjunto de datos bien estructurado, con columnas predefinidas y valores coherentes. Es comúnmente utilizado en situaciones donde los datos provienen de sistemas bancarios estructurados, como bases de datos relacionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método 2: Creación de DataFrames a partir de Listas Anidadas**\n",
    "\n",
    "El siguiente método consiste en utilizar listas de listas para estructurar los datos. Este enfoque puede ser útil cuando los datos provienen de una fuente menos estructurada, como archivos CSV o entrada manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los datos mediante listas anidadas\n",
    "datos_clientes = [\n",
    "    ['José', 45, 50000, 700],\n",
    "    ['Rodolfo', 52, 70000, 750],\n",
    "    ['María', 34, 60000, 680],\n",
    "    ['Julieta', 29, 15000, 720]\n",
    "]\n",
    "\n",
    "# Definición de las columnas\n",
    "columnas = ['Nombre', 'Edad', 'Saldo', 'Calificación_Crédito']\n",
    "\n",
    "# Creación del DataFrame\n",
    "df_clientes_lista = pd.DataFrame(datos_clientes, columns=columnas)\n",
    "\n",
    "# Visualización del DataFrame\n",
    "print(df_clientes_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método es particularmente útil cuando los datos no están previamente etiquetados y requieren un procesamiento adicional para ser organizados en un formato tabular. Es frecuente en la integración de datos desde múltiples fuentes no homogéneas, como encuestas o registros de transacciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Método 3: Creación de DataFrames a partir de Listas de Diccionarios**\n",
    "\n",
    "Finalmente, exploraremos cómo crear un DataFrame a partir de una lista de diccionarios. Este método es flexible y permite manejar datos con campos opcionales o información incompleta, algo común en grandes bases de datos bancarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los datos mediante una lista de diccionarios\n",
    "clientes_dict = [\n",
    "    {'Nombre': 'José', 'Edad': 45, 'Saldo': 50000, 'Calificación_Crédito': 700},\n",
    "    {'Nombre': 'Rodolfo', 'Edad': 52, 'Saldo': 70000, 'Calificación_Crédito': 750},\n",
    "    {'Nombre': 'María', 'Edad': 34, 'Saldo': 60000},  # Falta calificación de crédito\n",
    "    {'Nombre': 'Julieta', 'Edad': 29, 'Calificación_Crédito': 720},  # Falta saldo\n",
    "    {'Edad': 28, 'Saldo': 30000}  # Faltan nombre y calificación de crédito\n",
    "]\n",
    "\n",
    "# Creación del DataFrame\n",
    "df_clientes_dict = pd.DataFrame(clientes_dict)\n",
    "\n",
    "# Visualización del DataFrame\n",
    "print(df_clientes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capacidad de manejar datos incompletos o parcialmente definidos es crucial en el análisis de datos bancarios, donde la información puede provenir de fuentes dispares y no siempre estará completa. Este método permite construir DataFrames robustos que pueden ser limpiados o completados en etapas posteriores del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "Algunas diferencias clave entre una Serie (`Series`) y un `DataFrame` en `Pandas`:\n",
    "\n",
    "1. **Dimensionalidad**:\n",
    "\n",
    "    * **Serie**: Es unidimensional, como una lista o columna única de datos.\n",
    "    * **DataFrame**: Es bidimensional, similar a una tabla con múltiples filas y columnas.\n",
    "\n",
    "2. **Estructura**:\n",
    "\n",
    "    * **Serie**: Contiene una sola columna de datos con un índice.\n",
    "    * **DataFrame**: Contiene múltiples columnas, cada una de las cuales es una Serie.\n",
    "\n",
    "3. **Uso**:\n",
    "\n",
    "    * **Serie**: Ideal para manejar una sola secuencia de datos.\n",
    "    * **DataFrame**: Ideal para trabajar con datos tabulares que tienen múltiples variables o características.\n",
    "\n",
    "4. **Etiquetas del Eje**:\n",
    "\n",
    "    * **Serie**: Tiene un único conjunto de etiquetas o índice asociado con los datos.\n",
    "    * **DataFrame**: Tiene dos ejes de etiquetas: uno para las filas (índice) y otro para las columnas.\n",
    "\n",
    "5. **Operaciones de Agregación**:\n",
    "\n",
    "    * **Serie**: Las operaciones de agregación, como la suma o el promedio, se aplican directamente a la secuencia de datos.\n",
    "    * **DataFrame**: Puedes aplicar operaciones de agregación a lo largo de filas o columnas, permitiendo un análisis más detallado y comparativo.\n",
    "    \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manipulación**\n",
    "\n",
    "La manipulación de datos con Pandas es una de las habilidades fundamentales en el análisis de datos. `Pandas` es una biblioteca de Python que proporciona estructuras de datos fáciles de usar, como Series y DataFrames, que permiten realizar operaciones y transformaciones complejas de manera sencilla y eficiente.\n",
    "\n",
    "#### **Introducción a la manipulación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora carguemos el conjunto de datos de **marketing del banco** `bank-full`. \n",
    "\n",
    "Los datos están relacionados con `campañas de marketing directo` (llamadas telefónicas) de una institución bancaria portuguesa.\n",
    "\n",
    "Este conjunto de datos tiene 4521 observaciones y 17 variables. Las variables son:\n",
    "\n",
    "* **age:** Edad del cliente.\n",
    "* **job**: Profesión del cliente (por ejemplo, desempleado, servicios, gestión).\n",
    "* **marital**: Estado civil del cliente (soltero, casado, divorciado).\n",
    "* **education**: Nivel educativo del cliente (primaria, secundaria, terciaria).\n",
    "* **default** : Indica si el cliente tiene crédito en incumplimiento (sí o no).\n",
    "* **balance**: Saldo promedio anual de la cuenta bancaria del cliente.\n",
    "* **housing**: Indica si el cliente tiene un préstamo hipotecario (sí o no).\n",
    "* **loan**: Indica si el cliente tiene un préstamo personal (sí o no).\n",
    "* **contact**: Tipo de comunicación de contacto (teléfono celular, teléfono fijo).\n",
    "* **day**: Día del mes en que se realizó el último contacto con el cliente.\n",
    "* **month**: Mes en que se realizó el último contacto con el cliente.\n",
    "* **duration**: Duración del último contacto en segundos.\n",
    "* **campaign**: Número de contactos realizados durante esta campaña de marketing.\n",
    "* **pdays**: Días que han pasado desde que el cliente fue contactado por última vez en una campaña anterior (valores -1 indican que el cliente no fue contactado previamente).\n",
    "* **previous**: Número de contactos realizados antes de esta campaña.\n",
    "* **poutcome**: Resultado de una campaña de marketing anterior (éxito, fracaso, desconocido).\n",
    "* **y**: Resultado de la campaña actual (si el cliente suscribió o no un depósito a plazo fijo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age           job   marital  education default  balance housing loan  \\\n",
      "0       58    management   married   tertiary      no     2143     yes   no   \n",
      "1       44    technician    single  secondary      no       29     yes   no   \n",
      "2       33  entrepreneur   married  secondary      no        2     yes  yes   \n",
      "3       47   blue-collar   married    unknown      no     1506     yes   no   \n",
      "4       33       unknown    single    unknown      no        1      no   no   \n",
      "45206   51    technician   married   tertiary      no      825      no   no   \n",
      "45207   71       retired  divorced    primary      no     1729      no   no   \n",
      "45208   72       retired   married  secondary      no     5715      no   no   \n",
      "45209   57   blue-collar   married  secondary      no      668      no   no   \n",
      "45210   37  entrepreneur   married  secondary      no     2971      no   no   \n",
      "\n",
      "         contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
      "0        unknown    5   may       261         1     -1         0  unknown   no  \n",
      "1        unknown    5   may       151         1     -1         0  unknown   no  \n",
      "2        unknown    5   may        76         1     -1         0  unknown   no  \n",
      "3        unknown    5   may        92         1     -1         0  unknown   no  \n",
      "4        unknown    5   may       198         1     -1         0  unknown   no  \n",
      "45206   cellular   17   nov       977         3     -1         0  unknown  yes  \n",
      "45207   cellular   17   nov       456         2     -1         0  unknown  yes  \n",
      "45208   cellular   17   nov      1127         5    184         3  success  yes  \n",
      "45209  telephone   17   nov       508         4     -1         0  unknown   no  \n",
      "45210   cellular   17   nov       361         2    188        11    other   no  \n",
      "   age           job   marital  education default  balance housing loan  \\\n",
      "0   58    management   married   tertiary      no     2143     yes   no   \n",
      "1   44    technician    single  secondary      no       29     yes   no   \n",
      "2   33  entrepreneur   married  secondary      no        2     yes  yes   \n",
      "3   47   blue-collar   married    unknown      no     1506     yes   no   \n",
      "4   33       unknown    single    unknown      no        1      no   no   \n",
      "5   51    technician   married   tertiary      no      825      no   no   \n",
      "6   71       retired  divorced    primary      no     1729      no   no   \n",
      "7   72       retired   married  secondary      no     5715      no   no   \n",
      "8   57   blue-collar   married  secondary      no      668      no   no   \n",
      "9   37  entrepreneur   married  secondary      no     2971      no   no   \n",
      "\n",
      "     contact  day month  duration  campaign  pdays  previous poutcome    y  \n",
      "0    unknown    5   may       261         1     -1         0  unknown   no  \n",
      "1    unknown    5   may       151         1     -1         0  unknown   no  \n",
      "2    unknown    5   may        76         1     -1         0  unknown   no  \n",
      "3    unknown    5   may        92         1     -1         0  unknown   no  \n",
      "4    unknown    5   may       198         1     -1         0  unknown   no  \n",
      "5   cellular   17   nov       977         3     -1         0  unknown  yes  \n",
      "6   cellular   17   nov       456         2     -1         0  unknown  yes  \n",
      "7   cellular   17   nov      1127         5    184         3  success  yes  \n",
      "8  telephone   17   nov       508         4     -1         0  unknown   no  \n",
      "9   cellular   17   nov       361         2    188        11    other   no  \n"
     ]
    }
   ],
   "source": [
    "# importar librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Asignar la URL del archivo: url\n",
    "url ='https://raw.githubusercontent.com/cdeoroaguado/jbook_ml202430/main/data/bank/bank-full.csv'\n",
    "\n",
    "# leer el archivo en u dataframe:df\n",
    "df = pd.read_csv(url,sep=';')\n",
    "\n",
    "# Imprimir el encabezado del dataframe\n",
    "df.head()\n",
    "\n",
    "# Mostrar las 5 ultimas filas de DataFrame\n",
    "df.tail()\n",
    "\n",
    "# Concatenar el encabezado y las últimas 5 filas del DataFrame\n",
    "result = pd.concat([df.head(), df.tail()])\n",
    "print(result)\n",
    "\n",
    "# Para ignorar el indice\n",
    "print(pd.concat([df.head(), df.tail()],ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dimensiones del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las dimensiones del DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Información de la estructura del dataset de marketing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener información sobre la estructura del DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo `df.size` en pandas devuelve el número total de elementos en un `DataFrame`. Esto se calcula multiplicando el número de filas por el número de columnas. Es útil para obtener una visión rápida del tamaño total del DataFrame en términos de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# número total de elementos en el dataframe\n",
    "df.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ocurrir que el conjunto de datos de marketing para la banca tenga duplicados. El método `drop_duplicates()` en pandas se utiliza para eliminar filas duplicadas de un DataFrame. Este método permite identificar y remover filas que contienen los mismos valores en las columnas seleccionadas, o en todas las columnas si no se especifica ninguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas duplicadas\n",
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "Si nuestro conjunto de datos de marketing en la banca contiene valores nulos, se utiliza el método `dropna()` o. Este método te permite eliminar filas o columnas que contengan valores nulos (NaN). A continuación te muestro cómo hacerlo:\n",
    "\n",
    "```python\n",
    "\n",
    "# Eliminar todas las filas que contengan al menos un valor nulo\n",
    "df_sin_nulos = df.dropna()\n",
    "\n",
    "# Eliminar filas que contengan al menos un valor nulo\n",
    "df_sin_nulos_filas = df.dropna(axis=0)\n",
    "\n",
    "# Eliminar columnas que contengan al menos un valor nulo\n",
    "df_sin_nulos_columnas = df.dropna(axis=1)\n",
    "\n",
    "# Mostrar los DataFrames sin valores nulos\n",
    "print(\"DataFrame sin valores nulos en filas:\")\n",
    "print(df_sin_nulos_filas)\n",
    "\n",
    "print(\"\\nDataFrame sin valores nulos en columnas:\")\n",
    "print(df_sin_nulos_columnas)\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Consideraciones**\n",
    ":class: danger\n",
    "El uso de `df.dropna()` puede resultar en la pérdida de datos importantes si una gran cantidad de valores nulos está presente. Antes de eliminar los valores nulos, considera las siguientes opciones:\n",
    "\n",
    "* **Imputar Valores Nulos**: Puedes reemplazar los valores nulos con valores específicos utilizando `df.fillna()`.\n",
    "* **Revisar el Impacto**: Evalúa cómo la eliminación de valores nulos afectará tu análisis y si es necesario ajustar tu enfoque para manejar los datos faltantes de manera más adecuada.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, el nombres de las variables, el indice, el tipo de dato del dataset de marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de las variables\n",
    "print(df.columns)\n",
    "\n",
    "# Obtener el índice del DataFrame\n",
    "print(df.index)\n",
    "\n",
    "# tipo de dato\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "1. Si quieres cambiar el nombre de las columnas o los indices. Usas `df.rename` de la siguiente forma\n",
    "```python\n",
    "df.rename(columns={},index={})\n",
    "```\n",
    "\n",
    "2. Para reindexar un dataframe debemos usar`df.reindex` y los selecciona:\n",
    "\n",
    "```python\n",
    "df.reindex(index = [],columns = [],fill_value='')\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos saber los clientes menores de 20 años:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las filas donde la condición es True\n",
    "df.loc[:,'age'] < 20\n",
    "\n",
    "# Mostrar los clientes menores de 20 años\n",
    "dfm20 = df[df.loc[:,'age'] < 20]\n",
    "\n",
    "# imprimir el dataframe las 5 primeras\n",
    "dfm20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escojamos las columnas `age`, `marital`, `balance`, `y` de los clientes menores de 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionemos las columnas\n",
    "new_dfm20 = dfm20[['age','marital','balance','y']]\n",
    "\n",
    "# imprimir\n",
    "print(new_dfm20.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "Para agregar y eliminar columnas o filas\n",
    "\n",
    "1. Puedes agregar una columna a un DataFrame en pandas usando una Serie (Series) de la siguiente manera:\n",
    "\n",
    "```python\n",
    "# Crear una Serie con los datos que quieres agregar como nueva columna\n",
    "nueva_columna = pd.Series([valor1, valor2, valor3, ...], index=df.index)\n",
    "\n",
    "# Agregar la Serie al DataFrame como una nueva columna\n",
    "df['nombre_nueva_columna'] = nueva_columna\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna\n",
    "print(df)\n",
    "```\n",
    "\n",
    "2. Para eliminar una, dos o más columnas de un DataFrame en pandas, puedes pasar una lista con los nombres de las columnas al método `drop()`. A continuación te muestro cómo hacerlo:\n",
    "\n",
    "```python\n",
    "# Crear una lista con los nombres de las columnas que quieres eliminar\n",
    "columnas_a_eliminar = ['nombre_columna1', 'nombre_columna2']\n",
    "\n",
    "# Eliminar las columnas especificadas en la lista\n",
    "df.drop(columnas_a_eliminar, axis=1, inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df)\n",
    "```\n",
    "\n",
    "3. Para agregar una nueva fila a un DataFrame en pandas, puedes seguir estos pasos generales:\n",
    "\n",
    "```python\n",
    "# Crear una nueva fila como un diccionario\n",
    "nueva_fila = {\n",
    "    'columna1': valor1,\n",
    "    'columna2': valor2,\n",
    "    'columna3': valor3,\n",
    "    # Agregar más columnas si es necesario\n",
    "}\n",
    "\n",
    "# Convertir la nueva fila en un DataFrame\n",
    "nueva_fila_df = pd.DataFrame([nueva_fila])\n",
    "\n",
    "# Agregar la nueva fila al DataFrame original\n",
    "df = df.append(nueva_fila_df, ignore_index=True)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df)\n",
    "```\n",
    "\n",
    "4. Para eliminar una fila de un DataFrame en pandas, puedes seguir estos pasos generales:\n",
    "\n",
    "```python\n",
    "# Identificar el índice de la fila que deseas eliminar\n",
    "indice_a_eliminar = 5 \n",
    "\n",
    "# Usar el método drop() para eliminar la fila\n",
    "df = df.drop(indice_a_eliminar, axis=0)\n",
    "\n",
    "# (Opcional) Resetear los índices si es necesario\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(df)\n",
    "\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para saber quien tiene mayor balance en la cuenta de los menores de 20, debo ordenarlo usando el método `sort_values`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordenar\n",
    "new_dfm20.sort_values(by='balance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes aplicar una función personalizada a una columna específica del DataFrame usando el método `apply()` de `pandas`. Supongamos que deseas crear una nueva columna llamada `balance_category` que clasifique el balance de cada cliente en `\"Bajo\"`, `\"Medio\"` o `\"Alto\"` según ciertos umbrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para categorizar el balance\n",
    "def categorizar_balance(balance):\n",
    "    if balance < 500:\n",
    "        return 'Bajo'\n",
    "    elif 500 <= balance < 1500:\n",
    "        return 'Medio'\n",
    "    else:\n",
    "        return 'Alto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función 'categorizar_balance' a la columna 'balance'\n",
    "# y crear la nueva columna 'balance_category'\n",
    "new_dfm20['balance_category'] = new_dfm20['balance'].apply(categorizar_balance)\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(new_dfm20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, debemos obtener los clientes menores de 20 que si se suscribieron. Ademas los que se suscribieron con balance bajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menores de 20 que se suscribieron\n",
    "new_dfm20[new_dfm20['y']=='yes']\n",
    "\n",
    "# Otra forma de seleccionarlos\n",
    "new_dfm20[new_dfm20[\"y\"].isin([\"yes\"])]\n",
    "\n",
    "# menores de 20 que se suscribieron con balance bajo\n",
    "new_dfm20[(new_dfm20['y']=='yes') & (new_dfm20['balance_category']=='Bajo')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Descripción estadística**\n",
    "\n",
    "Exploraremos cómo obtener estadísticas de resumen detalladas para columnas específicas de un DataFrame, así como cómo realizar análisis estadísticos avanzados mediante agrupaciones y tablas dinámicas. Comenzaremos con el cálculo de métricas descriptivas básicas, tales como medias, medianas, y desviaciones estándar, para evaluar la distribución y variabilidad de los datos. A continuación, abordaremos técnicas para aplicar estas estadísticas a subconjuntos de datos mediante agrupaciones, permitiendo un análisis más granular y enfocado. \n",
    "\n",
    "Finalmente, dominaremos el uso de tablas dinámicas para sintetizar, visualizar y resumir datos complejos, facilitando la extracción de insights clave y patrones significativos en grandes volúmenes de información. Este enfoque integral fortalecerá tu capacidad para extraer, interpretar y comunicar hallazgos estadísticos de manera efectiva en el análisis de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Resumen estadístico univariado**\n",
    "\n",
    "Calculemos las medidas descriptivas fundamentales, incluyendo la media, mediana, moda, varianza, desviación estándar y cuartiles, para proporcionar una visión general de la distribución de los datos. Usaremos el conjunto de datos.\n",
    "\n",
    "1. Si la variable es *numérica* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptivo de una sola variable numérica solo promedio\n",
    "print(df['age'].mean())\n",
    "              \n",
    "# Resumen descriptivo de una sola variable numérica\n",
    "print(df['age'].agg({\n",
    "    'Promedio': 'mean',                       # Media\n",
    "    'Desviacion_Estandar': 'std',             # Desv Estandar\n",
    "    'Minimo': 'min',                          # Mínimo\n",
    "    'Maximo': 'max',                          # Máximo\n",
    "    'Mediana': np.median,                      # Mediana\n",
    "    'Cuantil 1': lambda x: x.quantile(0.25),  # Cuantil 25%\n",
    "    'Cuantil 3': lambda x: x.quantile(0.75)   # Cuantil 75%\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptivo de una varias variable numérica solo promedio\n",
    "print(df[['age','balance']].mean())\n",
    "              \n",
    "# Resumen descriptivo de varias variable numérica\n",
    "result = pd.DataFrame({\n",
    "    'Promedio': df[['age', 'balance']].mean(),\n",
    "    'Desv. Estandar': df[['age', 'balance']].std(),\n",
    "    'minimo': df[['age', 'balance']].min(),\n",
    "    'maximo': df[['age', 'balance']].max(),\n",
    "    'mediana': df[['age', 'balance']].median(),\n",
    "    'Cuantil 1': df[['age', 'balance']].quantile(0.25),\n",
    "    'Cuantil 3': df[['age', 'balance']].quantile(0.75)\n",
    "})\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(result.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Si la variable es *catégorica* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptivo de una sola variable categórica solo conteo\n",
    "conteo = df['job'].value_counts()\n",
    "print(conteo)\n",
    "\n",
    "# Descriptivo de una sola variable categórica solo proporcion\n",
    "proporciones = df['job'].value_counts(normalize=True)\n",
    "print(proporciones)\n",
    "\n",
    "# Combinar los resultados en un solo DataFrame\n",
    "resultado = pd.DataFrame({\n",
    "    'Conteo': conteo,\n",
    "    'Proporción': proporciones\n",
    "})\n",
    "\n",
    "# imprimir\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptivo de varias variable categórica solo conteo\n",
    "conteo = df[['job','education']].value_counts()\n",
    "# print(conteo)\n",
    "\n",
    "# Descriptivo de varias variable categórica solo proporcion\n",
    "proporciones = df[['job','education']].value_counts(normalize=True)\n",
    "# print(proporciones)\n",
    "\n",
    "# Combinar los resultados en un solo DataFrame\n",
    "resultado = pd.DataFrame({\n",
    "    'Conteo': conteo,\n",
    "    'Proporción': proporciones\n",
    "})\n",
    "\n",
    "# imprimir\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Resumen estadístico bivariado**\n",
    "\n",
    "El resumen estadístico bivariado se refiere al estudio de dos variables simultáneamente para determinar si existe alguna relación o asociación entre ellas. Solo realizaremos las tablas para dicho análisis estadístico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Variable categórica vs variable numérica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Promedio  Desv Estandar  Minimo  Maximo  Mediana  Cuantil 1  Cuantil 3\n",
      "y                                                                           \n",
      "no   40.838986      10.172662      18      95     39.0       33.0       48.0\n",
      "yes  41.670070      13.497781      18      95     38.0       31.0       50.0\n"
     ]
    }
   ],
   "source": [
    "# descriptivo edad según la suscripcion solo una variable\n",
    "df.groupby('y')['age'].mean()\n",
    "\n",
    "var_num_cat = df.groupby('y')['age'].agg([\n",
    "    ('Promedio', 'mean'),                       # Media\n",
    "    ('Desv Estandar', 'std'),                         # Desviación estándar\n",
    "    ('Minimo', 'min'),                         # Mínimo\n",
    "    ('Maximo', 'max'),                         # Máximo\n",
    "    ('Mediana', 'median'),                   # Mediana\n",
    "    ('Cuantil 1', lambda x: x.quantile(0.25)),   # Cuantil 25%\n",
    "    ('Cuantil 3', lambda x: x.quantile(0.75))    # Cuantil 75%\n",
    "])\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(var_num_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptivo edad según la suscripcion varias variable\n",
    "df.groupby('y')[['age','balance']].mean()\n",
    "\n",
    "# Resumen descriptivo  de edad según la suscripcion solo una variable\n",
    "var_num_cat = df.groupby('y')[['age','balance']].agg([\n",
    "    'mean',                       # Media\n",
    "    'std',                        # Desviación estándar\n",
    "    'min',                        # Mínimo\n",
    "    'max',                        # Máximo\n",
    "    'median',                     # Mediana\n",
    "    lambda x: x.quantile(0.25),   # Cuantil 25%\n",
    "    lambda x: x.quantile(0.75)    # Cuantil 75%\n",
    "])\n",
    "\n",
    "# Renombrar las columnas resultantes\n",
    "var_num_cat.columns = [\n",
    "    'Edad_Promedio', 'Edad_Desviacion_Estandar', 'Edad_Minimo', 'Edad_Maximo', 'Edad_Mediana', 'Edad_Cuantil_1', 'Edad_Cuantil_3',\n",
    "    'Balance_Promedio', 'Balance_Desviacion_Estandar', 'Balance_Minimo', 'Balance_Maximo', 'Balance_Mediana', 'Balance_Cuantil_1', 'Balance_Cuantil_3'\n",
    "]\n",
    "\n",
    "# imprimir\n",
    "print(var_num_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Resumen estadístico con tablas dinámicas**\n",
    "\n",
    "Las tablas dinámicas son otras formas de calcular estadística de resumen agrupada. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# promedio de la edad según la suscripcion con pivot_table\n",
    "df.pivot_table(values='age',index='y')\n",
    "\n",
    "# descriptivo edad según la suscripcion con pivot_table\n",
    "\n",
    "df.pivot_table(values='age',index='y',aggfunc=['mean','std','min','max','median'])\n",
    "\n",
    "# Agreaar los cuantiles 1 y 3\n",
    "def q25(series):\n",
    "    return np.quantile(series, 0.25)\n",
    "\n",
    "def q75(series):\n",
    "    return np.quantile(series, 0.75)\n",
    "\n",
    "df.pivot_table(values='age',index='y',aggfunc=['mean','std','min','max','median',q25,q75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, usemos `pivot_table` para dos variables categóricas. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de edad de la variable educación vs empleo\n",
    "df.pivot_table(values = 'age',index='education', columns='job')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear una **tabla de contigencia**, basta con tener dos variables categóricas. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la tabla pivote con conteo de personas\n",
    "pivot_table = df.pivot_table(\n",
    "    index='education',\n",
    "    columns='job',\n",
    "    aggfunc='size'  # Conteo de entradas\n",
    ")\n",
    "print(pivot_table)\n",
    "\n",
    "# Otra forma de crear una tabla de contingencia\n",
    "crosstab = pd.crosstab(df['education'], df['job'], margins=True, margins_name='Total')\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Indices explicitos**\n",
    "\n",
    "En Python, los **índices** son utilizados para acceder a elementos en estructuras de datos como listas, tuplas, y matrices (arrays). Un índice explícito se refiere a la práctica de definir de manera específica el índice que se va a utilizar para acceder a un elemento, en lugar de depender de la indexación automática por la posición.\n",
    "\n",
    ":::{admonition} **Características de los Índices Explícitos**\n",
    ":class: note\n",
    "* **Flexibilidad**: Permiten el acceso a elementos específicos de una estructura de datos sin necesidad de recorrer secuencialmente todos los elementos.\n",
    "\n",
    "* **Claridad**: Facilitan la lectura y comprensión del código al hacer evidente qué elementos se están accediendo o modificando.\n",
    "\n",
    "* **Manipulación de Datos**: Hacen más sencillo realizar operaciones como reordenar elementos, filtrar,seleccionar, agrupar o acceder a subconjuntos de datos.\n",
    "\n",
    "* **Compatibilidad con Pandas**: En bibliotecas como pandas, los índices explícitos son fundamentales para trabajar con Series y DataFrames, permitiendo indexar tanto por números como por etiquetas.\n",
    "\n",
    "* **Precisión**: Al especificar el índice, reduces el riesgo de errores al manipular datos.\n",
    "\n",
    "* **Eficiencia**: Mejoran la eficiencia al permitir operaciones directas sobre los elementos deseados.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualicemos nuevamente el dataframe de marketing para la banca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# marco de datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos algunas funciones utiles de la indexación explicita:\n",
    "\n",
    "* `df.set_index()`; Este método se usa para establecer una o más columnas del DataFrame como su índice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>58</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>44</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneur</th>\n",
       "      <td>33</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue-collar</th>\n",
       "      <td>47</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>33</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>51</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>825</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>977</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>71</td>\n",
       "      <td>divorced</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1729</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>456</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>72</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>5715</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>1127</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>success</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue-collar</th>\n",
       "      <td>57</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>668</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>508</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneur</th>\n",
       "      <td>37</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2971</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>17</td>\n",
       "      <td>nov</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age   marital  education default  balance housing loan  \\\n",
       "job                                                                    \n",
       "management     58   married   tertiary      no     2143     yes   no   \n",
       "technician     44    single  secondary      no       29     yes   no   \n",
       "entrepreneur   33   married  secondary      no        2     yes  yes   \n",
       "blue-collar    47   married    unknown      no     1506     yes   no   \n",
       "unknown        33    single    unknown      no        1      no   no   \n",
       "...           ...       ...        ...     ...      ...     ...  ...   \n",
       "technician     51   married   tertiary      no      825      no   no   \n",
       "retired        71  divorced    primary      no     1729      no   no   \n",
       "retired        72   married  secondary      no     5715      no   no   \n",
       "blue-collar    57   married  secondary      no      668      no   no   \n",
       "entrepreneur   37   married  secondary      no     2971      no   no   \n",
       "\n",
       "                contact  day month  duration  campaign  pdays  previous  \\\n",
       "job                                                                       \n",
       "management      unknown    5   may       261         1     -1         0   \n",
       "technician      unknown    5   may       151         1     -1         0   \n",
       "entrepreneur    unknown    5   may        76         1     -1         0   \n",
       "blue-collar     unknown    5   may        92         1     -1         0   \n",
       "unknown         unknown    5   may       198         1     -1         0   \n",
       "...                 ...  ...   ...       ...       ...    ...       ...   \n",
       "technician     cellular   17   nov       977         3     -1         0   \n",
       "retired        cellular   17   nov       456         2     -1         0   \n",
       "retired        cellular   17   nov      1127         5    184         3   \n",
       "blue-collar   telephone   17   nov       508         4     -1         0   \n",
       "entrepreneur   cellular   17   nov       361         2    188        11   \n",
       "\n",
       "             poutcome    y  \n",
       "job                         \n",
       "management    unknown   no  \n",
       "technician    unknown   no  \n",
       "entrepreneur  unknown   no  \n",
       "blue-collar   unknown   no  \n",
       "unknown       unknown   no  \n",
       "...               ...  ...  \n",
       "technician    unknown  yes  \n",
       "retired       unknown  yes  \n",
       "retired       success  yes  \n",
       "blue-collar   unknown   no  \n",
       "entrepreneur    other   no  \n",
       "\n",
       "[45211 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establecer la columna 'job' como índice\n",
    "df.set_index('job')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df.reset_index()`:Este método se usa para restablecer el índice del DataFrame, devolviendo los índices actuales a columnas y creando un nuevo índice numérico predeterminado. Si usas el parámetro `drop=True` indica que se debe eliminar la columna de índice original en lugar de moverla a una columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `df.sort_index()`: Este método ordena las filas del DataFrame en función del índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, el uso de índices explícitos en Python es una técnica poderosa que permite un control detallado sobre la manipulación de datos. Ya sea en estructuras simples como listas o en análisis más complejos utilizando pandas, el conocimiento y uso adecuado de índices explícitos puede mejorar significativamente la eficiencia y claridad de tu código."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
