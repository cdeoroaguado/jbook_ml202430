{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Módulo 2: Estructuración y manipulación de datos con Python**\n",
    "\n",
    "El manejo de datos es el corazón de cualquier proyecto de análisis, y Python se ha consolidado como uno de los lenguajes más poderosos y versátiles para este propósito. En este módulo, nos sumergiremos en las técnicas fundamentales para la estructuración y manipulación de datos utilizando Python, proporcionando las bases necesarias para transformar datos crudos en información útil y procesable.\n",
    "\n",
    "Comenzaremos explorando las estructuras de datos disponibles en Python, como listas, dataframes, pilas, colas, árboles y grafos. Estas estructuras permiten organizar y acceder a la información de manera eficiente, lo que es crucial cuando se trabaja con grandes volúmenes de datos o datos complejos. Además, abordaremos cómo manipular y transformar datos no estructurados, como textos, imágenes y datos provenientes de redes sociales, que requieren enfoques y herramientas específicas para su análisis.\n",
    "\n",
    "El módulo también se centrará en el uso de librerías especializadas como NumPy y Pandas, que son esenciales para el análisis de datos en Python. Estas librerías ofrecen potentes funciones para la manipulación y el análisis de datos estructurados, permitiendo realizar operaciones avanzadas con facilidad y eficiencia.\n",
    "\n",
    "Además, aprenderemos a trabajar con secuencias de datos utilizando herramientas como `re`, `string` e `itertools`, que son fundamentales para el procesamiento y análisis de cadenas de texto y otras secuencias de información. La habilidad para manipular secuencias es clave en tareas como la limpieza de datos y la preparación de datos para modelos de machine learning.\n",
    "\n",
    "Finalmente, exploraremos las bases de la visualización de datos para representar de manera gráfica los resultados del análisis, facilitando la interpretación y comunicación de los hallazgos. Este módulo también incluirá casos prácticos que permitirán a los participantes aplicar las técnicas aprendidas en escenarios reales, consolidando así los conceptos y habilidades adquiridos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Archivos planos con Numpy y Pandas**\n",
    "\n",
    "En esta sección aprenderás a importar datos a Python desde todo tipo de archivos planos, que son una forma sencilla y frecuente de almacenamiento de datos. Ya has aprendido a utilizar NumPy y Pandas: aprenderás a utilizar estos paquetes para importar archivos planos y personalizar tus importaciones.\n",
    "\n",
    "### **Archivos planos**\n",
    "\n",
    "Los archivos de texto plano se pueden clasificar en dos grandes tipos:\n",
    "\n",
    "1. **Archivos que contienen texto sin formato** . Por ejemplo:\n",
    "\n",
    "  ![no estructurado](_image/noestructurado.png)\n",
    "\n",
    "2.  **Archivos que contienen registros estructurados**. Un ejemplo es el conjunto de datos del Titanic \n",
    "\n",
    "  ![estructurado](_image/estructurado.png)\n",
    "\n",
    "  En este archivo, cada columna representa una característica o rasgo, como el género, la cabina o si la persona sobrevivió, mientras que cada fila corresponde a una persona que estaba a bordo del Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es fundamental que cualquier científico de datos comprenda el concepto de **archivo plano**. Estos son archivos de texto simples que contienen datos organizados en tablas, pero sin relaciones estructuradas complejas.\n",
    "\n",
    "Es probable que hayas notado que la extensión del archivo es `.csv`. Tal vez te preguntes qué significa:\n",
    "\n",
    "* `.csv` (Comma-Separated Values): Archivo en el que los valores están separados por comas.\n",
    "* `.txt`: Archivo de texto simple.\n",
    "* `.tsv` (Tab-Separated Values): Archivo en el que los valores están separados por tabulaciones.\n",
    "\n",
    "Los valores en archivos planos pueden estar separados por diferentes caracteres, como comas o tabulaciones, conocidos como **delimitadores**. Estos delimitadores permiten organizar y estructurar los datos de manera sencilla y efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para consultar cualquier archivo de texto sin formato, que debemos hacer:\n",
    "* Asignar el nombre del archivo a una variable como una cadena.\n",
    "* Usamos la función básica `open` de Python para abrir una conexión al archivo y le pasamos el argumento `mode='r'`, lo que garantiza que solo podamos leerlo.\n",
    "*  Despues le asignamos el texto del archivo a una variable `text` aplicando el método `read` a la conexión al archivo. \n",
    "* Después asegúrese de cerrar la conexión al archivo usando el comando `file.close`.\n",
    "\n",
    "Miremos un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '_data/elprincipito.txt'\n",
    "file = open(filename, mode='r') # 'r' es de lectura\n",
    "text = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir el texto\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: attention\n",
    "\n",
    "- Para abrir un archivo en modo de escritura, debes usar `mode='w'`\n",
    "\n",
    "```python\n",
    "filename = '_data/escritura.txt'\n",
    "file = open(filename, mode='w')  # 'w' es para escritura\n",
    "\n",
    "\n",
    "# Escribir texto en el archivo\n",
    "file.write(\"Era un pequeño príncipe que vivía en un planeta apenas más grande que él.\")\n",
    "\n",
    "# Cerrar el archivo después de escribir\n",
    "file.close()\n",
    "```\n",
    "\n",
    "- Para verificar el contenido escrito en `escritura.txt`, primero debes abrir el archivo en modo de escritura como se muestra arriba. Luego, abre el archivo en modo de lectura para ver el contenido:\n",
    "\n",
    "```python\n",
    "# Abrir el archivo en modo lectura\n",
    "file = open(filename, mode='r')  # 'r' es para lectura\n",
    "\n",
    "# Leer el contenido del archivo\n",
    "content = file.read()\n",
    "\n",
    "# Imprimir el contenido\n",
    "print(content)\n",
    "\n",
    "# Cerrar el archivo después de leer\n",
    "file.close()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes evitar tener que cerrar la conexión al archivo utilizando una declaración `with`. Esto le permite crear un contexto en el que puede ejecutar comandos con el archivo abierto. Una vez fuera de esta cláusula o contexto, el archivo ya no está abierto y, por esta razón, `with` se denomina **administrador de contexto**. Realmente asegura que el archivo se cierre correctamente, incluso si ocurre un error durante la escritura. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_data/elprincipito.txt',mode ='r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1.  Abre el archivo de texto `GabrielGarciaMarquez.txt` e imprimelo. Utiliza el administrador de contexto `with`.\n",
    "2.  En el caso de archivos grandes, puede que no queramos imprimir todo su contenido en el shell: tal vez quieras imprimir sólo las primeras líneas. Use el archivo de texto `GabrielGarciaMarquez.txt` e imprima las 3 primeras líneas. **Sugerencia**: use el método `readline()`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de archivos planos con Numpy**\n",
    "\n",
    "Ahora que sabes cómo usar la función incorporada `open` de Python para abrir archivos de texto, veamos cómo importar un archivo plano y asignarlo a una variable. Si todos los datos son numéricos, puedes usar el paquete NumPy para importarlos como una matriz NumPy. ¿Por qué querríamos hacer esto?\n",
    "\n",
    ":::{admonition} **Características de las matrices NumPy**\n",
    ":class: note\n",
    "\n",
    "1. **Eficiencia y velocidad**:  \n",
    "   - Las matrices NumPy son el estándar de Python para almacenar datos numéricos debido a su eficiencia y rapidez.  \n",
    "   - Son ideales para manejar grandes volúmenes de datos de manera limpia y ordenada.\n",
    "\n",
    "   ```{figure} /_image/NumPy.png\n",
    "   :align: center\n",
    "   :name: Imagen de numpy\n",
    "   :scale: 10\n",
    "   ```\n",
    "   \n",
    "\n",
    "2.  **Compatibilidad con otros paquetes**:\n",
    "    - NumPy es esencial para muchos otros paquetes en Python, como `scikit-learn`, un popular paquete de aprendizaje automático.\n",
    "\n",
    "    ```{figure} /_image/scikitlearn.png\n",
    "    :align: center\n",
    "    :name: Imagen de ScikitLearn\n",
    "    :scale: 40\n",
    "    ```\n",
    "    \n",
    "    - Al trabajar con scikit-learn, es común que los datos estén en formato de matriz NumPy.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NumPy` tiene varias funciones integradas que nos permiten importar datos como matrices de forma mucho más sencilla y eficiente. Aquí se encuentran las funciones `loadtxt` y `genfromtxt`.\n",
    "\n",
    "1. **loadtxt**: Importa datos de un archivo de texto como una matriz NumPy. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# dataset\n",
    "# mnist es una colección de dígitos manuscritos del 0 al 9\n",
    "\n",
    "filename = '_data/mnist.csv'\n",
    "dataset = np.loadtxt(filename,delimiter=',')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos argumentos adicionales de `loadtxt`\n",
    "\n",
    "* `skiprows`: Si deseas omitir la primera fila (por ejemplo, un encabezado), puedes usar `skiprows=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/babosa.txt', delimiter='\\t', skiprows=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `usecols`: Si solo quieres importar columnas específicas, usa `usecols` con una lista de los índices de las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/50_Startups.csv', delimiter=',',usecols=[0,1,2,4], skiprows=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `dtype`: Te ayuda a importar diferentes tipos de datos en matrices. `dtype=str` garantiza que todas las entradas se importen como cadenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('_data/50_Startups.csv', delimiter=',',dtype=str)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "Aunque `loadtxt` es útil para casos básicos. Si encuentra datos que no se pueden convertir al tipo especificado (por defecto, flotantes), generará un error, lo que puede detener el proceso de carga de datos.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **genfromtxt**: Similar a `loadtxt`, pero más flexible para manejar datos mixtos. Además, cuando usamos `dtype=None` permite que NumPy adivine el tipo de datos para cada columna. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('_data/mnist.csv', delimiter=',', dtype=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "Del archivo `digitos.txt`, que tiene la primera fila con los nombres de las variables y está delimitado por tabulaciones. Importe solo las 3 primeras columnas del archivo plano. Imprime la primera fila\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ara exportar archivos planos usando `NumPy`, puedes utilizar la función `numpy.savetxt()`. Esta función es muy útil para guardar datos en un archivo de texto con un formato específico. Aquí te muestro un ejemplo básico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una matriz NumPy\n",
    "data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Guardar la matriz en un archivo de texto\n",
    "np.savetxt('_data/archivo.txt', data, fmt='%d', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve explicación de los parámetros es la siguiente:\n",
    "\n",
    "* `'archivo.txt'`: Nombre del archivo en el que se guardarán los datos.\n",
    "* `data`: La matriz `NumPy` que deseas guardar.\n",
    "* `fmt='%d'`: El formato en el que los datos se guardarán (en este caso, enteros). Puedes ajustar el formato según el tipo de datos que estás manejando (por ejemplo, %.2f para números de punto flotante con dos decimales).\n",
    "* `delimiter=','`: El delimitador que separa los valores en el archivo. Aquí se usa una coma, pero puedes cambiarlo a otro carácter como un espacio `' '` o un punto y coma `';'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres agregar un encabezado al archivo, puedes hacerlo con el parámetro `header`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('_data/archivo.csv', data, fmt='%d', \n",
    "           delimiter=',', header='Columna1,Columna2,Columna3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de archivos planos con Pandas**\n",
    "\n",
    "En la ciencia de datos, se requiere manejar *estructuras de datos etiquetadas bidimensionales con columnas de tipos potencialmente diferentes*, algo que las matrices `NumPy` no pueden satisfacer completamente. Esta necesidad impulsó a **Wes McKinney** a desarrollar la biblioteca `Pandas` para `Python`, que se ha convertido en una herramienta esencial para los científicos de datos.\n",
    "\n",
    "`Pandas` es una biblioteca de `Python` que permite llevar a cabo todo el flujo de trabajo de análisis de datos sin cambiar a otro lenguaje específico como `R`. La estructura de datos más relevante en `Pandas` es el DataFrame, que es el análogo Pythonic del marco de datos en `R`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Características claves de Pandas**\n",
    ":class: note\n",
    "\n",
    "- **Importación de datos**: `Pandas` facilita la importación de archivos planos, bases de datos, archivos Excel, entre otros, como DataFrames.\n",
    "\n",
    "- **Estructuras de datos etiquetadas**: Los DataFrames permiten manipular y analizar datos con etiquetas en filas y columnas, lo que facilita el manejo de diferentes tipos de datos en un solo lugar.\n",
    "\n",
    "- **Manipulación de datos**: `Pandas` ofrece funciones para cortar, remodelar, agrupar, unir y fusionar datos de manera eficiente.\n",
    "\n",
    "- **Estadísticas y manejo de valores faltantes**: Realiza cálculos estadísticos sin afectar los valores faltantes y proporciona herramientas para manejar series temporales.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importemos un archivo plano con `Pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importar un archivo CSV como DataFrame\n",
    "filename = '_data/winequality-red.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "# Ver las primeras 5 filas del DataFrame\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos convertir fácilmente el DataFrame en una matriz `numpy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = data.to_numpy()\n",
    "data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Observación**\n",
    ":class: warning\n",
    "\n",
    "1. `Pandas` simplifica la manipulación y análisis de datos, permitiendo realizar operaciones complejas con un código conciso y legible.\n",
    "\n",
    "2. Es compatible con muchas fuentes de datos, lo que lo convierte en una herramienta versátil para diferentes flujos de trabajo.\n",
    "\n",
    "3. `Pandas` tiene una comunidad activa y una documentación extensa, lo que facilita el aprendizaje y la resolución de problemas. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para familiarizarte más con `Pandas`, es recomendable experimentar importando archivos planos que presenten desafíos, como comentarios incrustados y cadenas que deben interpretarse como valores faltantes. Esto te permitirá dominar las herramientas de limpieza y preparación de datos que ofrece Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Importe el dataset del `titanic.csv`, guardelo en el objeto `df` y muestre las 5 ultimas filas.\n",
    "2. Completa el código:\n",
    "\n",
    "```python\n",
    "# Asignar el nombre de archivo: file\n",
    "file = 'digitos.csv'\n",
    "\n",
    "# Leer las primeras 5 filas del archivo en un DataFrame: data\n",
    "# Use nrow y header\n",
    "# TU CODIGO\n",
    "\n",
    "# Construir un de numpy a partir del DataFrame: data_array\n",
    "# TU CODIGO\n",
    "\n",
    "# Imprimir el tipo de dato de data_array en la consola\n",
    "print(type(data_array))\n",
    "```\n",
    "\n",
    "3. Complete el código:\n",
    "\n",
    "```python\n",
    "# Asignar el nombre del archivo: file\n",
    "file = 'titanic_corrupt.txt'\n",
    "\n",
    "# Importar el archivo: data\n",
    "data = pd.read_csv(file, sep=____, comment=____, na_values=____)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame\n",
    "print(data.head())\n",
    "```\n",
    "\n",
    "donde\n",
    "* `sep=` es el delimitador que separa los campos en el archivo (en tu caso, debería ser `'\\t'` o `','`).\n",
    "* `comment=` especifica el carácter que indica el inicio de un comentario (en tu caso, debería ser `'#'` ).\n",
    "* `na_values=` define los valores que deben ser interpretados como valores faltantes (puedes usar `'NA', 0 'NaN' o 'Nothing').\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar archivos planos usando `pandas`, puedes utilizar la función `to_csv()` para guardar datos en formato CSV. Aquí te muestro cómo hacerlo para archivos CSV y otros formatos comunes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "data = {\n",
    "    'Columna1': [1, 4, 7],\n",
    "    'Columna2': [2, 5, 8],\n",
    "    'Columna3': [3, 6, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "df.to_csv('_data/archivo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve explicación de los parámetros de `to_csv()`:\n",
    "\n",
    "* `'archivo.csv'`: Nombre del archivo CSV a generar.\n",
    "* `index=False`: Evita que se guarde la columna de índices del DataFrame en el archivo CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes usar `to_csv()` con diferentes delimitadores para crear archivos de texto con otros formatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('_data/archivo.txt', sep='\\t', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importar datos de otros tipos de archivos**\n",
    "\n",
    "Como científico de datos, es crucial saber cómo importar datos desde una variedad de tipos de archivo. En esta sección, exploraremos cómo importar datos en `Python` desde varios formatos importantes. Cubriremos:\n",
    "\n",
    "* **Archivos serializados (Pickle)**: Usados para almacenar datos de manera eficiente en `Python`. El concepto de serializados (Pickle)  un archivo está motivado por lo siguiente: si bien puede ser fácil guardar una matriz `numpy` o un `dataframe` de `pandas` en un archivo plano, hay muchos otros tipos de datos, como diccionarios y listas, para los cuales no es obvio cómo almacenarlos.\n",
    "* **Hojas de Cálculo Excel**: Permiten integrar datos de análisis de hojas de cálculo comunes.\n",
    "* **Archivos SAS y Stata**: Formatoss utilizados en software de estadística y análisis de datos.\n",
    "* **Archivos HDF5**: Diseñados para manejar grandes volúmenes de datos numéricos, ideales para almacenamiento y acceso eficiente.\n",
    "* **Archivos MATLAB**: Utilizados en entornos de `MATLAB` para almacenar datos y variables.\n",
    "\n",
    "\n",
    "Aprenderás a manejar estos formatos para que puedas trabajar con una amplia gama de datos en tus proyectos de ciencia de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de datos serializados**\n",
    "\n",
    "Los **datos serializados** es el proceso de convertir los datos que han sido convertidos de su formato original (por ejemplo, un diccionario, una lista, un objeto de clase, etc.) a una secuencia de bytes. Este proceso se llama **serialización** o **marshalling**. La serialización permite que estos datos se almacenen en un archivo, se envíen a través de una red o se transmitan entre diferentes partes de un programa de manera eficiente. En `Python`, la serialización es manejada por el módulo `pickle`.\n",
    " \n",
    ":::{admonition} ¿Por qué serializar datos?\n",
    ":class: tip dropdown\n",
    "\n",
    "1. **Almacenamiento** : Puedes guardar un objeto complejo (como un diccionario o un árbol binario) en un archivo y cargarlo más tarde sin perder su estructura.\n",
    "\n",
    "2. **Comunicación entre procesos**: Los datos serializados pueden enviarse entre diferentes procesos de un programa o entre programas diferentes (por ejemplo, entre un cliente y un servidor en una aplicación web).\n",
    "\n",
    "3. **Persistencia de objetos**: Los datos serializados permiten almacenar el estado de un objeto, de modo que pueda ser restaurado más tarde y seguir funcionando donde se dejó.\n",
    "\n",
    ":::\n",
    "\n",
    "Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('_data/data_fruta.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Características de un archivo `.pkl`**:\n",
    "\n",
    "Algunas característica son:\n",
    "\n",
    "* Almacena una representación binaria de los objetos, lo que significa que el contenido del archivo no es legible por humanos. Solo se puede interpretar correctamente mediante deserialización utilizando `pickle` u otras herramientas compatibles con el formato.\n",
    "\n",
    "* Es ideal para guardar estructuras de datos complejas, como diccionarios, listas, o incluso objetos personalizados en Python. Estos datos pueden ser restaurados más tarde a su estado original, lo que permite la persistencia de información entre sesiones de programación.\n",
    "\n",
    "* Casi cualquier objeto de `Python` puede ser serializado a un archivo `.pkl`, incluyendo funciones y clases, lo que lo hace muy versátil.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, exportemos los datos a un archivo `.pkl` usando `pickle` en `Python`, que es útil para serializar objetos de Python (como listas, diccionarios, o DataFrames). Aquí te muestro cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto (por ejemplo, un diccionario)\n",
    "data = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "# Guardar el objeto en un archivo pickle\n",
    "with open('_data/archivo.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Consideraciones**\n",
    ":class: danger\n",
    "\n",
    "1 **No cargues archivos `pickle` de fuentes no confiables**, ya que pueden ejecutar código malicioso durante la deserialización.\n",
    "\n",
    "2. Archivos `pickle` son **específicos de `Python`**, por lo que no se pueden leer fácilmente en otros lenguajes de programación sin soporte para `pickle`.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Complete el código:\n",
    "```python\n",
    "# Importar el paquete pickle \n",
    "# TU CÓDIGO\n",
    "\n",
    "# Abre el archivo pickle y carga los datos llamados data: d\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Imprime y el tipo de dato de d\n",
    "# TU CÓDIGO\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importación y exportación de datos en Excel**\n",
    "\n",
    "Las hojas de cálculo de Excel son una herramienta universalmente conocida y ampliamente utilizada, especialmente en el ámbito del análisis de datos. Un archivo de Excel generalmente contiene múltiples hojas de cálculo, cada una de las cuales puede almacenar diferentes conjuntos de datos relacionados o independientes. En el contexto de la ciencia de datos, el manejo eficiente de estos archivos es fundamental, y la biblioteca `pandas` de `Python` se destaca como una herramienta poderosa para este propósito.\n",
    "\n",
    "`Pandas` permite importar archivos de Excel de manera sencilla y convertir sus hojas de cálculo en DataFrames, que son estructuras de datos optimizadas para el análisis y la manipulación de datos. La conversión de las hojas de Excel a DataFrames facilita enormemente el trabajo con los datos, ya que pandas proporciona una amplia gama de funciones para exploración, transformación y análisis.\n",
    "\n",
    "Para comenzar, se puede utilizar la función `ExcelFile` de pandas para cargar un archivo de Excel en una variable, generalmente llamada data o algún nombre descriptivo. Este objeto `ExcelFile` actúa como un contenedor del archivo de Excel, permitiendo el acceso a sus diferentes hojas sin necesidad de cargarlas todas en la memoria al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1960-1966', '1967-1974', '1975-2011']\n"
     ]
    }
   ],
   "source": [
    "# Especifica el nombre del archivo de Excel\n",
    "file = '_data/urbanpop.xlsx' \n",
    "\n",
    "# Carga el archivo de Excel en un objeto ExcelFile\n",
    "data = pd.ExcelFile(file)\n",
    "\n",
    "# Imprime la lista de nombres de las hojas en el archivo\n",
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto indica que el archivo contiene tres hojas de cálculo, cada una correspondiente a un rango de años diferente.\n",
    "\n",
    "Una vez que conoces los nombres de las hojas, puedes cargar cualquier hoja en particular como un DataFrame para empezar a analizar los datos. Para hacer esto, utilizas el método `parse` del objeto `ExcelFile`. Este método acepta un argumento, que puede ser el nombre de la hoja como una cadena o su índice como un número entero (no como un `float`, ya que Python no acepta índices de hojas en forma de floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una hoja usando su nombre\n",
    "df1 = data.parse('1960-1966') \n",
    "\n",
    "# Cargar una hoja usando su índice (comienza en 0)\n",
    "df2 = data.parse(0)  \n",
    "\n",
    "# imprimir las primeras filas\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` es lo suficientemente inteligente para interpretar si le estás proporcionando un nombre de hoja o un índice, por lo que puedes utilizar cualquiera de los dos métodos según tu preferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_excel()` de `pandas` es una función muy útil y versátil para leer archivos de Excel directamente en un DataFrame. A diferencia de `ExcelFile` y `parse()`, que se usan en conjunto cuando necesitas trabajar con múltiples hojas de un archivo de Excel, `read_excel()` es una función de uso directo que simplifica la lectura de una o más hojas de cálculo.\n",
    "\n",
    ":::{admonition} ¿Cuándo usar `read_excel()`?\n",
    ":class: tip dropdown\n",
    "\n",
    "1. **Lectura directa de una hoja de Excel**: Si solo necesitas cargar una hoja específica de un archivo Excel sin necesidad de explorar todas las hojas primero, `read_excel()` es la mejor opción.\n",
    "\n",
    "2. **Lectura de múltiples hojas**: Puedes leer varias hojas al mismo tiempo especificando una lista de nombres o índices de hojas.\n",
    "\n",
    "3. **Simplicidad**: `read_excel()` es más directa y menos verbosa que el uso combinado de `ExcelFile` y `parse()`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos ejemplos del uso de la función `read_excel()`\n",
    "\n",
    "1. **Leer una sola hoja de cálculo**: Si sabes el nombre de la hoja que necesitas, puedes leerla directamente en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee la hoja '1960–1966' del archivo Excel y la carga en un DataFrame\n",
    "df = pd.read_excel('urbanpop.xlsx', sheet_name='1960–1966')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O si prefieres usar el índice de la hoja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee la primera hoja (índice 0) del archivo Excel\n",
    "df = pd.read_excel('urbanpop.xlsx', sheet_name=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Leer múltiples hojas al mismo tiempo**: Si necesitas cargar varias hojas de un archivo de Excel, `read_excel()` puede hacerlo en una sola llamada y devolver un diccionario donde las llaves son los nombres de las hojas y los valores son los DataFrames correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee las hojas '1960–1966' y '1975–2011' del archivo Excel\n",
    "sheets = pd.read_excel('urbanpop.xlsx', sheet_name=['1960–1966', '1975–2011'])\n",
    "\n",
    "# Accede a cada DataFrame por el nombre de la hoja\n",
    "df1 = sheets['1960–1966']\n",
    "df2 = sheets['1975–2011']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Leer todas las hojas de un archivo de Excel**: Si quieres leer todas las hojas del archivo de Excel sin tener que especificar sus nombres, puedes hacerlo pasando `None` al argumento `sheet_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee todas las hojas del archivo Excel\n",
    "all_sheets = pd.read_excel('urbanpop.xlsx', sheet_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_excel()` es ideal para situaciones en las que necesitas una solución rápida y directa para leer archivos de Excel en `Python`. Su simplicidad lo hace la primera opción para la mayoría de los casos de uso, mientras que `ExcelFile` y `parse()` ofrecen más flexibilidad para tareas más complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para exportar datos a un archivo Excel usando pandas, puedes utilizar el método `to_excel()` del DataFrame. Aquí te muestro cómo hacerlo, con opciones para personalizar la exportación. Por ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame\n",
    "data = {\n",
    "    'Columna1': [1, 4, 7],\n",
    "    'Columna2': [2, 5, 8],\n",
    "    'Columna3': [3, 6, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "df.to_excel('_data/archivo_nuevo.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres exportar a múltiples hojas de un archivo excel, puedes guardar diferentes DataFrames en diferentes hojas del mismo archivo Excel usando un `ExcelWriter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('_data/archivo_multihojas.xlsx') as writer:\n",
    "    df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "    df2 = pd.DataFrame({'X': [5, 6], 'Y': [7, 8]})\n",
    "    \n",
    "    # Guardar DataFrames en hojas diferentes\n",
    "    df1.to_excel(writer, sheet_name='Hoja1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Hoja2', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{admonition} **Ejercicios**\n",
    ":class: tip\n",
    "\n",
    "1. Complete el código:\n",
    "```python\n",
    "# Asigna el nombre del archivo de excel battledeath: file\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Cargar hoja de cálculo: xls\n",
    "# TU CÓDIGO\n",
    "\n",
    "# Imprimir nombres de hojas\n",
    "# TU CÓDIGO\n",
    "```\n",
    "\n",
    "2. Usando el punto anterior: Complete\n",
    "\n",
    "```python\n",
    "# Cargar una hoja en un DataFrame por nombre: df1\n",
    "df1 = xls.parse(__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df1\n",
    "print(__TU CÓDIGO__)\n",
    "\n",
    "# Cargar una hoja en un DataFrame por índice: df2\n",
    "df2 = xls.parse(__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df2\n",
    "print(__TU CÓDIGO__)\n",
    "```\n",
    "\n",
    "3. Usando el punto anterior. Complete en código en python. Sugerencia: Los valores pasados a `skiprows` y names deben ser todos del tipo `list`\n",
    "\n",
    "```python\n",
    "# Analizar la primera hoja y renombrar las columnas: df1\n",
    "df1 = xls.parse(__TU CÓDIGO__, skiprows=__TU CÓDIGO__, names=__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Analizar la primera columna de la segunda hoja y renombrar la columna: df2\n",
    "df2 = xls.parse(__TU CÓDIGO__, usecols=__TU CÓDIGO__, skiprows=__TU CÓDIGO__, names=__TU CÓDIGO__)\n",
    "\n",
    "# Imprimir las primeras filas del DataFrame df2\n",
    "print(df2.head())\n",
    "\n",
    "```\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
