{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Módulo 4: Visualización de datos con Python**\n",
    "\n",
    "En este módulo, exploraremos la visualización de datos, una herramienta esencial para transformar grandes volúmenes de información en representaciones visuales claras y útiles para la toma de decisiones. A través de gráficos y visualizaciones, podremos identificar patrones, tendencias y relaciones en los datos, facilitando la comunicación y el análisis.\n",
    "\n",
    "Comenzaremos con un enfoque fundamental: el **tratamiento de datos faltantes y atípicos**. Aprenderemos a identificar y manejar estos problemas comunes que pueden afectar la calidad y precisión de nuestras visualizaciones. Un manejo adecuado de estos datos es crucial para asegurar que nuestras representaciones visuales sean confiables y significativas.\n",
    "\n",
    "A continuación, entraremos en la **introducción a la visualización de datos con Python**, donde exploraremos bibliotecas populares como Matplotlib y Seaborn, que permiten crear visualizaciones estáticas poderosas. Posteriormente, avanzaremos hacia la **visualización interactiva**, que nos permitirá desarrollar gráficos dinámicos y personalizables, mejorando la interacción y el análisis de datos.\n",
    "\n",
    "Seguiremos con la **visualización de datos a través de capas**, una biblioteca que ofrece una forma intuitiva de crear gráficos complejos mediante una sintaxis declarativa. Este enfoque facilita la combinación y superposición de diferentes tipos de visualizaciones para obtener una comprensión más profunda de los datos.\n",
    "\n",
    "También profundizaremos en la **visualización interactiva de datos geográficos**, una habilidad clave para realizar análisis espaciales y desarrollar soluciones que consideren la ubicación geográfica.\n",
    "\n",
    "Finalmente, introduciremos **Streamlit**, una herramienta potente y de fácil uso para crear aplicaciones web interactivas centradas en la visualización de datos. Con Streamlit, aprenderás a transformar scripts de Python en aplicaciones web completamente funcionales, permitiéndote combinar todas las técnicas de visualización vistas en el módulo en una interfaz interactiva y accesible para el usuario final.\n",
    "\n",
    "Al completar este módulo, contarás con un conjunto sólido de habilidades para crear visualizaciones de datos desde cero, manejar datos atípicos y faltantes, y desarrollar aplicaciones visuales interactivas que sean impactantes y útiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tratamiento de datos faltantes y atípicos**\n",
    "\n",
    "### **Introducción**\n",
    "En esta sección se enumeran y explican los posibles errores que pueden surgir durante diversas etapas del proceso de visualización de datos, tales como **la representación de elementos no correlacionados** para sugerir una relación o **la incorporación de características interactivas inadecuadas**.\n",
    "\n",
    "Aunque el proceso de visualización de datos puede parecer sencillo **tomar algunos datos, trazar gráficos y añadir funciones interactivas** en realidad es fácil cometer errores en diferentes fases del mismo. Estos errores pueden resultar en visualizaciones defectuosas que no logran comunicar de manera clara y eficaz la información contenida en los datos, lo que las convierte en herramientas inútiles para el público al que van dirigidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tratamiento de valores faltantes**\n",
    "\n",
    "* Los datos perdidos son, como su nombre indica, valores que están en blanco (**NaN**, -, **0** cuando no deberían ser **0**, etc.). Al igual que los valores atípicos, los valores perdidos pueden ser problemáticos tanto en el caso de las visualizaciones como en el de los modelos predictivos.\n",
    "\n",
    "* Los valores faltantes en las visualizaciones pueden mostrar una tendencia que en realidad no existe o no representa una relación entre dos variables que, en realidad, es significativa. Aunque es posible crear visualizaciones con un conjunto de datos que contenga valores perdidos, no se recomienda hacerlo. Al hacerlo, se ignoran los casos en los que se encuentran esos valores perdidos, creando así una visualización basada en algunos de los datos pero no en todos.\n",
    "\n",
    "* Por lo tanto, el tratamiento de los valores perdidos es de suma importancia. Existen dos enfoques principales para tratar los valores perdidos: **la supresión y la imputación**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos contiene información relacionada con los **empleos de profesionales de datos**, recopilada durante varios años. Cada fila representa un empleo único y proporciona detalles sobre el puesto, nivel de experiencia, modalidad de trabajo, ubicación del empleado, y otros factores relevantes para el contexto laboral y el salario recibido. Este conjunto de datos es útil para analizar tendencias en el mercado laboral de la ciencia de datos, permitiendo comparaciones entre diferentes tipos de empleos, niveles de experiencia, y ubicaciones geográficas.\n",
    "\n",
    "**Descripción de las columnas**\n",
    "\n",
    "| **Columna**               | **Descripción**                                                                                   | **Tipo de dato** |\n",
    "|---------------------------|---------------------------------------------------------------------------------------------------|------------------|\n",
    "| **Working_Year**           | Año en que se obtuvieron los datos sobre el empleo. Esto puede ser útil para observar tendencias a lo largo del tiempo. | Float            |\n",
    "| **Designation**            | Título del puesto del profesional de datos. Ejemplos comunes incluyen \"Data Scientist\", \"Data Engineer\", etc. | Cadena           |\n",
    "| **Experience**             | Nivel de experiencia del empleado en el puesto, categorizado como \"Medio\", \"Senior\", etc. Esto ayuda a segmentar los trabajos según la experiencia necesaria. | Cadena           |\n",
    "| **Employment_Status**      | Tipo de contrato laboral bajo el cual se emplea a la persona. Puede ser a tiempo completo (\"FT\"), medio tiempo (\"PT\"), entre otros. Es un indicador de la estabilidad y dedicación del empleo. | Cadena           |\n",
    "| **Employee_Location**      | País donde se encuentra ubicado el empleado. Esto puede influir en el salario y las condiciones laborales, dada la variación entre mercados internacionales. | Cadena           |\n",
    "| **Company_Size**           | Tamaño de la empresa en la que trabaja el profesional de datos. Las empresas se clasifican en \"S\" (Pequeña), \"M\" (Mediana), o \"L\" (Grande), y esto puede influir en las oportunidades de crecimiento, ambiente de trabajo, y remuneración. | Cadena           |\n",
    "| **Remote_Working_Ratio**   | Porcentaje de tiempo que el empleado trabaja de manera remota. Un valor del 100% indicaría que el empleo es completamente remoto, mientras que un valor del 0% indicaría un empleo presencial. | Entero           |\n",
    "| **Salary_USD**             | Salario anual del empleado expresado en dólares estadounidenses (USD). Este valor es útil para hacer comparaciones salariales entre empleos de diferentes ubicaciones y niveles de experiencia. | Float            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo CSV proporcionado\n",
    "file_path = '_data/dataviz/ds_salaries.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 607 entries, 0 to 606\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Working_Year          595 non-null    float64\n",
      " 1   Designation           600 non-null    object \n",
      " 2   Experience            607 non-null    object \n",
      " 3   Employment_Status     607 non-null    object \n",
      " 4   Employee_Location     607 non-null    object \n",
      " 5   Company_Size          607 non-null    object \n",
      " 6   Remote_Working_Ratio  607 non-null    int64  \n",
      " 7   Salary_USD            597 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 38.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Informacion del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores Faltantes</th>\n",
       "      <th>Porcentaje Faltante (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Working_Year</th>\n",
       "      <td>12</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Designation</th>\n",
       "      <td>7</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employee_Location</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remote_Working_Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary_USD</th>\n",
       "      <td>10</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Valores Faltantes  Porcentaje Faltante (%)\n",
       "Working_Year                         12                     1.98\n",
       "Designation                           7                     1.15\n",
       "Experience                            0                     0.00\n",
       "Employment_Status                     0                     0.00\n",
       "Employee_Location                     0                     0.00\n",
       "Company_Size                          0                     0.00\n",
       "Remote_Working_Ratio                  0                     0.00\n",
       "Salary_USD                           10                     1.65"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copia del dataset\n",
    "df_va = df.copy()\n",
    "\n",
    "# Revisar los datos faltantes en el conjunto de datos\n",
    "missing_values = df_va .isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores faltantes\n",
    "missing_percentage = (df_va .isnull().mean() * 100).round(2)\n",
    "\n",
    "# Crear un DataFrame con el análisis de datos faltantes\n",
    "missing_data = pd.DataFrame({\n",
    "    'Valores Faltantes': missing_values,\n",
    "    'Porcentaje Faltante (%)': missing_percentage\n",
    "})\n",
    "\n",
    "missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas de tratar los datos faltantes. Como modo de ejemplo, se explicaran los procesos de cada uno.\n",
    "\n",
    "#### **Eliminación de datos faltantes** \n",
    "\n",
    "La estrategia **eliminar valores faltantes** implica quitar aquellas filas de tu conjunto de datos que contienen valores faltantes (`NaN`). Sin embargo, para evitar eliminar demasiados datos y reducir significativamente el tamaño del conjunto de datos, esta estrategia se aplica solo cuando los valores faltantes constituyen un pequeño porcentaje del total, en este caso, el **5% o menos**.\n",
    "\n",
    "* **5% o menos del total de valores**: Si la cantidad de valores faltantes en una columna o fila representa el 5% o menos del total de registros, es una pérdida aceptable de información. Por lo tanto, puedes eliminar esas filas o columnas sin comprometer demasiado la integridad del análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloquemos un umbral\n",
    "umbral = len(df_va) * 0.05\n",
    "\n",
    "# Selecciona columnas con valores faltantes <= umbral\n",
    "cols_to_drop = df_va .columns[df_va .isna().sum() <= umbral]\n",
    "\n",
    "# Elimina filas con valores faltantes en las columnas seleccionadas\n",
    "df_va.dropna(subset=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 0 to 606\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Working_Year          578 non-null    float64\n",
      " 1   Designation           578 non-null    object \n",
      " 2   Experience            578 non-null    object \n",
      " 3   Employment_Status     578 non-null    object \n",
      " 4   Employee_Location     578 non-null    object \n",
      " 5   Company_Size          578 non-null    object \n",
      " 6   Remote_Working_Ratio  578 non-null    int64  \n",
      " 7   Salary_USD            578 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 40.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# informacion del dataset ajustado\n",
    "df_va .info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores Faltantes</th>\n",
       "      <th>Porcentaje Faltante (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Working_Year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Designation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employee_Location</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remote_Working_Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary_USD</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Valores Faltantes  Porcentaje Faltante (%)\n",
       "Working_Year                          0                      0.0\n",
       "Designation                           0                      0.0\n",
       "Experience                            0                      0.0\n",
       "Employment_Status                     0                      0.0\n",
       "Employee_Location                     0                      0.0\n",
       "Company_Size                          0                      0.0\n",
       "Remote_Working_Ratio                  0                      0.0\n",
       "Salary_USD                            0                      0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisar los datos faltantes en el conjunto de datos\n",
    "missing_values = df_va.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores faltantes\n",
    "missing_percentage = (df_va.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Crear un DataFrame con el análisis de datos faltantes\n",
    "missing_data = pd.DataFrame({\n",
    "    'Valores Faltantes': missing_values,\n",
    "    'Porcentaje Faltante (%)': missing_percentage\n",
    "})\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma para eliminar los datos faltantes es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copia del dataset\n",
    "df_2 = df.copy()\n",
    "\n",
    "# eliminar las filas con Nans\n",
    "df_2_new = df_2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 578 entries, 0 to 606\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Working_Year          578 non-null    float64\n",
      " 1   Designation           578 non-null    object \n",
      " 2   Experience            578 non-null    object \n",
      " 3   Employment_Status     578 non-null    object \n",
      " 4   Employee_Location     578 non-null    object \n",
      " 5   Company_Size          578 non-null    object \n",
      " 6   Remote_Working_Ratio  578 non-null    int64  \n",
      " 7   Salary_USD            578 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 40.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_2_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valores Faltantes</th>\n",
       "      <th>Porcentaje Faltante (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Working_Year</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Designation</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experience</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employment_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Employee_Location</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company_Size</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remote_Working_Ratio</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary_USD</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Valores Faltantes  Porcentaje Faltante (%)\n",
       "Working_Year                          0                      0.0\n",
       "Designation                           0                      0.0\n",
       "Experience                            0                      0.0\n",
       "Employment_Status                     0                      0.0\n",
       "Employee_Location                     0                      0.0\n",
       "Company_Size                          0                      0.0\n",
       "Remote_Working_Ratio                  0                      0.0\n",
       "Salary_USD                            0                      0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisar los datos faltantes en el conjunto de datos\n",
    "missing_values = df_2_new.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores faltantes\n",
    "missing_percentage = (df_2_new.isnull().mean() * 100).round(2)\n",
    "\n",
    "# Crear un DataFrame con el análisis de datos faltantes\n",
    "missing_data = pd.DataFrame({\n",
    "    'Valores Faltantes': missing_values,\n",
    "    'Porcentaje Faltante (%)': missing_percentage\n",
    "})\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una diferencia muy importante entre ambos método; el **primer enfoque es más flexible y te permite manejar datos faltantes de manera más controlada**, mientras que el segundo es **más directo y elimina todas las filas que tengan valores faltantes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Imputación de datos faltantes**\n",
    "\n",
    "##### **Datos categóricos**\n",
    "Para los datos categóricos (como \"País\", \"Categoría\", \"Género\", etc.), los métodos comunes de imputación incluyen:\n",
    "- **Moda**: Imputar los valores faltantes con la categoría que más se repite. Este enfoque es simple y suele ser efectivo cuando los datos tienen una categoría predominante.\n",
    "- **Asignación aleatoria**: Reemplazar los valores faltantes con una categoría seleccionada al azar entre los valores no faltantes de la misma variable, preservando la distribución original de las categorías.\n",
    "- **Imputación basada en subgrupos**: Imputar los valores faltantes basándose en subgrupos definidos por otras variables, asegurando que la categoría imputada sea coherente con los datos restantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Usando la **moda**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset\n",
    "df_3 = df.copy()\n",
    "\n",
    "# Iterar sobre cada columna del DataFrame\n",
    "for col in df_3.columns:\n",
    "    # Comprobar si la columna es de tipo objeto (categórica)\n",
    "    if df_3[col].dtypes == 'object':\n",
    "        # Imputar los valores faltantes con la moda (categoría más frecuente)\n",
    "        df_3[col].fillna(df_3[col].value_counts().index[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usando **Asignación aleatoria**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset\n",
    "df_4 = df.copy()\n",
    "\n",
    "# Iterar sobre cada columna de df_4\n",
    "for col in df_4.columns:\n",
    "    # Comprobar si la columna es de tipo objeto (categórica)\n",
    "    if df_4[col].dtypes == 'object':\n",
    "        # Obtener las categorías no faltantes de la columna\n",
    "        categorias_no_nan = df_4[col].dropna().unique()\n",
    "        # Reemplazar valores faltantes con una categoría seleccionada aleatoriamente\n",
    "        df_4[col] = df_4[col].apply(lambda x: np.random.choice(categorias_no_nan) if pd.isna(x) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Usando **imputación basada en grupos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset\n",
    "df_5 = df.copy()\n",
    "\n",
    "# Definir la columna por la cual agrupar (por ejemplo, \"Experience\")\n",
    "grupo_col = 'Experience'\n",
    "\n",
    "# Iterar sobre cada columna de df_4\n",
    "for col in df_5.columns:\n",
    "    # Comprobar si la columna es de tipo objeto (categórica) y no es la columna por la cual agrupamos\n",
    "    if df_5[col].dtypes == 'object' and col != grupo_col:\n",
    "        # Agrupar por la columna definida (en este caso 'Experience') e imputar valores faltantes\n",
    "        df_5[col] = df_5.groupby(grupo_col)[col].transform(\n",
    "            lambda x: x.fillna(np.random.choice(x.dropna().unique())) if x.isna().sum() > 0 else x\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### **Datos numéricos**\n",
    "Para los datos numéricos (como \"Edad\", \"Salario\", \"Ingreso\", etc.), los métodos comunes de imputación incluyen:\n",
    "- **Media**: Reemplazar los valores faltantes con la media de la columna. Este método es útil cuando los datos tienen una distribución simétrica y no hay valores atípicos.\n",
    "- **Mediana**: Utilizar la mediana para imputar, lo cual es más robusto frente a valores atípicos o distribuciones asimétricas.\n",
    "- **Imputación por métodos de machine learning**: Estimar el valor faltante utilizando una regresión basada en otras variables del conjunto de datos. Este método es más avanzado y puede ser más preciso, pero requiere un modelo de regresión adecuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar la imputación de datos con la media o la mediana, se debe conocer la distribución de los datos sin los vacios. Con lo anterior podemos ver si tiene comportamiento normal o no. De la distribución depende si imputar con el promedio o la mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Usando **la media o el promedio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset\n",
    "df_6 = df.copy()\n",
    "\n",
    "# Imputar los valores perdidos con imputación de medias\n",
    "df_6.fillna(df_6.select_dtypes(include=np.number).mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usando **la mediana**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia del dataset\n",
    "df_7 = df.copy()\n",
    "\n",
    "# Imputar los valores perdidos con imputación de medias\n",
    "df_7.fillna(df_7.select_dtypes(include=np.number).median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra manera adecuada de imputar valores ausentes es mediante la clase `SimpleImputer` de `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Data Scientist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Imputar los valores faltantes\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_8 \u001b[38;5;241m=\u001b[39m \u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Mostrar el DataFrame después de la imputación\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_8)\n",
      "File \u001b[1;32mc:\\Users\\cdeor\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\cdeor\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\cdeor\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cdeor\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\impute\\_base.py:366\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cdeor\\miniconda3\\envs\\ml_venv\\lib\\site-packages\\sklearn\\impute\\_base.py:327\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    322\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    325\u001b[0m         )\n\u001b[0;32m    326\u001b[0m     )\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'Data Scientist'"
     ]
    }
   ],
   "source": [
    "# Libreria\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Copia del dataset\n",
    "df_8 = df.copy()\n",
    "\n",
    "# Crear la instancia para imputar con la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Imputar los valores faltantes\n",
    "df_8 = imputer.fit_transform(df_8)\n",
    "\n",
    "# Mostrar el DataFrame después de la imputación\n",
    "print(df_8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
