

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Módulo 6: Machine Learning &#8212; Ciencia de datos aplicada a la banca</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'modulo_6';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modulo 7: Despliegue de modelos" href="modulo_7.html" />
    <link rel="prev" title="Modulo 5: Introducción a Streamlit" href="modulo_5.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Ciencia de datos aplicada a la banca
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="modulo_1.html"><strong>Módulo 1: Introducción a la ciencia de datos con Python</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="modulo_2.html"><strong>Módulo 2: Estructuración y manipulación de datos con Python</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="modulo_3.html"><strong>Modulo 3: Análisis exploratorio de datos de la banca</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="modulo_4.html"><strong>Módulo 4: Visualización de datos con Python</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="modulo_5.html"><strong>Modulo 5: Introducción a Streamlit</strong></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Módulo 6: Machine Learning</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="modulo_7.html"><strong>Modulo 7: Despliegue de modelos</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fmodulo_6.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/modulo_6.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Módulo 6: Machine Learning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arthur-samuel-pionero-del-aprendizaje-automatico-y-la-inteligencia-artificial"><strong>Arthur Samuel: Pionero del Aprendizaje Automático y la Inteligencia Artificial</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste"><strong>Generalización, sobreajuste y subajuste</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion"><strong>Regresión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-regresion"><strong>Tipos de regresión</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-lineal"><strong>Modelo de regresión lineal</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-simple"><strong>Regresión lineal simple</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#importemos-las-librerias">1. <strong>Importemos las librerias</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#carguemos-los-datos">2. <strong>Carguemos los datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#eda">3. <strong>EDA</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#datos-faltantes-o-nans">4. <strong>Datos faltantes o NANs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos">5. <strong>Visualización de datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo">6. <strong>Construcción del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-conjunto-de-entrenamiento-y-prueba">7. <strong>Visualización del conjunto de entrenamiento y prueba</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-del-modelo-de-regresion"><strong>Métricas de evaluacion del modelo de regresión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-medio-mse-mean-squared-error">1. <strong>Error Cuadrático Medio (<span class="math notranslate nohighlight">\(MSE\)</span> - Mean Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-mse"><strong>Interpretación de MSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mse"><strong>Conclusiones de MSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-absoluto-medio-mae-mean-absolute-error">2. <strong>Error Absoluto Medio (<span class="math notranslate nohighlight">\(MAE\)</span> - Mean Absolute Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-mae"><strong>Interpretación de MAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mae"><strong>Conclusiones de MAE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#raiz-del-error-cuadratico-medio-rmse-root-mean-squared-error">3. <strong>Raíz del Error Cuadrático Medio (<span class="math notranslate nohighlight">\(RMSE\)</span> - Root Mean Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rmse"><strong>Interpretación de RMSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rmse"><strong>Conclusiones de RMSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rmse"><strong>Resumen de RMSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coeficiente-de-determinacion-r-2-r-squared">4. <strong>Coeficiente de Determinación (<span class="math notranslate nohighlight">\(R^2\)</span> - <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-r-2"><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-r-2"><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-si-es-necesario-de-r-2"><strong>Posibles acciones para mejorar (si es necesario) de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-r-2"><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#r-2-ajustado-adjusted-r-squared">5. <strong><span class="math notranslate nohighlight">\(R^2\)</span> Ajustado (Adjusted <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-r-2-ajustado"><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-r-2-ajustado"><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-r-2-ajustado"><strong>Posibles acciones para mejorar <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-r-2-ajustado"><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-medio-proporcional-absoluto-mape-mean-absolute-percentage-error">6. <strong>Error Medio Proporcional Absoluto (<span class="math notranslate nohighlight">\(MAPE\)</span> - Mean Absolute Percentage Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-del-mape"><strong>Interpretación del MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mape"><strong>Conclusiones de MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-si-es-necesario-de-mape"><strong>Posibles acciones para mejorar (si es necesario) de MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-mape"><strong>Resumen de MAPE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-medio-de-logaritmo-msle-mean-squared-logarithmic-error">7. <strong>Error Cuadrático Medio de Logaritmo (<span class="math notranslate nohighlight">\(MSLE\)</span> - Mean Squared Logarithmic Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-msle"><strong>Interpretación de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-msle"><strong>Conclusiones de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-msle"><strong>Posibles acciones para mejorar de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-msle"><strong>Resumen de MSLE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-relativo-absoluto-rae-relative-absolute-error">8. <strong>Error Relativo Absoluto (<span class="math notranslate nohighlight">\(RAE\)</span> - Relative Absolute Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rae"><strong>Interpretación de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rae"><strong>Conclusiones de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-rae"><strong>Posibles acciones para mejorar de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rae"><strong>Resumen de RAE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-relativo-rse-relative-squared-error">9. <strong>Error Cuadrático Relativo (<span class="math notranslate nohighlight">\(RSE\)</span> - Relative Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rse"><strong>Interpretación de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rse"><strong>Conclusiones de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-rse"><strong>Posibles acciones para mejorar de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rse"><strong>Resumen de RSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-con-la-libreria-statsmodels"><strong>Regresión Lineal con la librería Statsmodels</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#formas-de-entrenar-un-modelo-de-regresion-en-statsmodels"><strong>Formas de entrenar un modelo de regresión en Statsmodels</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resultados-de-la-regresion-lineal-ols"><strong>Resultados de la Regresión Lineal (OLS)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-con-scikit-learn"><strong>Comparación con Scikit-learn</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-multiple"><strong>Regresión lineal multiple</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-las-librerias-necesarias">1. <strong>Importar las librerías necesarias</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-los-datos">2. <strong>Lectura de los datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3. <strong>Datos faltantes o NANs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-estadistico">4. <strong>Resumen estadístico.</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-conjunto-de-datos">5. <strong>Visualización del conjunto de datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#correlaciones">6. <strong>Correlaciones</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-regresion">7. <strong>Construcción del modelo de regresión</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-ridge"><strong>Regresión Ridge</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-rigde"><strong>Construcción del modelo Rigde</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lasso"><strong>Regresión Lasso</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-lasso"><strong>Construcción del modelo Lasso</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-por-k-vecinos"><strong>Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-knn-regression"><strong>¿Cómo funciona KNN Regression?</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#consideraciones-al-usar-knn-regression"><strong>Consideraciones al usar KNN Regression</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-knn"><strong>Construcción del modelo KNN</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-con-support-vector-machine-svr"><strong>Regresión con Support Vector Machine (SVR)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-la-svr"><strong>¿Cómo funciona la SVR?</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-decision"><strong>Función de Decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-del-nucleo"><strong>Definición del Núcleo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-de-un-modelo-de-svr"><strong>Construcción de un Modelo de SVR</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen"><strong>Resumen</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-svr"><strong>Construcción del modelo de SVR</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-de-los-modelos"><strong>Evaluación de los módelos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-cross-validation"><strong>Validación cruzada (Cross-Validation)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-validacion-cruzada"><strong>Tipos de validación cruzada</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#concepto-de-grid-search-busqueda-de-grilla"><strong>Concepto de Grid Search (busqueda de grilla)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-regresion-que-pueden-usar-grid-search-para-hiperparametrizacion"><strong>Modelos de Regresión que pueden usar Grid Search para hiperparametrización</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-con-validacion-cruzada"><strong>Grid Search con validación cruzada</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-completo-de-los-modelos"><strong>Análisis completo de los modelos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-rigde"><strong>Modelo Rigde</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-lasso"><strong>Modelo Lasso</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-k-vecinos"><strong>Modelo por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-lineal"><strong>Modelo por SVR con kernel lineal</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-polinomial"><strong>Modelo por SVR con kernel polinomial</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-rbf"><strong>Modelo por SVR con kernel RBF</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-rendimiento-de-modelos"><strong>Comparación de rendimiento de modelos</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clasificacion"><strong>Clasificación</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-modelos-de-clasificacion"><strong>Tipos de Modelos de Clasificación</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-logistica"><strong>Regresión logística</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-claves"><strong>Características claves</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-de-la-regresion-logistica"><strong>Idea de la regresión logística</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-clasificacion-usando-regresion-logistica-de-entrega-o-no-de-tarjetas-de-creditos"><strong>Modelo de clasificación usando regresión logística de entrega o no de tarjetas de créditos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-las-librerias">1. <strong>Importar las librerias</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2. <strong>Lectura de los datos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#datos-faltantes-o-atipicos">3. <strong>Datos faltantes o atípicos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#etl-conjunto-de-entrenamiento-y-prueba"><strong>4. ETL, conjunto de entrenamiento y prueba</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento-de-los-datos">5. <strong>Preprocesamiento de los datos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">6. <strong>Construcción del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-de-un-modelo"><strong>Métricas de evaluación de un modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#matriz-de-confunsion"><strong>Matriz de confunsión</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#exactitud-accuracy"><strong>Exactitud (Accuracy)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-precision"><strong>Precisión (Precision)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#recall-sensibilidad"><strong>Recall (Sensibilidad)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#especificidad-specificity"><strong>Especificidad (Specificity)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score"><strong>F1-Score</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#curva-roc-y-auc-roc"><strong>Curva ROC y AUC-ROC</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-del-modelo-de-regresion-logistica"><strong>Metricas de evaluación del modelo de regresión logística</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-clasificacion-de-knn"><strong>Modelo de clasificación de KNN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas"><strong>Características</strong>:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-distancia"><strong>Métricas de distancia</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-knn"><strong>Idea del KNN</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-knn-con-sus-metricas"><strong>Construcción del modelo de KNN con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-maquina-de-soporte-vectorial"><strong>Modelo de Máquina de Soporte Vectorial</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-los-modelos-svm"><strong>Características de los Modelos SVM</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-de-maquina-de-soporte-vectorial"><strong>Idea de maquina de soporte vectorial</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-kernel-de-maquina-de-soporte-vectorial"><strong>Idea del kernel de maquina de soporte vectorial</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-svm-con-sus-metricas"><strong>Construcción del modelo de SVM con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-naives-bayes"><strong>Modelo de Naives-Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-la-regla-de-bayes"><strong>Definición de la Regla de Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-la-regla-de-bayes"><strong>Ejemplo de la regla de Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clasificador-naive-bayes"><strong>Clasificador Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-naive-bayes-para-clasificacion"><strong>Modelos de Naive Bayes para clasificación</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Construcción del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-arbol-de-decision"><strong>Modelo de arbol de decisión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-de-un-arbol-de-decision"><strong>Componentes de un árbol de decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-arbol"><strong>Construcción del arbol</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-arbol-de-decision"><strong>Idea del arbol de decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-arbol-de-decision-con-sus-metricas"><strong>Construcción del modelo de arbol de decisión con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-random-forest"><strong>Modelo Random Forest</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-del-modelo"><strong>Características del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-random-forest"><strong>Construcción del modelo de Random Forest</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-xgboost"><strong>Modelo de XGBoost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-xgboost"><strong>Definición de XGboost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-matematica"><strong>Fórmula matemática</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Características del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-xgboost-con-sus-metricas"><strong>Construcción del modelo XGboost con sus métricas</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-con-optimizacion-bayesiana"><strong>Hiperparámetros con optimización bayesiana</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Análisis completo de los modelos</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="modulo-6-machine-learning">
<h1><strong>Módulo 6: Machine Learning</strong><a class="headerlink" href="#modulo-6-machine-learning" title="Permalink to this heading">#</a></h1>
<p><strong>Machine Learning</strong> (ML), o aprendizaje automático, es una rama de la inteligencia artificial (IA) que se enfoca en construir sistemas capaces de aprender y mejorar automáticamente a partir de los datos sin necesidad de ser programados de manera explícita. Estos sistemas permiten identificar patrones y tomar decisiones basadas en grandes volúmenes de datos, aplicándose en diversas áreas como la clasificación de imágenes, la predicción de ventas o la personalización de recomendaciones.</p>
<p>Uno de los algoritmos más simples y utilizados en Machine Learning es la <strong>regresión lineal</strong>, que permite predecir una variable continua a partir de la relación entre una variable dependiente y una o más variables independientes. Cuando se consideran múltiples variables independientes, se utiliza la <strong>regresión múltiple</strong> para mejorar las predicciones. A medida que los datos se vuelven más complejos, es importante aplicar técnicas como la <strong>regresión Ridge</strong> y <strong>Lasso</strong>, que introducen penalizaciones para evitar el sobreajuste y mejorar la regularización de los modelos. Ridge tiende a minimizar la magnitud de los coeficientes, mientras que Lasso puede reducir algunos de estos coeficientes a cero, facilitando la selección de las características más relevantes.</p>
<p>En el ámbito de la clasificación, uno de los algoritmos más comunes es <strong>Naive Bayes</strong>, un modelo probabilístico basado en el teorema de Bayes que resulta especialmente útil para problemas donde se puede asumir independencia entre las características, como la clasificación de texto o el filtrado de correos no deseados. Otro algoritmo utilizado para clasificación es <strong>K-Vecinos Más Cercanos (K-NN)</strong>, que clasifica los nuevos datos en función de la cercanía a sus vecinos más cercanos, lo cual lo convierte en un enfoque intuitivo pero potencialmente costoso cuando se maneja un gran volumen de datos.</p>
<p>Para abordar problemas más complejos que requieren modelos más potentes, se utilizan algoritmos avanzados como las <strong>Máquinas de Soporte Vectorial (SVM)</strong>, que buscan un hiperplano óptimo para separar las clases en un espacio de características. También destacan los modelos basados en árboles, como <strong>Random Forest</strong>, que combina varios árboles de decisión para mejorar la precisión y robustez del modelo, reduciendo el riesgo de sobreajuste. Un modelo de gran eficacia es <strong>XGBoost</strong>, una técnica de boosting que construye modelos secuenciales de árboles de decisión, lo que lo hace altamente eficiente y efectivo en grandes volúmenes de datos.</p>
<p>La correcta <strong>evaluación del modelo</strong> es fundamental para garantizar que no solo funcione bien en los datos de entrenamiento, sino que también pueda generalizarse a datos nuevos. Este proceso incluye dividir los datos en conjuntos de entrenamiento y prueba, o utilizar validación cruzada. Las métricas más comunes para evaluar el rendimiento del modelo varían según el tipo de problema. En el caso de la regresión, se suelen utilizar métricas como el error cuadrático medio (MSE), el error absoluto medio (MAE) y el coeficiente de determinación (R²). Para la clasificación, se emplean métricas como la exactitud, la precisión, la recuperación (recall), la F1-Score y la curva ROC-AUC, que permiten medir la capacidad del modelo para distinguir entre las diferentes clases.</p>
<p>Finalmente, las <strong>redes neuronales</strong> son modelos avanzados inspirados en la estructura del cerebro humano, que permiten resolver problemas complejos y no lineales. Estas redes están compuestas por capas de neuronas artificiales que transforman los datos a través de cálculos matemáticos. Las redes neuronales han demostrado ser especialmente útiles en aplicaciones como el reconocimiento de imágenes, el procesamiento de lenguaje natural y el análisis de grandes volúmenes de datos.</p>
<section id="arthur-samuel-pionero-del-aprendizaje-automatico-y-la-inteligencia-artificial">
<h2><strong>Arthur Samuel: Pionero del Aprendizaje Automático y la Inteligencia Artificial</strong><a class="headerlink" href="#arthur-samuel-pionero-del-aprendizaje-automatico-y-la-inteligencia-artificial" title="Permalink to this heading">#</a></h2>
<p>Arthur Samuel fue un visionario en el campo de la inteligencia artificial y la computación. Nacido en 1901, Samuel se graduó en ingeniería eléctrica y comenzó su carrera trabajando en IBM, donde se convirtió en uno de los pioneros del desarrollo de software y en uno de los primeros en explorar el potencial de las máquinas para “aprender” por sí mismas. A través de su trabajo, sentó las bases de lo que hoy conocemos como <strong>aprendizaje automático</strong> (<em>Machine Learning</em>).</p>
<p>El logro más reconocido de Samuel fue el desarrollo del programa <strong>“Jugador de Damas”</strong> en 1959, donde utilizó conceptos de lo que más tarde se llamaría <strong>aprendizaje por refuerzo</strong> y <strong>algoritmos heurísticos</strong>. Su programa no solo jugaba a las damas, sino que también era capaz de mejorar su habilidad con el tiempo, jugando contra sí mismo y aprendiendo de sus errores. Lo innovador de este enfoque fue que permitía que el programa ajustara sus estrategias con base en la retroalimentación de las partidas previas, optimizando su desempeño sin intervención humana directa.</p>
<p>Samuel también fue uno de los primeros en utilizar el término <strong>“aprendizaje automático”</strong>, lo que indica su clara visión de que las máquinas podrían, algún día, desarrollar la capacidad de aprender de manera similar a los humanos. Este concepto marcó un punto de inflexión en la historia de la informática y la IA, ya que introdujo la idea de que las computadoras podían ser programadas no solo para ejecutar tareas específicas, sino también para <strong>aprender y adaptarse</strong> a nuevas situaciones y mejorar su rendimiento a medida que acumulaban experiencia.</p>
<p>El impacto de Arthur Samuel se extiende más allá de su programa de damas. Su trabajo inspiró a generaciones de investigadores en inteligencia artificial y aprendizaje automático, y es recordado como uno de los primeros en abrir el camino para el desarrollo de sistemas de IA modernos que, como los humanos, pueden aprender y mejorar a través de la experiencia. Gracias a sus contribuciones, Samuel es reconocido como uno de los <strong>padres fundadores de la inteligencia artificial</strong>.</p>
<p><img alt="arthur" src="_images/arthut.jpg" /></p>
</section>
<section id="generalizacion-sobreajuste-y-subajuste">
<h2><strong>Generalización, sobreajuste y subajuste</strong><a class="headerlink" href="#generalizacion-sobreajuste-y-subajuste" title="Permalink to this heading">#</a></h2>
<p>En el <strong>aprendizaje supervisado</strong>, el objetivo principal es construir un modelo a partir de los datos de entrenamiento y que este sea capaz de realizar <strong>predicciones precisas</strong> sobre datos desconocidos que tengan las mismas características que el conjunto de entrenamiento utilizado. Si un modelo es capaz de hacer predicciones acertadas sobre datos nuevos, decimos que tiene la capacidad de <strong>generalizar</strong> desde el conjunto de <strong>entrenamiento</strong> al conjunto de <strong>prueba</strong>. Nuestro objetivo es construir un modelo que pueda <strong>generalizar</strong> con la mayor precisión posible.</p>
<p>Por lo general, entrenamos un modelo de manera que sea preciso en el conjunto de entrenamiento. Si los conjuntos de <strong>entrenamiento</strong> y de <strong>prueba</strong> comparten suficientes similitudes, esperamos que el modelo también funcione bien en el conjunto de prueba. Sin embargo, esto no siempre es así. Si construimos modelos demasiado complejos, podemos lograr un ajuste perfecto en el conjunto de entrenamiento, pero esto no garantiza que el modelo generalice bien a datos nuevos, lo que lleva a un fenómeno conocido como <strong>sobreajuste</strong>.</p>
<p>El <strong>sobreajuste (overfitting)</strong> ocurre cuando el modelo se ajusta demasiado a las particularidades y ruido del conjunto de entrenamiento, lo que resulta en un modelo que tiene un rendimiento excelente en dicho conjunto, pero falla al enfrentarse a datos no vistos. Por el contrario, si el modelo es demasiado simple, podría no capturar adecuadamente la complejidad y variabilidad de los datos, causando un mal desempeño tanto en el conjunto de entrenamiento como en el de prueba. Esta situación se conoce como <strong>subajuste (underfitting)</strong>.</p>
<p>El desafío en el aprendizaje supervisado es encontrar un balance adecuado entre un modelo demasiado simple y uno excesivamente complejo, de modo que pueda generalizar correctamente y ofrecer un rendimiento sólido en datos nuevos.</p>
<p><img alt="overunder" src="_images/overunder.png" /></p>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<ul class="simple">
<li><p><strong>Cuanto más complejo permitimos que sea nuestro modelo, mejor podremos predecir en los datos de entrenamiento</strong>. Sin embargo, si nuestro <strong>modelo se vuelve demasiado complejo</strong>, empezamos a <strong>centrarnos demasiado en cada punto de datos individual de nuestro conjunto de entrenamiento</strong>, y el modelo <strong>no se generalizará correctamente con nuevos datos</strong>.</p></li>
<li><p>Hay un <strong>punto intermedio (sweet spot)</strong> en el que se obtiene el mejor rendimiento de generalización. Este es el modelo que queremos encontrar. El <strong>equilibrio entre el overfitting y underfitting</strong>.</p></li>
</ul>
</div>
<p><img alt="sweet_spot" src="_images/sweet_spot.png" /></p>
</section>
<section id="regresion">
<h2><strong>Regresión</strong><a class="headerlink" href="#regresion" title="Permalink to this heading">#</a></h2>
<p>La <strong>regresión</strong> es una técnica estadística y de aprendizaje automático utilizada para modelar la relación entre una <strong>variable dependiente</strong> (o respuesta) y una o más <strong>variables independientes</strong> (o predictoras). El objetivo principal de la regresión es predecir el valor de la variable dependiente en función de los valores de las variables independientes, o entender cómo las variables independientes influyen en la variable dependiente.</p>
<p>Existen varios tipos de regresión, siendo los más comunes la <strong>regresión lineal</strong> y la <strong>regresión no lineal</strong>, que se seleccionan en función de la relación entre las variables.</p>
<section id="tipos-de-regresion">
<h3><strong>Tipos de regresión</strong><a class="headerlink" href="#tipos-de-regresion" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Regresión lineal</strong>: Este es el tipo más básico de regresión, donde se asume que la relación entre la variable dependiente y las variables independientes es lineal. Se busca ajustar una línea recta que mejor represente los datos, minimizando la distancia entre los puntos de los datos y la línea ajustada. La <strong>regresión lineal simple</strong> involucra solo una variable independiente, mientras que la <strong>regresión lineal múltiple</strong> involucra varias variables independientes.</p></li>
<li><p><strong>Regresión Ridge y Lasso</strong>: Son variaciones de la regresión lineal que incluyen regularización para evitar el sobreajuste. <strong>Ridge</strong> agrega una penalización a la magnitud de los coeficientes del modelo, mientras que <strong>Lasso</strong> no solo penaliza los coeficientes, sino que también puede llevar algunos de ellos a cero, lo que resulta en la selección automática de características.</p></li>
</ol>
</section>
<section id="modelo-de-regresion-lineal">
<h3><strong>Modelo de regresión lineal</strong><a class="headerlink" href="#modelo-de-regresion-lineal" title="Permalink to this heading">#</a></h3>
<p>El objetivo principal de la regresión es encontrar los <strong>coeficientes</strong> que mejor ajusten el modelo, minimizando el <strong>error</strong> o la diferencia entre los valores predichos y los valores reales.</p>
<p>El modelo tiene la forma:</p>
<div class="math notranslate nohighlight" id="equation-linear-reg">
<span class="eqno">(1)<a class="headerlink" href="#equation-linear-reg" title="Permalink to this equation">#</a></span>\[
\boldsymbol{y}=\boldsymbol{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon},
\]</div>
<p>este se denomina, <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> clásico, si se cumplen los siguientes supuestos:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(\boldsymbol{\varepsilon})=\boldsymbol{0}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Cov(\boldsymbol{\varepsilon})=E(\boldsymbol{\varepsilon}\boldsymbol{\varepsilon}^{T})=\sigma^{2}\boldsymbol{I}\)</span></p></li>
<li><p>La matriz de diseño <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> tiene rango completo, es decir <span class="math notranslate nohighlight">\(\textrm{rk}(\boldsymbol{X})=p+1\)</span></p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">normal</span></code> clasico es obtenido si adicionalmente  se tiene que <span class="math notranslate nohighlight">\(\boldsymbol{\varepsilon}\sim N(\boldsymbol{0}, \sigma^{2}\boldsymbol{I})\)</span>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> <a class="reference internal" href="#equation-linear-reg">(1)</a> puede escribirse en la siguiente forma</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear-reg-mat">
<span class="eqno">(2)<a class="headerlink" href="#equation-linear-reg-mat" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{i}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{i1} &amp; x_{i2} &amp; \cdots &amp; x_{ip}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\[2mm]
\beta_{1}\\[2mm]
\beta_{2}\\
\vdots\\[2mm]
\beta_{p}
\end{pmatrix}
+
\begin{pmatrix}
\varepsilon_{1}\\
\varepsilon_{2}\\
\vdots\\
\varepsilon_{i}\\
\vdots\\
\varepsilon_{n}
\end{pmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>En el curso de <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> se estudian estimaciones del vector de coeficientes de regresión <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> utilizando método de <code class="docutils literal notranslate"><span class="pre">mínimos</span> <span class="pre">cuadrados</span></code> y <code class="docutils literal notranslate"><span class="pre">máxima</span> <span class="pre">verosimilitud</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>A partir del sistema <a class="reference internal" href="#equation-linear-reg-mat">(2)</a>, se puede observar que la <span class="math notranslate nohighlight">\(i\)</span>-esima predicción para un modelo lineal es la siguiente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i}=\hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1}+\hat{\beta}_{2}\cdot x_{i2}+\cdots+\hat{\beta}_{p}\cdot x_{ip}=\boldsymbol{\hat{\beta}}^{T}\boldsymbol{x}_{i},~i = 1,2,\dots, n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(x_{i1},\dots, x_{ip}\)</span> denotan las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">predictoras</span></code> o características (en este ejemplo, el número de características es <span class="math notranslate nohighlight">\(p\)</span>). Los valores, <span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=0,1,\dots,p\)</span>, son lo parámetros aprendidos por el modelo y <span class="math notranslate nohighlight">\(\hat{y}_{i}\)</span> es la predicción obtenida por el modelo. Para un conjunto de datos con una sola característica</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i} = \hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1},~i=1,2,\dots,n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> es la pendiente y <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span> es el desplazamiento en el eje <span class="math notranslate nohighlight">\(y\)</span>. Para más características, <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> contiene las pendientes a lo largo de cada eje de características. Alternativamente, se puede pensar en la respuesta predicha como una suma ponderada de las características de entrada, con pesos (que pueden ser negativos) dados por las entradas de <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span>.</p></li>
</ul>
<p>Veamos una idea visual de la regresión lineal simple</p>
<p><img alt="MRL1" src="_images/MRL_1.png" /></p>
<p><img alt="MRL2" src="_images/MRL_2.png" /></p>
<p><img alt="MRL3" src="_images/MRL_3.png" /></p>
<p><img alt="MRL4" src="_images/MRL_4.png" /></p>
</section>
<section id="regresion-lineal-simple">
<h3><strong>Regresión lineal simple</strong><a class="headerlink" href="#regresion-lineal-simple" title="Permalink to this heading">#</a></h3>
<p>El siguiente  conjunto de datos relaciona los años de experiencia laboral con los salarios percibidos por empleados. Estas dos variables ofrecen una perspectiva clave para entender cómo la experiencia profesional puede influir en la remuneración en el contexto laboral.</p>
<p>Las columnas presentes en el archivo son:</p>
<ol class="arabic simple">
<li><p><strong>YearsExperience</strong>: Indica los años de experiencia acumulada por un empleado. Esta variable podría ser útil para evaluar el crecimiento salarial promedio según la trayectoria laboral.</p></li>
<li><p><strong>Salary</strong>: Refleja el salario anual correspondiente a esos años de experiencia. Este dato permite analizar la progresión del salario a medida que los empleados ganan más años de experiencia, lo que podría ser útil para modelos predictivos de salario.</p></li>
</ol>
<p>Este tipo de información suele ser relevante en estudios de recursos humanos, análisis de mercado laboral, o al construir modelos de regresión que estimen el salario en función de los años de experiencia, ayudando a identificar patrones o desigualdades salariales.</p>
<section id="importemos-las-librerias">
<h4>1. <strong>Importemos las librerias</strong><a class="headerlink" href="#importemos-las-librerias" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># Importa la librería NumPy para operaciones matemáticas avanzadas.</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># Importa Matplotlib para visualización de datos.</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>  <span class="c1"># Importa pandas para manipulación y análisis de datos.</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span> <span class="c1"># Importa seaborn para la visualizacion de datos</span>
<span class="kn">import</span> <span class="nn">warnings</span> <span class="c1"># Importa warnings para las advertencia</span>

<span class="c1"># Importa funciones de Scikit-learn para dividir el conjunto de datos y aplicar regresión lineal.</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1"># Importa la librería Statsmodels para ajustar modelos de regresión con más opciones estadísticas.</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="carguemos-los-datos">
<h4>2. <strong>Carguemos los datos</strong><a class="headerlink" href="#carguemos-los-datos" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar el archivo CSV para inspeccionar su contenido</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;C:/Users/cdeor/OneDrive/Documentos/MachineLearningDipSerfinanzas/jbook_ml202430/docs/_data/dataml/Salary_Data.csv&#39;</span>
<span class="n">df_salary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="eda">
<h4>3. <strong>EDA</strong><a class="headerlink" href="#eda" title="Permalink to this heading">#</a></h4>
<p>Procedemos a realizar un <strong>análisis exploratorio de datos</strong> para investigar y resumir principales características de nuestros datos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar las primeras filas del conjunto de datos para entender su estructura</span>
<span class="n">df_salary</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YearsExperience</th>
      <th>Salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.1</td>
      <td>39343.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.3</td>
      <td>46205.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.5</td>
      <td>37731.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.0</td>
      <td>43525.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.2</td>
      <td>39891.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar la información</span>
<span class="n">df_salary</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 30 entries, 0 to 29
Data columns (total 2 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   YearsExperience  30 non-null     float64
 1   Salary           30 non-null     float64
dtypes: float64(2)
memory usage: 608.0 bytes
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tamaño de los datos</span>
<span class="n">df_salary</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(30, 2)
</pre></div>
</div>
</div>
</div>
<p>El método <code class="docutils literal notranslate"><span class="pre">DataFrame.describe()</span></code> genera estadísticos descriptivos que resumen la <strong>tendencia central</strong>, la <strong>dispersión</strong> y la <strong>forma de la distribución</strong> de un conjunto de datos, excluyendo los valores <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Este método es útil para obtener una visión general del comportamiento de los datos numéricos dentro del DataFrame.</p>
<p>Algunos de los estadísticos que se generan incluyen:</p>
<ul class="simple">
<li><p><strong>Conteo (count)</strong>: La cantidad de valores no nulos.</p></li>
<li><p><strong>Promedio (mean)</strong>: El valor promedio de la columna.</p></li>
<li><p><strong>Desviación estándar (std)</strong>: La medida de dispersión o variabilidad de los datos.</p></li>
<li><p><strong>Mínimo (min)</strong> y <strong>máximo (max)</strong>: Los valores más extremos.</p></li>
<li><p><strong>Cuartiles (25%, 50%, 75%)</strong>: Los valores que dividen los datos en cuatro partes iguales.</p></li>
</ul>
<p>Es importante destacar que el método <code class="docutils literal notranslate"><span class="pre">describe()</span></code> <strong>solo trabaja con valores numéricos</strong> por defecto. Si el DataFrame contiene alguna columna categórica, el método la ignorará y solo mostrará el resumen de las columnas numéricas. Sin embargo, puedes incluir un resumen para todas las columnas, incluidas las categóricas, pasando el parámetro <code class="docutils literal notranslate"><span class="pre">include=&quot;all&quot;</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generar estadísticos descriptivos con salary_data</span>
<span class="n">df_salary</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YearsExperience</th>
      <th>Salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>30.000000</td>
      <td>30.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.313333</td>
      <td>76003.000000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.837888</td>
      <td>27414.429785</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.100000</td>
      <td>37731.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3.200000</td>
      <td>56720.750000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>4.700000</td>
      <td>65237.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>7.700000</td>
      <td>100544.750000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.500000</td>
      <td>122391.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="datos-faltantes-o-nans">
<h4>4. <strong>Datos faltantes o NANs</strong><a class="headerlink" href="#datos-faltantes-o-nans" title="Permalink to this heading">#</a></h4>
<p>Verifiquemos además si existen datos faltantes en nuestro conjunto de datos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_salary</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>YearsExperience    0
Salary             0
dtype: int64
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizacion-de-datos">
<h4>5. <strong>Visualización de datos</strong><a class="headerlink" href="#visualizacion-de-datos" title="Permalink to this heading">#</a></h4>
<p>Realicemos un diagrama de cajas y bigotes para el salario</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ignorar advertencias de futuras versiones</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 

<span class="c1"># # Establecer el estilo de las gráficas como &#39;whitegrid&#39;</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>

<span class="c1"># Diagrama de cajas y bigotes para &#39;Salary&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">df_salary</span><span class="p">[</span><span class="s1">&#39;Salary&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Diagrama de Cajas y Bigotes - Salario&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d0320d0782a4de661ff8f1596cf57d501c6d0e21d788fb26ad8202a4ba2a94c4.png" src="_images/d0320d0782a4de661ff8f1596cf57d501c6d0e21d788fb26ad8202a4ba2a94c4.png" />
</div>
</div>
<p>Este gráfico muestra la distribución de los salarios en el conjunto de datos. Podemos observar lo siguiente:</p>
<ul class="simple">
<li><p>La mayor concentración de salarios está en el rango entre 50,000 y 100,000 unidades monetarias.</p></li>
<li><p>La mediana se encuentra alrededor de los 70,000, lo que indica que la mitad de los salarios están por debajo de este valor.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ignorar advertencias de futuras versiones</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 

<span class="c1"># # Establecer el estilo de las gráficas como &#39;whitegrid&#39;</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>

<span class="c1"># Diagrama de cajas y bigotes para &#39;YearsExperience&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">df_salary</span><span class="p">[</span><span class="s1">&#39;YearsExperience&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Diagrama de Cajas y Bigotes - Años de Experiencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3a41659abd928efbd240158dc1354854f35f3fa6174cd05b51657685b60b8221.png" src="_images/3a41659abd928efbd240158dc1354854f35f3fa6174cd05b51657685b60b8221.png" />
</div>
</div>
<p>Este gráfico muestra la distribución de los años de experiencia:</p>
<ul class="simple">
<li><p>La mayoría de los empleados tiene entre 2 y 7 años de experiencia.</p></li>
<li><p>No se observan valores atípicos destacados en la variable de años de experiencia.</p></li>
<li><p>La mediana se encuentra alrededor de los 5 años de experiencia, lo que sugiere que el conjunto de datos está centrado en empleados con experiencia moderada.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gráfico de dispersión de &#39;Salary&#39; vs &#39;YearsExperience&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;YearsExperience&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Salary&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_salary</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gráfico de Dispersión - Salario vs Años de Experiencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/44b29f9baad142026133814a08596873254de8a174f9a2c6382fe8eeea0432a9.png" src="_images/44b29f9baad142026133814a08596873254de8a174f9a2c6382fe8eeea0432a9.png" />
</div>
</div>
<p>El gráfico de dispersión nos muestra cómo se relacionan los años de experiencia con el salario:</p>
<ul class="simple">
<li><p>Existe una clara tendencia positiva: a medida que los empleados tienen más años de experiencia, su salario tiende a aumentar.</p></li>
<li><p>Sin embargo, parece haber cierta dispersión en los salarios para aquellos con más experiencia, lo que indica que el crecimiento salarial no es lineal ni uniforme en todos los casos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mapa de calor de las correlaciones</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">df_salary</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm_r&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Mapa de Calor de Correlaciones&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/45b10e1add9235e7901f574234dc35159a09b3be0d0c8b7ac89276966e290865.png" src="_images/45b10e1add9235e7901f574234dc35159a09b3be0d0c8b7ac89276966e290865.png" />
</div>
</div>
<p>Este mapa de calor visualiza las correlaciones entre las variables <strong>Salary</strong> y <strong>YearsExperience</strong>:</p>
<ul class="simple">
<li><p>La correlación entre ambas variables es alta y positiva (+0.97), lo que confirma que los empleados con más años de experiencia suelen tener salarios más altos.</p></li>
<li><p>Este fuerte coeficiente sugiere que la experiencia laboral es un predictor clave del salario, lo que podría ser relevante para modelos de predicción.</p></li>
</ul>
</section>
<section id="construccion-del-modelo">
<h4>6. <strong>Construcción del modelo</strong><a class="headerlink" href="#construccion-del-modelo" title="Permalink to this heading">#</a></h4>
<p>Se ajusta un modelo de regresión lineal utilizando <code class="docutils literal notranslate"><span class="pre">Salary</span></code> como variable respuesta y <code class="docutils literal notranslate"><span class="pre">YearsExperience</span></code> como variable predictora. En cualquier estudio predictivo, no solo es esencial ajustar el modelo, sino también evaluar su capacidad para predecir correctamente nuevas observaciones. Para realizar esta evaluación de manera adecuada, los datos se dividen en dos grupos: uno destinado al entrenamiento del modelo y otro reservado para pruebas, lo que permite validar su rendimiento en datos no utilizados durante el ajuste del modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># División de los datos en conjuntos de entrenamiento y prueba</span>
<span class="c1"># X contiene la variable predictora &#39;YearsExperience&#39; y y es la variable objetivo &#39;Salary&#39;.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_salary</span><span class="p">[[</span><span class="s1">&#39;YearsExperience&#39;</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_salary</span><span class="p">[</span><span class="s1">&#39;Salary&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Se divide el conjunto de datos en un 80% para entrenamiento y un 20% para prueba.</span>
<span class="c1"># random_state = 42 asegura que la división sea reproducible.</span>
<span class="c1"># shuffle = True indica que los datos se mezclarán antes de dividirse.</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                                        <span class="n">X</span><span class="p">,</span>               <span class="c1"># Variables predictoras</span>
                                        <span class="n">y</span><span class="p">,</span>               <span class="c1"># Variable objetivo</span>
                                        <span class="n">train_size</span>   <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>  <span class="c1"># Tamaño del conjunto de entrenamiento</span>
                                        <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>    <span class="c1"># Para obtener resultados reproducibles</span>
                                        <span class="n">shuffle</span>      <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Mezclar los datos antes de dividir</span>
                                    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<ul class="simple">
<li><p>El número <code class="docutils literal notranslate"><span class="pre">42</span></code> es comúnmente elegido en la literatura relacionada con la <strong>inteligencia artificial</strong> (AI) como un homenaje al libro de Douglas Adams, <em><a class="reference external" href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#The_number_42">The Hitchhiker’s Guide to the Galaxy</a></em>, una popular serie de ciencia ficción. En este libro, el número 42 es presentado como la respuesta a la gran pregunta sobre “la vida, el universo y todo lo demás”, según los cálculos de un superordenador llamado <strong>“Deep Thought”</strong>. Esta referencia ha ganado notoriedad tanto entre los aficionados al género como entre los miembros de la comunidad científica.</p></li>
<li><p>En el contexto de la programación, el parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> puede tomar cualquier número entero. Si bien se suele utilizar <code class="docutils literal notranslate"><span class="pre">42</span></code> por razones simbólicas, en realidad cualquier entero positivo es válido. Además, se podría realizar un <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> para encontrar el valor de <code class="docutils literal notranslate"><span class="pre">random_state</span></code> que proporcione el mejor rendimiento del modelo. Más adelante, abordaremos el uso de <strong>GridSearch</strong>.</p></li>
<li><p>Es importante tener en cuenta que, si no se establece un valor específico para <code class="docutils literal notranslate"><span class="pre">random_state</span></code>, como <code class="docutils literal notranslate"><span class="pre">42</span></code> u otro número entero, cada vez que se ejecute el código, se generará un conjunto de prueba diferente, lo que puede afectar la reproducibilidad de los resultados.</p></li>
</ul>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creación del modelo de regresión lineal</span>
<span class="c1"># Se crea un objeto de regresión lineal utilizando la clase LinearRegression de sklearn.</span>
<span class="c1"># Luego, se ajusta el modelo a los datos de entrenamiento X_train y y_train.</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">LinearRegression</label><div class="sk-toggleable__content"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los parámetros de “pendiente” (<span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=1,2,\dots,p\)</span>), también llamados pesos o coeficientes, se almacenan en el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code>, mientras que el desplazamiento o intercepción (<span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span>) se almacena en el atributo <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.coef_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.intercept_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lr.coef_: [9423.81532303]
lr.intercept_: 25321.583011776813
</pre></div>
</div>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<p>El guión bajo (<code class="docutils literal notranslate"><span class="pre">_</span></code>) al final de atributos como <code class="docutils literal notranslate"><span class="pre">coef_</span></code> e <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> es una convención comúnmente utilizada en <strong>scikit-learn</strong> para indicar que dichos atributos son derivados de los datos de entrenamiento. Esta convención permite distinguir entre los atributos que son calculados por el modelo y los parámetros que son definidos por el usuario. De esta manera, los atributos que terminan con un guión bajo (<code class="docutils literal notranslate"><span class="pre">_</span></code>) indican que son aprendidos o ajustados durante el proceso de entrenamiento del modelo.</p>
</div>
<ul class="simple">
<li><p>La función <code class="docutils literal notranslate"><span class="pre">modelo.predict()</span></code> se utiliza en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> para realizar <strong>predicciones utilizando un modelo previamente entrenado</strong>. En el contexto de un modelo de regresión lineal, como el que has ajustado, <code class="docutils literal notranslate"><span class="pre">modelo.predict()</span></code> toma como entrada un conjunto de datos (generalmente las variables predictoras) y devuelve las predicciones del modelo sobre esas entradas.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># para los datos conocidos del conjunto de train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Primeras tres predicciones: </span><span class="si">{</span><span class="n">y_pred_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Primeras tres predicciones: [122386.880839   107308.77632215  63016.8443039 ]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># para los datos desconocidos</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Primeras tres predicciones: </span><span class="si">{</span><span class="n">y_pred_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Primeras tres predicciones: [115790.21011287  71498.27809463 102596.86866063]
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizacion-del-conjunto-de-entrenamiento-y-prueba">
<h4>7. <strong>Visualización del conjunto de entrenamiento y prueba</strong><a class="headerlink" href="#visualizacion-del-conjunto-de-entrenamiento-y-prueba" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear una figura para mostrar ambas gráficas una al lado de la otra</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Visualizar los resultados del conjunto de entrenamiento</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sueldo vs Años de Experiencia (Conjunto de Entrenamiento)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Años de Experiencia&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Sueldo (en $)&quot;</span><span class="p">)</span>

<span class="c1"># Visualizar los resultados del conjunto de prueba</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sueldo vs Años de Experiencia (Conjunto de Testing)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Años de Experiencia&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Sueldo (en $)&quot;</span><span class="p">)</span>

<span class="c1"># Mostrar las gráficas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/f7d28829452d5b8b9865415554b8c4e9c39a22b9821648458be1f22d1d160625.png" src="_images/f7d28829452d5b8b9865415554b8c4e9c39a22b9821648458be1f22d1d160625.png" />
</div>
</div>
</section>
</section>
<section id="metricas-de-evaluacion-del-modelo-de-regresion">
<h3><strong>Métricas de evaluacion del modelo de regresión</strong><a class="headerlink" href="#metricas-de-evaluacion-del-modelo-de-regresion" title="Permalink to this heading">#</a></h3>
<p>La <strong>métricas de evaluación</strong> son medidas que se utilizan para evaluar el rendimiento de un modelo de regresión. Estas métricas permiten medir qué tan bien un modelo se ajusta a los datos observados y su capacidad para hacer predicciones precisas sobre nuevos datos. La elección de la métrica adecuada es crucial, ya que cada métrica puede destacar diferentes aspectos del rendimiento del modelo, como la magnitud del error, la sensibilidad a valores atípicos, o la proporción de la varianza explicada por el modelo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar las librerías necesarias para el cálculo de las métricas</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_log_error</span>
</pre></div>
</div>
</div>
</div>
<p>Algunas métricas de evaluación del modelo son:</p>
<section id="error-cuadratico-medio-mse-mean-squared-error">
<h4>1. <strong>Error Cuadrático Medio (<span class="math notranslate nohighlight">\(MSE\)</span> - Mean Squared Error)</strong><a class="headerlink" href="#error-cuadratico-medio-mse-mean-squared-error" title="Permalink to this heading">#</a></h4>
<p>El <strong>Error Cuadrático Medio (<span class="math notranslate nohighlight">\(MSE\)</span>)</strong> mide la media de los errores al cuadrado entre los valores predichos y los valores reales. Penaliza los errores grandes más que los pequeños debido a la elevación al cuadrado.</p>
<p>Este se utiliza para evaluar qué tan bien se ajusta el modelo a los datos de entrenamiento o de prueba. Un MSE más bajo indica un mejor ajuste del modelo.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2,
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Cuadrático Medio (MSE)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set MSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set MSE: 27102249.7313
Test set MSE: 49830096.8559
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-mse">
<h5><strong>Interpretación de MSE</strong>:<a class="headerlink" href="#interpretacion-de-mse" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Diferencia significativa entre los MSE</strong>:</p>
<ul class="simple">
<li><p>El <strong>MSE</strong> en el conjunto de prueba es considerablemente mayor que en el conjunto de entrenamiento. Esto indica que el modelo tiene un mejor rendimiento en los datos de entrenamiento en comparación con los datos no vistos (conjunto de prueba).</p></li>
<li><p>Esta diferencia sugiere que el modelo podría estar <strong>sobreajustado</strong> (overfitting), lo que significa que ha aprendido bien los detalles de los datos de entrenamiento, pero no generaliza de manera óptima a nuevos datos.</p></li>
</ul>
</li>
<li><p><strong>Sobreajuste (Overfitting)</strong>:</p>
<ul class="simple">
<li><p>El sobreajuste ocurre cuando el modelo se adapta demasiado a las particularidades del conjunto de entrenamiento, incluyendo el ruido, y por lo tanto tiene un error bajo en entrenamiento pero un error considerablemente mayor en los datos de prueba.</p></li>
<li><p>En este caso, la diferencia en los MSEs indica un potencial sobreajuste, ya que el error en los datos de prueba es casi el doble del error en los datos de entrenamiento.</p></li>
</ul>
</li>
<li><p><strong>Magnitud del MSE</strong>:</p>
<ul class="simple">
<li><p>El <strong>MSE</strong> está en las unidades de la variable objetivo (salario), elevadas al cuadrado. Si bien el valor del MSE no es fácilmente interpretable directamente, la gran diferencia entre el conjunto de entrenamiento y el de prueba indica que el modelo no está generalizando bien.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-mse">
<h5><strong>Conclusiones de MSE</strong>:<a class="headerlink" href="#conclusiones-de-mse" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El modelo tiene un rendimiento significativamente mejor en el conjunto de entrenamiento que en el conjunto de prueba, lo que sugiere que podría estar sobreajustado.</p></li>
<li><p>Es posible que el modelo esté capturando patrones específicos del conjunto de entrenamiento que no se replican bien en datos nuevos.</p></li>
<li><p>Para mejorar el rendimiento en el conjunto de prueba, podrían considerarse las siguientes acciones:</p>
<ol class="arabic simple">
<li><p>Aplicar técnicas de <strong>regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para reducir el sobreajuste.</p></li>
<li><p>Implementar <strong>validación cruzada</strong> para evaluar mejor el rendimiento del modelo y ajustar sus hiperparámetros.</p></li>
<li><p><strong>Obtener más datos</strong> de entrenamiento para ayudar al modelo a generalizar mejor a nuevos datos.</p></li>
</ol>
</li>
</ul>
</section>
</section>
<section id="error-absoluto-medio-mae-mean-absolute-error">
<h4>2. <strong>Error Absoluto Medio (<span class="math notranslate nohighlight">\(MAE\)</span> - Mean Absolute Error)</strong><a class="headerlink" href="#error-absoluto-medio-mae-mean-absolute-error" title="Permalink to this heading">#</a></h4>
<p>El <strong>Error Absoluto Medio (<span class="math notranslate nohighlight">\(MAE\)</span>)</strong> mide el promedio de las diferencias absolutas entre los valores predichos y los valores reales. No eleva al cuadrado los errores, por lo que no es tan sensible a valores atípicos.</p>
<p>Este se utiliza cuando queremos una interpretación más directa del error medio en las mismas unidades que la variable objetivo.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|,
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Absoluto Medio (MAE)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set MAE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MAE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set MAE: 4221.0467
Test set MAE: 6286.4538
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-mae">
<h5><strong>Interpretación de MAE</strong>:<a class="headerlink" href="#interpretacion-de-mae" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Diferencia entre los MAE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>El <strong>MAE</strong> en el conjunto de prueba es significativamente mayor que en el conjunto de entrenamiento. Esto indica que el modelo tiene un mejor rendimiento en los datos de entrenamiento que en los datos de prueba.</p></li>
<li><p>Esta diferencia sugiere que el modelo podría estar <strong>sobreajustado</strong> (overfitting). Es decir, el modelo se ajusta muy bien a los datos de entrenamiento, pero no generaliza tan bien cuando se le presentan datos nuevos.</p></li>
</ul>
</li>
<li><p><strong>Magnitud del MAE</strong>:</p>
<ul class="simple">
<li><p>El <strong>MAE</strong> mide el error promedio absoluto en las predicciones, es decir, cuánto se desvían las predicciones del modelo en promedio respecto a los valores reales de salario. El error promedio en el conjunto de entrenamiento es de aproximadamente <strong>4,221 unidades monetarias</strong>, mientras que en el conjunto de prueba es de <strong>6,286 unidades monetarias</strong>.</p></li>
<li><p>Aunque la diferencia entre los errores en ambos conjuntos no es enorme, sigue siendo notable. Esto indica que el modelo está haciendo mejores predicciones en los datos que ha visto (entrenamiento) en comparación con los datos que no ha visto antes (prueba).</p></li>
</ul>
</li>
<li><p><strong>Posible sobreajuste (Overfitting)</strong>:</p>
<ul class="simple">
<li><p>El hecho de que el error en el conjunto de prueba sea mayor que en el conjunto de entrenamiento sugiere que el modelo está capturando patrones específicos del conjunto de entrenamiento que no se reflejan bien en los nuevos datos. Este comportamiento es típico de un modelo que está sobreajustado.</p></li>
<li><p>En este caso, el modelo podría estar adaptándose demasiado a las peculiaridades de los datos de entrenamiento, y esto está afectando su capacidad para generalizar a datos no vistos.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-mae">
<h5><strong>Conclusiones de MAE</strong>:<a class="headerlink" href="#conclusiones-de-mae" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>La diferencia entre los <strong>MAE</strong> sugiere que el modelo está funcionando bien en el conjunto de entrenamiento, pero tiene un peor rendimiento en el conjunto de prueba, lo que indica que podría estar sobreajustado.</p></li>
<li><p>El modelo tiene un error promedio en las predicciones de salario de aproximadamente <strong>6,286 unidades monetarias</strong> en los datos de prueba, lo que podría ser un error significativo dependiendo del contexto del problema.</p></li>
<li><p>Para mejorar el rendimiento del modelo y reducir el posible sobreajuste, se pueden tomar las siguientes acciones:</p>
<ol class="arabic simple">
<li><p>Aplicar técnicas de <strong>regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para reducir la complejidad del modelo y mejorar la generalización.</p></li>
<li><p>Utilizar <strong>validación cruzada</strong> para evaluar el rendimiento del modelo en múltiples divisiones de los datos y reducir el riesgo de sobreajuste.</p></li>
<li><p><strong>Aumentar el tamaño del conjunto de datos</strong> de entrenamiento, si es posible, para ayudar al modelo a generalizar mejor.</p></li>
</ol>
</li>
</ul>
</section>
</section>
<section id="raiz-del-error-cuadratico-medio-rmse-root-mean-squared-error">
<h4>3. <strong>Raíz del Error Cuadrático Medio (<span class="math notranslate nohighlight">\(RMSE\)</span> - Root Mean Squared Error)</strong><a class="headerlink" href="#raiz-del-error-cuadratico-medio-rmse-root-mean-squared-error" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(RMSE\)</span></strong> es la raíz cuadrada del <span class="math notranslate nohighlight">\(MSE\)</span> y devuelve el error en las mismas unidades que la variable dependiente, lo que facilita la interpretación.</p>
<p>Este al igual que el <span class="math notranslate nohighlight">\(MSE\)</span>, mide el ajuste del modelo, pero es más fácil de interpretar porque está en las mismas unidades que los datos.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2},
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Raíz del Error Cuadrático Medio (RMSE)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set RMSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">))))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set RMSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set RMSE: 5205.9821
Test set RMSE: 7059.0436
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-rmse">
<h5><strong>Interpretación de RMSE</strong>:<a class="headerlink" href="#interpretacion-de-rmse" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Diferencia entre los RMSE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>El <strong>RMSE</strong> en el conjunto de prueba es mayor que en el conjunto de entrenamiento. Esto significa que el modelo está cometiendo errores más grandes en las predicciones de los datos no vistos (conjunto de prueba) en comparación con los datos con los que fue entrenado.</p></li>
<li><p>Aunque la diferencia entre ambos <strong>RMSE</strong> no es extrema, sugiere que el modelo podría estar <strong>sobreajustado</strong> (overfitting) a los datos de entrenamiento. El modelo parece ajustarse mejor a los datos que ya ha visto y tiene un rendimiento inferior en nuevos datos.</p></li>
</ul>
</li>
<li><p><strong>Magnitud del RMSE</strong>:</p>
<ul class="simple">
<li><p>El <strong>RMSE</strong> te dice, en promedio, cuánto se desvían las predicciones del modelo respecto a los valores reales, pero en las mismas unidades de la variable objetivo (en este caso, el salario).</p></li>
<li><p>En el conjunto de entrenamiento, el error promedio es de aproximadamente <strong>5,206 unidades monetarias</strong>, mientras que en el conjunto de prueba, el error promedio es de <strong>7,059 unidades monetarias</strong>.</p></li>
<li><p>Esto significa que en datos de prueba (nuevos datos no vistos), las predicciones del modelo están, en promedio, a <strong>7,059 unidades</strong> de los valores reales de salario.</p></li>
</ul>
</li>
<li><p><strong>Posible sobreajuste (Overfitting)</strong>:</p>
<ul class="simple">
<li><p>El hecho de que el <strong>RMSE</strong> sea mayor en el conjunto de prueba sugiere un posible <strong>sobreajuste</strong>. Aunque el modelo se desempeña bien en el conjunto de entrenamiento (con un <strong>RMSE</strong> más bajo), su rendimiento en datos no vistos no es tan bueno.</p></li>
<li><p>Sin embargo, la diferencia en los <strong>RMSE</strong> entre los conjuntos de entrenamiento y prueba no es excesivamente grande, lo que indica que el sobreajuste no es muy severo, pero aún podría mejorarse.</p></li>
</ul>
</li>
<li><p><strong>Comparación con el MAE y el MSE</strong>:</p>
<ul class="simple">
<li><p>El <strong>RMSE</strong> es más sensible a los errores grandes en las predicciones que el <strong>MAE</strong>. Dado que el <strong>RMSE</strong> penaliza más los errores grandes, un <strong>RMSE</strong> mayor en el conjunto de prueba puede estar indicando que hay algunos errores considerables en las predicciones que el modelo está haciendo en datos no vistos.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-rmse">
<h5><strong>Conclusiones de RMSE</strong>:<a class="headerlink" href="#conclusiones-de-rmse" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>RMSE</strong> más alto en el conjunto de prueba en comparación con el de entrenamiento sugiere que el modelo podría estar ligeramente <strong>sobreajustado</strong>. Aunque no hay una diferencia extremadamente grande entre los valores de RMSE, el modelo claramente tiene un mejor rendimiento en los datos de entrenamiento.</p></li>
<li><p>La magnitud del error promedio (alrededor de <strong>7,059 unidades monetarias</strong> en el conjunto de prueba) puede considerarse significativa, dependiendo del rango de salarios en los datos. Esto indica que hay margen para mejorar las predicciones del modelo.</p></li>
<li><p>Para mejorar el rendimiento del modelo, especialmente en datos no vistos, se pueden considerar las siguientes acciones:</p>
<ol class="arabic simple">
<li><p>Aplicar técnicas de <strong>regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para reducir el sobreajuste.</p></li>
<li><p>Implementar <strong>validación cruzada</strong> para obtener una mejor medida de la capacidad de generalización del modelo.</p></li>
<li><p>Considerar añadir más datos de entrenamiento, si es posible, o explorar nuevas variables predictoras que puedan mejorar la precisión del modelo.</p></li>
</ol>
</li>
</ul>
</section>
<section id="resumen-de-rmse">
<h5><strong>Resumen de RMSE</strong>:<a class="headerlink" href="#resumen-de-rmse" title="Permalink to this heading">#</a></h5>
<p>El modelo tiene un <strong>RMSE</strong> más bajo en el conjunto de entrenamiento, lo que indica un buen ajuste a esos datos, pero el mayor <strong>RMSE</strong> en el conjunto de prueba sugiere que el modelo no generaliza tan bien en datos nuevos. Aunque la diferencia no es extremadamente grande, esto sugiere que el modelo puede estar sobreajustado y hay margen para mejorar su capacidad de generalización.</p>
</section>
</section>
<section id="coeficiente-de-determinacion-r-2-r-squared">
<h4>4. <strong>Coeficiente de Determinación (<span class="math notranslate nohighlight">\(R^2\)</span> - <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong><a class="headerlink" href="#coeficiente-de-determinacion-r-2-r-squared" title="Permalink to this heading">#</a></h4>
<p>El <strong>coeficiente de determinación (<span class="math notranslate nohighlight">\(R^2\)</span>)</strong> mide la proporción de la varianza de la variable dependiente que es explicada por las variables independientes. Su valor está entre 0 y 1.</p>
<p>Esto indica qué tan bien se ajusta el modelo a los datos. Un valor cercano a 1 sugiere un ajuste muy bueno.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2},
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{y}\)</span> es el promedio de los valores reales.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Coeficiente de Determinación (R²)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set R²: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set R²: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set R²: 0.9645
Test set R²: 0.9024
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como tenemos integrado el <code class="docutils literal notranslate"><span class="pre">.score</span></code> en <strong>scikit-learn</strong>, este también calcula <span class="math notranslate nohighlight">\(R^2\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Coeficiente de Determinación (R²)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set R²: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set R²: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set R²: 0.9645
Test set R²: 0.9024
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-r-2">
<h5><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:<a class="headerlink" href="#interpretacion-de-r-2" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Valor de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</p>
<ul class="simple">
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> indica qué proporción de la variabilidad en la variable dependiente (salario) es explicada por el modelo basado en la variable independiente (años de experiencia). Un valor de <strong>R²</strong> más cercano a 1 indica un mejor ajuste del modelo.</p></li>
<li><p>En el conjunto de entrenamiento, un <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> de <strong>0.9645</strong> significa que el modelo explica el <strong>96.45%</strong> de la variabilidad en los salarios en función de los años de experiencia.</p></li>
<li><p>En el conjunto de prueba, un <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> de <strong>0.9024</strong> indica que el modelo sigue explicando el <strong>90.24%</strong> de la variabilidad en los salarios, lo que sugiere que el modelo sigue siendo bastante preciso en datos no vistos.</p></li>
</ul>
</li>
<li><p><strong>Diferencia entre los valores de <span class="math notranslate nohighlight">\(R^2\)</span> de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>Aunque el <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> del conjunto de prueba es un poco menor que en el conjunto de entrenamiento, la diferencia no es grande. Esto sugiere que el modelo generaliza relativamente bien en nuevos datos, aunque hay una leve disminución en su capacidad para explicar la variabilidad en los salarios en los datos de prueba.</p></li>
<li><p>Esta diferencia menor podría indicar un <strong>ligero sobreajuste</strong> (overfitting), donde el modelo se ajusta un poco mejor a los datos de entrenamiento que a los de prueba, pero aún generaliza razonablemente bien.</p></li>
</ul>
</li>
<li><p><strong>Buen ajuste del modelo</strong>:</p>
<ul class="simple">
<li><p>Con un <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> superior a 0.90 tanto en los datos de entrenamiento como de prueba, podemos decir que el modelo tiene un <strong>buen ajuste</strong> y que la variable de <strong>años de experiencia</strong> explica bien la variabilidad en los salarios.</p></li>
<li><p>A pesar de la pequeña disminución en el rendimiento en los datos de prueba, el modelo sigue siendo útil para predecir salarios en función de la experiencia.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-r-2">
<h5><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:<a class="headerlink" href="#conclusiones-de-r-2" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El alto <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> en el conjunto de entrenamiento (<strong>0.9645</strong>) indica que el modelo está bien ajustado a los datos de entrenamiento.</p></li>
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> del conjunto de prueba (<strong>0.9024</strong>) sugiere que el modelo generaliza bien en datos no vistos, aunque existe una pequeña diferencia que podría indicar un leve <strong>sobreajuste</strong>.</p></li>
<li><p>A pesar de esta pequeña diferencia, el modelo sigue siendo robusto, ya que explica más del <strong>90%</strong> de la variabilidad en los salarios en el conjunto de prueba.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-si-es-necesario-de-r-2">
<h5><strong>Posibles acciones para mejorar (si es necesario) de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-si-es-necesario-de-r-2" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Dado que el modelo ya está funcionando bien, las siguientes acciones solo serían necesarias si se busca mejorar aún más la generalización:</p>
<ol class="arabic simple">
<li><p>Aplicar <strong>técnicas de regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para evitar cualquier posible sobreajuste.</p></li>
<li><p>Implementar <strong>validación cruzada</strong> para obtener una mejor evaluación de la capacidad del modelo para generalizar.</p></li>
<li><p>Añadir más datos o explorar otras características predictoras que puedan mejorar la precisión del modelo.</p></li>
</ol>
</li>
</ul>
</section>
<section id="resumen-de-r-2">
<h5><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:<a class="headerlink" href="#resumen-de-r-2" title="Permalink to this heading">#</a></h5>
<p>El modelo tiene un <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> alto en ambos conjuntos (entrenamiento y prueba), lo que indica que el modelo ajusta bien los datos y generaliza razonablemente bien a datos no vistos. La pequeña diferencia entre el <strong>R²</strong> del entrenamiento y el de prueba podría sugerir un leve sobreajuste, pero en general el modelo es sólido para predecir salarios basados en la experiencia.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">¿Cual sería un buen score?</p>
<p>Definir un <strong>buen score</strong> en machine learning es un tema subjetivo, y bastante ligado a los datos. Pero, <strong>de forma coherente con los estándares de la industria, cualquier score superior al 70% es un gran rendimiento del modelo</strong>. De hecho, <strong>una medida de precisión de entre el 70% y el 90% no sólo es ideal, sino que es realista</strong>.</p>
</div>
</section>
</section>
<section id="r-2-ajustado-adjusted-r-squared">
<h4>5. <strong><span class="math notranslate nohighlight">\(R^2\)</span> Ajustado (Adjusted <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong><a class="headerlink" href="#r-2-ajustado-adjusted-r-squared" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> es una versión modificada del coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> que tiene en cuenta el número de predictores en el modelo. Penaliza la adición de predictores irrelevantes que no mejoran significativamente el modelo.</p>
<p>Es útil cuando se está comparando el rendimiento de modelos que tienen diferentes cantidades de variables independientes. Un <span class="math notranslate nohighlight">\(R^2\)</span> puede aumentar simplemente por agregar más variables, pero el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> solo aumenta si las nuevas variables realmente mejoran el modelo.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
R^2_{\text{ajustado}} = 1 - \left( \frac{(1 - R^2)(n - 1)}{n - k - 1} \right)
\]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> es el coeficiente de determinación,</p></li>
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span> es el número de predictores (variables independientes).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular R² ajustado train</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>  <span class="c1"># número de observaciones</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># número de predictores</span>
<span class="n">r2_ajustado_train</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Calcular R² ajustado test</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>  <span class="c1"># número de observaciones</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># número de predictores</span>
<span class="n">r2_ajustado_test</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">p</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set R² ajustado: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_ajustado_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set R² ajustado: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r2_ajustado_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set R² ajustado: 0.9629
Test set R² ajustado: 0.8781
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-r-2-ajustado">
<h5><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:<a class="headerlink" href="#interpretacion-de-r-2-ajustado" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>¿Qué es el <span class="math notranslate nohighlight">\(R^2\)</span> ajustado?</strong>:</p>
<ul class="simple">
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> es una versión ajustada del <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> que penaliza por la cantidad de predictores utilizados en el modelo. Es especialmente útil cuando se trabaja con múltiples variables independientes, ya que evita inflar artificialmente el <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> simplemente añadiendo más predictores que podrían no ser útiles.</p></li>
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> proporciona una mejor medida de la capacidad de generalización del modelo cuando se tiene más de una variable predictora. Si solo tienes una variable predictora (como en este caso, con <strong>YearsExperience</strong>), la diferencia entre el <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> y el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> será pequeña, como se refleja en tus resultados.</p></li>
</ul>
</li>
<li><p><strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado en el conjunto de entrenamiento</strong>:</p>
<ul class="simple">
<li><p>Un <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> de <strong>0.9629</strong> en el conjunto de entrenamiento sugiere que el modelo explica el <strong>96.29%</strong> de la variación en los salarios en función de los años de experiencia, incluso teniendo en cuenta posibles sobreajustes.</p></li>
<li><p>La diferencia entre el <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> original (<strong>0.9645</strong>) y el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> (<strong>0.9629</strong>) es muy pequeña, lo que indica que el modelo es bastante confiable en los datos de entrenamiento y que no hay un impacto significativo por tener un número limitado de predictores.</p></li>
</ul>
</li>
<li><p><strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado en el conjunto de prueba</strong>:</p>
<ul class="simple">
<li><p>Un <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> de <strong>0.8781</strong> en el conjunto de prueba significa que, cuando se penaliza la complejidad del modelo, este sigue explicando el <strong>87.81%</strong> de la variación en los salarios en los datos no vistos.</p></li>
<li><p>La diferencia entre el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> y el <strong><span class="math notranslate nohighlight">\(R^2\)</span></strong> original en el conjunto de prueba (<strong>0.9024</strong>) indica una leve penalización, lo que sugiere que el modelo no generaliza tan bien en comparación con su rendimiento en los datos de entrenamiento.</p></li>
</ul>
</li>
<li><p><strong>Comparación entre <span class="math notranslate nohighlight">\(R^2\)</span> ajustado en entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> en el conjunto de entrenamiento es mayor que en el conjunto de prueba, lo que refleja que el modelo tiene un mejor ajuste a los datos con los que fue entrenado que a los nuevos datos.</p></li>
<li><p>La diferencia entre el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> del conjunto de entrenamiento (<strong>0.9629</strong>) y el del conjunto de prueba (<strong>0.8781</strong>) sugiere que el modelo puede estar ligeramente <strong>sobreajustado</strong> (overfitting), ya que está funcionando un poco mejor en el conjunto de entrenamiento en comparación con el conjunto de prueba.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-r-2-ajustado">
<h5><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:<a class="headerlink" href="#conclusiones-de-r-2-ajustado" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> más bajo en el conjunto de prueba (0.8781) en comparación con el conjunto de entrenamiento (0.9629) indica que, aunque el modelo está funcionando bien, hay una pequeña diferencia en la capacidad de generalización, lo que podría indicar un <strong>leve sobreajuste</strong>.</p></li>
<li><p>A pesar de esta diferencia, el <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> sigue siendo relativamente alto, lo que sugiere que el modelo es razonablemente robusto y explica la mayor parte de la variabilidad en los salarios, tanto en los datos de entrenamiento como en los de prueba.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-r-2-ajustado">
<h5><strong>Posibles acciones para mejorar <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-r-2-ajustado" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Si deseas mejorar la capacidad de generalización del modelo, podrías aplicar técnicas de <strong>regularización</strong> como <strong>Ridge</strong> o <strong>Lasso</strong> para reducir el sobreajuste y mejorar el rendimiento en datos no vistos.</p></li>
<li><p>Implementar <strong>validación cruzada</strong> para tener una mejor estimación de la capacidad de generalización del modelo y asegurarse de que está optimizado para datos nuevos.</p></li>
<li><p>Explorar la adición de más características predictoras, si están disponibles, o aumentar el tamaño del conjunto de datos para mejorar aún más el ajuste y la generalización del modelo.</p></li>
</ul>
</section>
<section id="resumen-de-r-2-ajustado">
<h5><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:<a class="headerlink" href="#resumen-de-r-2-ajustado" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong><span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong> del conjunto de entrenamiento (0.9629) y el del conjunto de prueba (0.8781) muestran que el modelo tiene un buen ajuste en los datos de entrenamiento, pero podría estar ligeramente sobreajustado. A pesar de esto, el modelo sigue explicando una gran parte de la variabilidad en los salarios, incluso en los datos de prueba. Sin embargo, hay margen para mejorar la capacidad de generalización mediante regularización u otras técnicas.</p></li>
</ul>
</section>
</section>
<section id="error-medio-proporcional-absoluto-mape-mean-absolute-percentage-error">
<h4>6. <strong>Error Medio Proporcional Absoluto (<span class="math notranslate nohighlight">\(MAPE\)</span> - Mean Absolute Percentage Error)</strong><a class="headerlink" href="#error-medio-proporcional-absoluto-mape-mean-absolute-percentage-error" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(MAPE\)</span></strong> mide el error porcentual promedio entre los valores reales y los predichos, lo que permite interpretar el error en términos relativos.</p>
<p>Es útil para entender el error en términos porcentuales, lo que es valioso cuando las magnitudes de los datos varían mucho.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left| \frac{y_i - \hat{y}_i}{y_i} \right|
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Medio Proporcional (MAPE)</span>
<span class="n">mape_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span> <span class="o">/</span> <span class="n">y_train</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">mape_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">/</span> <span class="n">y_test</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set MAPE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mape_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MAPE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mape_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set MAPE: 6.7656
Test set MAPE: 7.7449
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-del-mape">
<h5><strong>Interpretación del MAPE</strong>:<a class="headerlink" href="#interpretacion-del-mape" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>¿Qué es el MAPE?</strong>:</p>
<ul class="simple">
<li><p>El <strong>MAPE</strong> mide el error porcentual medio absoluto entre los valores predichos y los valores reales. Indica el porcentaje promedio por el cual las predicciones del modelo difieren de los valores reales.</p></li>
<li><p>El <strong>MAPE</strong> se expresa como un porcentaje, por lo que un valor de <strong>6.77%</strong> en el conjunto de entrenamiento significa que, en promedio, las predicciones del modelo difieren un <strong>6.77%</strong> de los valores reales.</p></li>
</ul>
</li>
<li><p><strong>MAPE en el conjunto de entrenamiento</strong>:</p>
<ul class="simple">
<li><p>Un <strong>MAPE</strong> de <strong>6.77%</strong> en el conjunto de entrenamiento sugiere que el modelo tiene un error porcentual medio relativamente bajo en los datos con los que fue entrenado. En otras palabras, las predicciones del modelo en el conjunto de entrenamiento son bastante cercanas a los valores reales.</p></li>
<li><p>Un MAPE menor al 10% generalmente se considera un buen resultado, ya que implica que las predicciones están relativamente bien ajustadas a los valores reales.</p></li>
</ul>
</li>
<li><p><strong>MAPE en el conjunto de prueba</strong>:</p>
<ul class="simple">
<li><p>Un <strong>MAPE</strong> de <strong>7.74%</strong> en el conjunto de prueba sugiere que el modelo también predice con bastante precisión los valores de salario en datos no vistos, pero con un pequeño aumento en el error en comparación con los datos de entrenamiento.</p></li>
<li><p>Aunque hay una pequeña diferencia entre los valores de MAPE en el conjunto de entrenamiento y el de prueba, ambos valores son menores al 10%, lo que indica un buen desempeño del modelo.</p></li>
</ul>
</li>
<li><p><strong>Diferencia entre los MAPE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>La diferencia entre el <strong>MAPE</strong> del conjunto de entrenamiento (<strong>6.77%</strong>) y el del conjunto de prueba (<strong>7.74%</strong>) es relativamente pequeña. Esta diferencia sugiere que el modelo tiene una buena capacidad de generalización, ya que no hay un aumento significativo en el error porcentual cuando se aplican las predicciones a nuevos datos.</p></li>
<li><p>Aunque el <strong>MAPE</strong> en el conjunto de prueba es un poco mayor, lo cual es esperado, esta diferencia no es lo suficientemente grande como para ser preocupante.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-mape">
<h5><strong>Conclusiones de MAPE</strong>:<a class="headerlink" href="#conclusiones-de-mape" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Los valores de <strong>MAPE</strong> tanto en el conjunto de entrenamiento (<strong>6.77%</strong>) como en el conjunto de prueba (<strong>7.74%</strong>) son relativamente bajos, lo que indica que el modelo está haciendo predicciones precisas en ambas muestras.</p></li>
<li><p>La pequeña diferencia entre los <strong>MAPE</strong> sugiere que el modelo no está sobreajustado y tiene una buena capacidad para generalizar a nuevos datos.</p></li>
<li><p>En general, los valores obtenidos indican que el modelo es confiable para hacer predicciones de salario basadas en la experiencia, con un error porcentual medio bastante razonable.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-si-es-necesario-de-mape">
<h5><strong>Posibles acciones para mejorar (si es necesario) de MAPE</strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-si-es-necesario-de-mape" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Aunque los resultados son buenos, si se desea mejorar aún más la precisión del modelo, se podrían explorar las siguientes acciones:</p>
<ol class="arabic simple">
<li><p>Aplicar <strong>técnicas de regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para reducir cualquier posible sobreajuste residual.</p></li>
<li><p><strong>Aumentar el tamaño del conjunto de datos</strong> de entrenamiento o añadir más características predictoras relevantes, si están disponibles, para mejorar la precisión del modelo en datos no vistos.</p></li>
<li><p>Utilizar <strong>validación cruzada</strong> para asegurar una estimación robusta del rendimiento del modelo en diferentes divisiones de los datos.</p></li>
</ol>
</li>
</ul>
</section>
<section id="resumen-de-mape">
<h5><strong>Resumen de MAPE</strong>:<a class="headerlink" href="#resumen-de-mape" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>MAPE</strong> en el conjunto de entrenamiento es <strong>6.77%</strong>, mientras que en el conjunto de prueba es <strong>7.74%</strong>. Estos valores sugieren que el modelo tiene un buen rendimiento en ambas muestras, con una ligera disminución de precisión en los datos de prueba. En general, el modelo es robusto y las predicciones de salario basadas en la experiencia son razonablemente precisas, con un error porcentual medio bajo.</p></li>
</ul>
</section>
</section>
<section id="error-cuadratico-medio-de-logaritmo-msle-mean-squared-logarithmic-error">
<h4>7. <strong>Error Cuadrático Medio de Logaritmo (<span class="math notranslate nohighlight">\(MSLE\)</span> - Mean Squared Logarithmic Error)</strong><a class="headerlink" href="#error-cuadratico-medio-de-logaritmo-msle-mean-squared-logarithmic-error" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(MSLE\)</span></strong> es una variante del <span class="math notranslate nohighlight">\(MSE\)</span> que utiliza los logaritmos de los valores reales y predichos, en lugar de los valores originales.</p>
<p>Este se utiliza cuando se quiere penalizar más los errores de predicción en valores pequeños que en valores grandes.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
MSLE = \frac{1}{n} \sum_{i=1}^{n} \left( \log(1 + y_i) - \log(1 + \hat{y}_i) \right)^2,
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Cuadrático Medio de Logaritmo (MSLE)</span>
<span class="n">msle_train</span> <span class="o">=</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
<span class="n">msle_test</span> <span class="o">=</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set MSLE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msle_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set MSLE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msle_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set MSLE: 0.0075
Test set MSLE: 0.0082
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-msle">
<h5><strong>Interpretación de MSLE</strong>:<a class="headerlink" href="#interpretacion-de-msle" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>¿Qué es el MSLE?</strong>:</p>
<ul class="simple">
<li><p>El <strong>Error Cuadrático Medio Logarítmico (MSLE)</strong> mide el error entre los logaritmos de las predicciones y los logaritmos de los valores reales. Es especialmente útil cuando deseas penalizar menos los errores grandes en las predicciones relativas, ya que considera las proporciones entre las predicciones y los valores reales.</p></li>
<li><p>Un <strong>MSLE</strong> bajo, como los valores obtenidos aquí, indica que las predicciones del modelo están relativamente cerca de los valores reales en términos proporcionales.</p></li>
</ul>
</li>
<li><p><strong>MSLE en el conjunto de entrenamiento</strong>:</p>
<ul class="simple">
<li><p>Un <strong>MSLE</strong> de <strong>0.0075</strong> en el conjunto de entrenamiento sugiere que el modelo tiene un error logarítmico medio muy bajo. Esto significa que las diferencias entre los valores predichos y los valores reales, después de aplicar el logaritmo, son pequeñas.</p></li>
<li><p>El logaritmo suaviza las diferencias, lo que hace que este error sea útil cuando las diferencias relativas son importantes o cuando hay outliers en los datos.</p></li>
</ul>
</li>
<li><p><strong>MSLE en el conjunto de prueba</strong>:</p>
<ul class="simple">
<li><p>El <strong>MSLE</strong> de <strong>0.0082</strong> en el conjunto de prueba indica que el modelo también tiene un error bajo en los datos no vistos. Aunque este valor es ligeramente mayor que el del conjunto de entrenamiento, la diferencia es pequeña.</p></li>
<li><p>Este bajo valor del <strong>MSLE</strong> sugiere que el modelo está prediciendo de manera precisa incluso en datos que no ha visto antes.</p></li>
</ul>
</li>
<li><p><strong>Diferencia entre los MSLE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>La diferencia entre el <strong>MSLE</strong> del conjunto de entrenamiento (<strong>0.0075</strong>) y el del conjunto de prueba (<strong>0.0082</strong>) es mínima, lo que indica que el modelo tiene una buena capacidad de generalización y no muestra signos evidentes de sobreajuste (overfitting).</p></li>
<li><p>Esta pequeña diferencia es esperada, ya que los modelos suelen funcionar mejor en los datos con los que han sido entrenados, pero la diferencia aquí no es lo suficientemente grande como para ser preocupante.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-msle">
<h5><strong>Conclusiones de MSLE</strong>:<a class="headerlink" href="#conclusiones-de-msle" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Los valores bajos de <strong>MSLE</strong> en ambos conjuntos (entrenamiento y prueba) sugieren que el modelo es capaz de predecir los valores con un alto grado de precisión en términos relativos, incluso cuando se consideran errores grandes.</p></li>
<li><p>La pequeña diferencia entre el <strong>MSLE</strong> de entrenamiento y prueba sugiere que el modelo tiene una <strong>buena capacidad de generalización</strong> y está funcionando bien tanto en los datos de entrenamiento como en los datos no vistos.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-de-msle">
<h5><strong>Posibles acciones para mejorar de MSLE</strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-de-msle" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Aunque los resultados son buenos, si se busca mejorar aún más la precisión del modelo, se pueden considerar las siguientes acciones:</p>
<ol class="arabic simple">
<li><p>Aplicar técnicas de <strong>regularización</strong> (como <strong>Ridge</strong> o <strong>Lasso</strong>) para reducir cualquier posible sobreajuste residual.</p></li>
<li><p>Explorar más variables predictoras, si están disponibles, para mejorar la precisión del modelo y reducir aún más el error.</p></li>
<li><p><strong>Validación cruzada</strong> podría ser útil para obtener una mejor estimación de la capacidad de generalización del modelo en diferentes divisiones de los datos.</p></li>
</ol>
</li>
</ul>
</section>
<section id="resumen-de-msle">
<h5><strong>Resumen de MSLE</strong>:<a class="headerlink" href="#resumen-de-msle" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>MSLE</strong> en el conjunto de entrenamiento es <strong>0.0075</strong>, mientras que en el conjunto de prueba es <strong>0.0082</strong>. Estos valores bajos sugieren que el modelo está haciendo predicciones precisas tanto en los datos de entrenamiento como en los de prueba. La diferencia mínima entre ambos valores indica una <strong>buena capacidad de generalización</strong>, y el modelo es sólido en cuanto a su rendimiento en datos no vistos.</p></li>
</ul>
</section>
</section>
<section id="error-relativo-absoluto-rae-relative-absolute-error">
<h4>8. <strong>Error Relativo Absoluto (<span class="math notranslate nohighlight">\(RAE\)</span> - Relative Absolute Error)</strong><a class="headerlink" href="#error-relativo-absoluto-rae-relative-absolute-error" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(RAE\)</span></strong> compara el error absoluto del modelo con el error absoluto de un modelo de referencia, que usualmente es el modelo que predice el valor medio de la variable dependiente.</p>
<p>Este evalúa el rendimiento relativo del modelo comparado con una solución trivial.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RAE = \frac{\sum_{i=1}^{n} |y_i - \hat{y}_i|}{\sum_{i=1}^{n} |y_i - \bar{y}|},
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{y}\)</span> es el promedio de los valores reales.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Relativo Absoluto (RAE)</span>
<span class="n">rae_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
<span class="n">rae_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_test</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set RAE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rae_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set RAE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rae_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set RAE: 0.1684
Test set RAE: 0.3139
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-rae">
<h5><strong>Interpretación de RAE</strong>:<a class="headerlink" href="#interpretacion-de-rae" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>¿Qué es el RAE?</strong>:</p>
<ul class="simple">
<li><p>El <strong>Error Relativo Absoluto (RAE)</strong> mide la suma de los errores absolutos de las predicciones en relación con la suma de los errores absolutos de un modelo simple que predice la media de los valores reales. En resumen, compara el rendimiento del modelo con un modelo base.</p></li>
<li><p>Un valor de <strong>RAE</strong> más cercano a 0 indica que el modelo tiene un buen rendimiento en comparación con el modelo base. Cuanto más se acerque a 1, peor es el rendimiento relativo del modelo.</p></li>
</ul>
</li>
<li><p><strong>RAE en el conjunto de entrenamiento</strong>:</p>
<ul class="simple">
<li><p>Un <strong>RAE</strong> de <strong>0.1684</strong> en el conjunto de entrenamiento significa que el modelo está cometiendo un error absoluto aproximadamente <strong>16.84%</strong> del error que cometería un modelo que simplemente predijera la media de los valores de entrenamiento. Este es un resultado muy bueno, ya que sugiere que el modelo es significativamente mejor que predecir simplemente la media.</p></li>
</ul>
</li>
<li><p><strong>RAE en el conjunto de prueba</strong>:</p>
<ul class="simple">
<li><p>El <strong>RAE</strong> de <strong>0.3139</strong> en el conjunto de prueba indica que el modelo está cometiendo un error absoluto aproximadamente <strong>31.39%</strong> del error que cometería un modelo que simplemente predijera la media de los valores de prueba.</p></li>
<li><p>Aunque este valor sigue siendo bueno (ya que está lejos de 1), es mayor que el <strong>RAE</strong> en el conjunto de entrenamiento, lo que sugiere que el modelo es un poco menos efectivo en los datos de prueba que en los de entrenamiento.</p></li>
</ul>
</li>
<li><p><strong>Diferencia entre los RAE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>La diferencia entre el <strong>RAE</strong> del conjunto de entrenamiento (<strong>0.1684</strong>) y el del conjunto de prueba (<strong>0.3139</strong>) es notable. Esto sugiere que el modelo tiene un rendimiento considerablemente mejor en los datos de entrenamiento que en los datos de prueba, lo que podría ser una señal de <strong>sobreajuste</strong> (overfitting).</p></li>
<li><p>El hecho de que el <strong>RAE</strong> sea mayor en el conjunto de prueba sugiere que el modelo está capturando detalles específicos del conjunto de entrenamiento que no se replican bien en los nuevos datos.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-rae">
<h5><strong>Conclusiones de RAE</strong>:<a class="headerlink" href="#conclusiones-de-rae" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>RAE</strong> del conjunto de entrenamiento es bajo (<strong>0.1684</strong>), lo que indica que el modelo está funcionando significativamente mejor que un modelo que predijera simplemente la media de los valores reales.</p></li>
<li><p>El <strong>RAE</strong> del conjunto de prueba es mayor (<strong>0.3139</strong>), lo que sugiere que el modelo no generaliza tan bien a los nuevos datos como lo hace en el conjunto de entrenamiento. A pesar de esto, el modelo sigue teniendo un rendimiento relativamente bueno en comparación con un modelo base.</p></li>
<li><p>La diferencia entre los <strong>RAE</strong> de entrenamiento y prueba indica que el modelo podría estar <strong>sobreajustado</strong> a los datos de entrenamiento y necesita mejorar su capacidad de generalización.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-de-rae">
<h5><strong>Posibles acciones para mejorar de RAE</strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-de-rae" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Aplicar regularización</strong>: Utilizar técnicas de regularización como <strong>Ridge</strong> o <strong>Lasso</strong> para reducir el sobreajuste y mejorar la capacidad de generalización del modelo en los datos de prueba.</p></li>
<li><p><strong>Validación cruzada</strong>: Implementar validación cruzada para obtener una estimación más robusta del rendimiento del modelo en diferentes particiones de los datos.</p></li>
<li><p><strong>Añadir más datos</strong>: Si es posible, aumentar el tamaño del conjunto de datos de entrenamiento podría ayudar a mejorar la capacidad del modelo para generalizar a nuevos datos.</p></li>
</ol>
</section>
<section id="resumen-de-rae">
<h5><strong>Resumen de RAE</strong>:<a class="headerlink" href="#resumen-de-rae" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>RAE</strong> en el conjunto de entrenamiento es <strong>0.1684</strong>, lo que sugiere un buen ajuste a los datos de entrenamiento, mientras que el <strong>RAE</strong> en el conjunto de prueba es <strong>0.3139</strong>, lo que indica un rendimiento un poco peor en datos no vistos.</p></li>
<li><p>La diferencia entre estos valores sugiere que el modelo está capturando patrones específicos de los datos de entrenamiento y no generaliza tan bien en datos nuevos, lo que podría indicar un <strong>leve sobreajuste</strong>. Para mejorar, se podrían aplicar técnicas de regularización o validación cruzada.</p></li>
</ul>
</section>
</section>
<section id="error-cuadratico-relativo-rse-relative-squared-error">
<h4>9. <strong>Error Cuadrático Relativo (<span class="math notranslate nohighlight">\(RSE\)</span> - Relative Squared Error)</strong><a class="headerlink" href="#error-cuadratico-relativo-rse-relative-squared-error" title="Permalink to this heading">#</a></h4>
<p>El <strong><span class="math notranslate nohighlight">\(RSE\)</span></strong> compara el error cuadrático del modelo con el error cuadrático de un modelo de referencia (generalmente el promedio de los valores reales).</p>
<p>Similar al <span class="math notranslate nohighlight">\(RAE\)</span>, compara el rendimiento del modelo frente a un predictor básico.</p>
<ul class="simple">
<li><p><strong>Fórmula</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
RSE = \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2},
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span> es el número total de observaciones,</p></li>
<li><p><span class="math notranslate nohighlight">\(y_i\)</span> son los valores reales,</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i\)</span> son los valores predichos.</p></li>
<li><p><span class="math notranslate nohighlight">\(\bar{y}\)</span> es el promedio de los valores reales.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Error Cuadrático Relativo (RSE)</span>
<span class="n">rse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_train</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">modelo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set RSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rse_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set RSE: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rse_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set RSE: 0.0355
Test set RSE: 0.0976
</pre></div>
</div>
</div>
</div>
<section id="interpretacion-de-rse">
<h5><strong>Interpretación de RSE</strong>:<a class="headerlink" href="#interpretacion-de-rse" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>¿Qué es el RSE?</strong>:</p>
<ul class="simple">
<li><p>El <strong>Error Cuadrático Relativo (RSE)</strong> mide el error cuadrático de las predicciones en relación con el error cuadrático de un modelo simple que predice la media de los valores reales. Al igual que el <strong>RAE</strong>, el <strong>RSE</strong> compara el rendimiento del modelo con un modelo base que predice la media.</p></li>
<li><p>Un valor de <strong>RSE</strong> más cercano a 0 indica que el modelo está funcionando mucho mejor que un modelo base, mientras que un valor más cercano a 1 indica que el modelo tiene un rendimiento comparable al de un modelo base.</p></li>
</ul>
</li>
<li><p><strong>RSE en el conjunto de entrenamiento</strong>:</p>
<ul class="simple">
<li><p>Un <strong>RSE</strong> de <strong>0.0355</strong> en el conjunto de entrenamiento significa que el modelo está cometiendo un error cuadrático que es aproximadamente el <strong>3.55%</strong> del error que cometería un modelo que predijera simplemente la media de los salarios en los datos de entrenamiento.</p></li>
<li><p>Este valor extremadamente bajo indica que el modelo tiene un rendimiento significativamente mejor que el modelo base en el conjunto de entrenamiento, ajustándose muy bien a los datos.</p></li>
</ul>
</li>
<li><p><strong>RSE en el conjunto de prueba</strong>:</p>
<ul class="simple">
<li><p>Un <strong>RSE</strong> de <strong>0.0976</strong> en el conjunto de prueba indica que el modelo está cometiendo un error cuadrático que es aproximadamente el <strong>9.76%</strong> del error que cometería un modelo que simplemente predijera la media de los salarios en los datos de prueba.</p></li>
<li><p>Aunque este valor sigue siendo bajo, es considerablemente mayor que el <strong>RSE</strong> en el conjunto de entrenamiento, lo que sugiere que el modelo no tiene el mismo nivel de precisión en los datos no vistos.</p></li>
</ul>
</li>
<li><p><strong>Diferencia entre los RSE de entrenamiento y prueba</strong>:</p>
<ul class="simple">
<li><p>La diferencia entre el <strong>RSE</strong> del conjunto de entrenamiento (<strong>0.0355</strong>) y el del conjunto de prueba (<strong>0.0976</strong>) indica que el modelo está funcionando mejor en los datos de entrenamiento que en los datos de prueba, lo que sugiere un posible <strong>sobreajuste</strong> (overfitting).</p></li>
<li><p>Aunque el <strong>RSE</strong> en el conjunto de prueba sigue siendo bajo, esta diferencia sugiere que el modelo ha aprendido patrones específicos de los datos de entrenamiento que no generalizan tan bien a los datos de prueba.</p></li>
</ul>
</li>
</ol>
</section>
<section id="conclusiones-de-rse">
<h5><strong>Conclusiones de RSE</strong>:<a class="headerlink" href="#conclusiones-de-rse" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>RSE</strong> del conjunto de entrenamiento es muy bajo (<strong>0.0355</strong>), lo que indica que el modelo tiene un rendimiento significativamente mejor que un modelo que predice la media de los salarios en esos datos.</p></li>
<li><p>El <strong>RSE</strong> del conjunto de prueba es mayor (<strong>0.0976</strong>), pero sigue siendo bajo, lo que sugiere que el modelo sigue siendo mejor que un modelo base en los datos de prueba, aunque con menor precisión en comparación con los datos de entrenamiento.</p></li>
<li><p>La diferencia entre los <strong>RSE</strong> de entrenamiento y prueba indica un posible <strong>sobreajuste</strong>, donde el modelo ha aprendido patrones específicos de los datos de entrenamiento que no se replican bien en los datos no vistos.</p></li>
</ul>
</section>
<section id="posibles-acciones-para-mejorar-de-rse">
<h5><strong>Posibles acciones para mejorar de RSE</strong>:<a class="headerlink" href="#posibles-acciones-para-mejorar-de-rse" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Aplicar regularización</strong>: Utilizar técnicas de regularización como <strong>Ridge</strong> o <strong>Lasso</strong> podría ayudar a reducir el sobreajuste y mejorar la capacidad del modelo para generalizar a nuevos datos.</p></li>
<li><p><strong>Validación cruzada</strong>: Implementar validación cruzada para evaluar mejor el rendimiento del modelo y optimizar su capacidad de generalización en diferentes subconjuntos de los datos.</p></li>
<li><p><strong>Añadir más datos</strong>: Si es posible, aumentar el tamaño del conjunto de entrenamiento o explorar otras características predictoras para mejorar aún más la precisión y capacidad de generalización del modelo.</p></li>
</ol>
</section>
<section id="resumen-de-rse">
<h5><strong>Resumen de RSE</strong>:<a class="headerlink" href="#resumen-de-rse" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>El <strong>RSE</strong> en el conjunto de entrenamiento es <strong>0.0355</strong>, lo que sugiere que el modelo se ajusta muy bien a los datos de entrenamiento. El <strong>RSE</strong> en el conjunto de prueba es <strong>0.0976</strong>, lo que indica que el modelo tiene un buen rendimiento en los datos no vistos, pero con una precisión algo menor.</p></li>
<li><p>La diferencia entre los <strong>RSE</strong> sugiere que el modelo podría estar <strong>ligeramente sobreajustado</strong>, pero sigue siendo significativamente mejor que un modelo base que predice simplemente la media de los valores de salario.</p></li>
</ul>
<p>Estas métricas permiten evaluar de manera precisa el rendimiento de los modelos de regresión. Dependiendo de la naturaleza del problema y de los objetivos del proyecto, se puede elegir una o varias métricas para obtener una visión completa del ajuste del modelo.</p>
</section>
</section>
<section id="regresion-lineal-con-la-libreria-statsmodels">
<h4><strong>Regresión Lineal con la librería Statsmodels</strong><a class="headerlink" href="#regresion-lineal-con-la-libreria-statsmodels" title="Permalink to this heading">#</a></h4>
<p>La implementación de <strong>regresión lineal</strong> en <strong>Statsmodels</strong> es más completa que la de <strong>Scikit-learn</strong>, ya que, además de ajustar el modelo, permite calcular pruebas estadísticas y realizar análisis necesarios para verificar que se cumplen las condiciones sobre las que se basa este tipo de modelos. Esto la convierte en una herramienta más robusta para el análisis de regresión.</p>
<div class="note admonition">
<p class="admonition-title">Ventajas de Statsmodels</p>
<ul class="simple">
<li><p><strong>Pruebas estadísticas</strong>: Permite realizar pruebas como el análisis de varianza (ANOVA), pruebas de significancia de los coeficientes, e intervalos de confianza para los parámetros del modelo.</p></li>
<li><p><strong>Análisis de residuales</strong>: Facilita el análisis de los residuos, permitiendo evaluar si el modelo cumple con los supuestos de homocedasticidad, normalidad de los errores, entre otros.</p></li>
</ul>
</div>
<section id="formas-de-entrenar-un-modelo-de-regresion-en-statsmodels">
<h5><strong>Formas de entrenar un modelo de regresión en Statsmodels</strong>:<a class="headerlink" href="#formas-de-entrenar-un-modelo-de-regresion-en-statsmodels" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Indicando la fórmula del modelo</strong>:</p>
<ul class="simple">
<li><p>En esta forma, se especifica la fórmula del modelo (similar a cómo se hace en <strong>R</strong>) y se pasan los datos de entrenamiento como un DataFrame que incluye tanto la variable respuesta como los predictores.</p></li>
<li><p>Ejemplo de uso:</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># datos train</span>
<span class="n">datos_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># construcción del modelo</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s1">&#39;Salary ~ YearsExperience&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">datos_train</span><span class="p">)</span>
<span class="n">resultado</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resultado</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Salary   R-squared:                       0.965
Model:                            OLS   Adj. R-squared:                  0.963
Method:                 Least Squares   F-statistic:                     598.4
Date:                Wed, 16 Oct 2024   Prob (F-statistic):           1.91e-17
Time:                        18:54:38   Log-Likelihood:                -239.44
No. Observations:                  24   AIC:                             482.9
Df Residuals:                      22   BIC:                             485.2
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
Intercept        2.532e+04   2285.938     11.077      0.000    2.06e+04    3.01e+04
YearsExperience  9423.8153    385.233     24.463      0.000    8624.891    1.02e+04
==============================================================================
Omnibus:                        0.647   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.724   Jarque-Bera (JB):                0.697
Skew:                           0.323   Prob(JB):                        0.706
Kurtosis:                       2.472   Cond. No.                         12.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>Pasando matrices de predictores y la variable respuesta</strong>:</p>
<ul class="simple">
<li><p>En este enfoque, se pasa una matriz con los predictores y otra con la variable respuesta, similar a cómo se hace en <strong>Scikit-learn</strong>. Sin embargo, en <strong>Statsmodels</strong> es necesario añadir manualmente una columna de unos (<code class="docutils literal notranslate"><span class="pre">1s</span></code>) a la matriz de predictores para incluir el término independiente (intercepto) en el modelo.</p></li>
<li><p>Ejemplo de uso:</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importar la libreria</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># construcción del modelo</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Añadir la columna de 1s para el intercepto</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">endog</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">modelo</span> <span class="o">=</span> <span class="n">modelo</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">modelo</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Salary   R-squared:                       0.965
Model:                            OLS   Adj. R-squared:                  0.963
Method:                 Least Squares   F-statistic:                     598.4
Date:                Wed, 16 Oct 2024   Prob (F-statistic):           1.91e-17
Time:                        18:58:57   Log-Likelihood:                -239.44
No. Observations:                  24   AIC:                             482.9
Df Residuals:                      22   BIC:                             485.2
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
===================================================================================
                      coef    std err          t      P&gt;|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const            2.532e+04   2285.938     11.077      0.000    2.06e+04    3.01e+04
YearsExperience  9423.8153    385.233     24.463      0.000    8624.891    1.02e+04
==============================================================================
Omnibus:                        0.647   Durbin-Watson:                   2.026
Prob(Omnibus):                  0.724   Jarque-Bera (JB):                0.697
Skew:                           0.323   Prob(JB):                        0.706
Kurtosis:                       2.472   Cond. No.                         12.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
</pre></div>
</div>
</div>
</div>
</section>
<section id="resultados-de-la-regresion-lineal-ols">
<h5><strong>Resultados de la Regresión Lineal (OLS)</strong><a class="headerlink" href="#resultados-de-la-regresion-lineal-ols" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Estadísticos del Modelo</strong>:</p></li>
</ol>
<ul class="simple">
<li><p><strong>R-squared (R²)</strong>: 0.965</p>
<ul>
<li><p>El modelo explica el <strong>96.5%</strong> de la variabilidad en el salario en función de los años de experiencia. Esto indica un <strong>buen ajuste</strong> del modelo a los datos.</p></li>
</ul>
</li>
<li><p><strong>Adjusted R-squared (R² ajustado)</strong>: 0.963</p>
<ul>
<li><p>El <strong>R² ajustado</strong> es ligeramente menor que el R², lo que es normal, ya que penaliza la inclusión de variables adicionales. En este caso, la diferencia es mínima, ya que solo tenemos un predictor.</p></li>
</ul>
</li>
<li><p><strong>F-statistic</strong>: 598.4</p>
<ul>
<li><p>La estadística <strong>F</strong> mide si el modelo en su conjunto es significativo. Un valor alto, como en este caso, sugiere que el modelo es válido y que la relación entre la variable dependiente (salario) y la independiente (años de experiencia) es estadísticamente significativa.</p></li>
</ul>
</li>
<li><p><strong>Prob(F-statistic)</strong>: 1.91e-17</p>
<ul>
<li><p>El valor p asociado con la estadística <strong>F</strong> es extremadamente pequeño (<strong>1.91e-17</strong>), lo que indica que es altamente improbable que el modelo en su conjunto sea insignificante. Esto refuerza la idea de que el modelo es significativo.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Coeficientes del Modelo</strong>:</p></li>
</ol>
<ul class="simple">
<li><p><strong>Intercepto (const)</strong>: 25,320.53</p>
<ul>
<li><p>El salario base estimado para alguien con <strong>0 años de experiencia</strong> es de <strong>25,320.53</strong> unidades monetarias. Este es el valor esperado cuando <strong>YearsExperience</strong> es igual a 0.</p></li>
</ul>
</li>
<li><p><strong>YearsExperience</strong>: 9423.82</p>
<ul>
<li><p>El coeficiente para <strong>YearsExperience</strong> indica que, por cada año adicional de experiencia, el salario aumenta en <strong>9,423.82</strong> unidades monetarias, en promedio, manteniendo todas las demás variables constantes.</p></li>
</ul>
</li>
<li><p><strong>Valores P (P&gt;|t|)</strong>:</p>
<ul>
<li><p>Tanto el intercepto como el coeficiente de <strong>YearsExperience</strong> tienen valores p extremadamente bajos (<strong>0.000</strong>), lo que indica que ambos son <strong>estadísticamente significativos</strong>. Esto significa que tanto el salario base como el aumento en salario asociado con cada año adicional de experiencia son diferentes de cero con un nivel de confianza muy alto.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Intervalos de Confianza</strong>:</p></li>
</ol>
<ul class="simple">
<li><p><strong>[0.025, 0.975] para el Intercepto</strong>: [20,600, 30,100]</p>
<ul>
<li><p>Esto significa que, con un 95% de confianza, el salario base para alguien con 0 años de experiencia está entre <strong>20,600</strong> y <strong>30,100</strong> unidades monetarias.</p></li>
</ul>
</li>
<li><p><strong>[0.025, 0.975] para YearsExperience</strong>: [8,625, 10,223]</p>
<ul>
<li><p>Para <strong>YearsExperience</strong>, se puede decir con un 95% de confianza que el incremento en salario por cada año adicional de experiencia está entre <strong>8,625</strong> y <strong>10,223</strong> unidades monetarias.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="4">
<li><p><strong>Pruebas de Supuestos del Modelo</strong>:</p></li>
</ol>
<ul class="simple">
<li><p><strong>Durbin-Watson</strong>: 2.026</p>
<ul>
<li><p>Este estadístico mide la autocorrelación de los residuos. Un valor cercano a <strong>2</strong> (como en este caso) indica que no hay autocorrelación significativa en los errores.</p></li>
</ul>
</li>
<li><p><strong>Omnibus Prob(Omnibus)</strong>: 0.724</p>
<ul>
<li><p>Esta prueba evalúa si los residuos del modelo se distribuyen de forma normal. Un valor p de <strong>0.724</strong> indica que no hay evidencia significativa de que los residuos se desvíen de la normalidad.</p></li>
</ul>
</li>
<li><p><strong>Jarque-Bera (Prob JB)</strong>: 0.706</p>
<ul>
<li><p>Al igual que el estadístico <strong>Omnibus</strong>, esta prueba evalúa la normalidad de los residuos. Un valor p de <strong>0.706</strong> también sugiere que no hay evidencia de que los residuos se desvíen de una distribución normal.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Cond. No. (Número de Condición)</strong>: 12.5</p></li>
</ol>
<ul class="simple">
<li><p>El número de condición es una medida de la multicolinealidad. Un valor menor de <strong>30</strong> sugiere que no hay problemas de multicolinealidad, lo cual es lógico ya que solo hay una variable independiente en el modelo.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p><strong>Conclusiones</strong>:</p></li>
</ol>
<ul class="simple">
<li><p>El modelo tiene un <strong>buen ajuste</strong> a los datos, ya que el <strong>R²</strong> es alto (<strong>96.5%</strong>).</p></li>
<li><p>Tanto el <strong>intercepto</strong> como el <strong>coeficiente de YearsExperience</strong> son <strong>estadísticamente significativos</strong>, lo que indica que la experiencia tiene un impacto claro y positivo en los salarios.</p></li>
<li><p>Los <strong>residuos</strong> del modelo parecen ser <strong>normales</strong> y no presentan problemas de autocorrelación, como lo indican las pruebas de <strong>Durbin-Watson</strong>, <strong>Omnibus</strong> y <strong>Jarque-Bera</strong>.</p></li>
<li><p>En general, el modelo es <strong>válido y robusto</strong>, y se puede concluir que los años de experiencia explican gran parte de la variación en los salarios.</p></li>
</ul>
</section>
<section id="comparacion-con-scikit-learn">
<h5><strong>Comparación con Scikit-learn</strong><a class="headerlink" href="#comparacion-con-scikit-learn" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p><strong>Scikit-learn</strong> está más orientado a la predicción y es ideal para construir modelos de regresión de forma rápida y eficiente, sin tener que preocuparse por el análisis estadístico detallado.</p></li>
<li><p><strong>Statsmodels</strong>, en cambio, está más orientado al análisis estadístico completo, proporcionando una visión detallada del ajuste del modelo y permitiendo realizar pruebas estadísticas y análisis de residuales de manera sencilla.</p></li>
</ul>
</section>
<section id="conclusion">
<h5><strong>Conclusión</strong><a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h5>
<p>Si solo necesitas ajustar un modelo de regresión lineal rápidamente para hacer predicciones, <strong>Scikit-learn</strong> es una excelente opción. Sin embargo, si necesitas realizar un análisis estadístico completo del modelo, incluyendo pruebas de significancia y validación de los supuestos del modelo, <strong>Statsmodels</strong> es una herramienta más adecuada.</p>
</section>
</section>
</section>
<section id="regresion-lineal-multiple">
<h3><strong>Regresión lineal multiple</strong><a class="headerlink" href="#regresion-lineal-multiple" title="Permalink to this heading">#</a></h3>
<p>En este ejemplo, utilizaremos el conjunto de datos <code class="docutils literal notranslate"><span class="pre">California</span> <span class="pre">Housing</span> <span class="pre">Prices.csv</span></code>, que consta de 20.640 instancias. Cada instancia representa una unidad residencial en el estado de California y contiene 10 atributos, incluyendo la variable objetivo. Los atributos se definen de la siguiente manera:</p>
<ul class="simple">
<li><p><strong>Objetivo General</strong>:
Desarrollar un modelo de predicción que estime el <strong>valor medio de las viviendas</strong> en diferentes áreas de California, utilizando características socioeconómicas y geográficas, con el fin de proporcionar una herramienta que apoye la toma de decisiones en el sector inmobiliario y facilite la planificación urbana.</p></li>
</ul>
<section id="importar-las-librerias-necesarias">
<h4>1. <strong>Importar las librerías necesarias</strong><a class="headerlink" href="#importar-las-librerias-necesarias" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="lectura-de-los-datos">
<h4>2. <strong>Lectura de los datos</strong><a class="headerlink" href="#lectura-de-los-datos" title="Permalink to this heading">#</a></h4>
<p>El conjunto de datos de <em>Boston Housing Price.</em> Puede ver que estamos especificando los nombres cortos para cada atributo para que podamos referenciarlos claramente más adelante. También puede ver que los atributos están delimitados por espacios en blanco en lugar de comas en este archivo e indicamos esto a la función <code class="docutils literal notranslate"><span class="pre">read_csv()</span></code> a través del argumento <code class="docutils literal notranslate"><span class="pre">delim.whitespace</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/Users/cdeor/OneDrive/Documentos/MachineLearningDipSerfinanzas/jbook_ml202430/docs/_data/dataml/housing.csv&quot;</span><span class="p">)</span>

<span class="c1"># Mostrar las primeras filas del conjunto de datos</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Las variables del conjunto de datos son</p>
<ul class="simple">
<li><p><strong>longitude</strong>: Coordenada de longitud de la ubicación de la vivienda.</p></li>
<li><p><strong>latitude</strong>: Coordenada de latitud de la ubicación de la vivienda.</p></li>
<li><p><strong>housing_median_age</strong>: Edad media de las casas en la zona.</p></li>
<li><p><strong>total_rooms</strong>: Número total de habitaciones en las casas de la zona.</p></li>
<li><p><strong>total_bedrooms</strong>: Número total de dormitorios en las casas de la zona.</p></li>
<li><p><strong>population</strong>: Población total de la zona.</p></li>
<li><p><strong>households</strong>: Número total de hogares en la zona.</p></li>
<li><p><strong>median_income</strong>: Ingreso medio de los hogares en la zona (en decenas de miles de dólares).</p></li>
<li><p><strong>median_house_value</strong>: Valor medio de las casas en la zona (en dólares).</p></li>
<li><p><strong>ocean_proximity</strong>: Proximidad del área al océano.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar las ultimas filas del conjunto de datos</span>
<span class="n">df</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>20635</th>
      <td>-121.09</td>
      <td>39.48</td>
      <td>25.0</td>
      <td>1665.0</td>
      <td>374.0</td>
      <td>845.0</td>
      <td>330.0</td>
      <td>1.5603</td>
      <td>78100.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20636</th>
      <td>-121.21</td>
      <td>39.49</td>
      <td>18.0</td>
      <td>697.0</td>
      <td>150.0</td>
      <td>356.0</td>
      <td>114.0</td>
      <td>2.5568</td>
      <td>77100.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20637</th>
      <td>-121.22</td>
      <td>39.43</td>
      <td>17.0</td>
      <td>2254.0</td>
      <td>485.0</td>
      <td>1007.0</td>
      <td>433.0</td>
      <td>1.7000</td>
      <td>92300.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20638</th>
      <td>-121.32</td>
      <td>39.43</td>
      <td>18.0</td>
      <td>1860.0</td>
      <td>409.0</td>
      <td>741.0</td>
      <td>349.0</td>
      <td>1.8672</td>
      <td>84700.0</td>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>20639</th>
      <td>-121.24</td>
      <td>39.37</td>
      <td>16.0</td>
      <td>2785.0</td>
      <td>616.0</td>
      <td>1387.0</td>
      <td>530.0</td>
      <td>2.3886</td>
      <td>89400.0</td>
      <td>INLAND</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Información de las variables</span>
<span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># dimensión del conjunto de datos</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(20640, 10)
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h4>3. <strong>Datos faltantes o NANs</strong><a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_values</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">total_rows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">missing_vars</span> <span class="o">=</span> <span class="n">missing_values</span><span class="p">[</span><span class="n">missing_values</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">missing_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Datos faltantes&#39;</span><span class="p">:</span> <span class="n">missing_vars</span><span class="p">,</span>
    <span class="s1">&#39;Porcentaje (%)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">((</span><span class="n">missing_vars</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)})</span>

<span class="n">missing_info_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datos faltantes</th>
      <th>Porcentaje (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>total_bedrooms</th>
      <td>207</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Podemos observar que existen datos faltantes para nuestro atríbuto <code class="docutils literal notranslate"><span class="pre">total_bedromms</span></code>. Procedemos a realizar imputación a reemplazando los valores <code class="docutils literal notranslate"><span class="pre">NaN</span></code> por la media.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">df2</span><span class="p">[</span><span class="s1">&#39;total_bedrooms&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;total_bedrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;total_bedrooms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Verificamos nuevamente la existencia de datos faltantes a tráves de la función <code class="docutils literal notranslate"><span class="pre">info()</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df2</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20640 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
</pre></div>
</div>
</div>
</div>
</section>
<section id="resumen-estadistico">
<h4>4. <strong>Resumen estadístico.</strong><a class="headerlink" href="#resumen-estadistico" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Variable de objetivo con las predictoras (numéricas)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># descriptiva</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.precision&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>20640.0</td>
      <td>-119.57</td>
      <td>2.00</td>
      <td>-124.35</td>
      <td>-121.80</td>
      <td>-118.49</td>
      <td>-118.01</td>
      <td>-114.31</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>20640.0</td>
      <td>35.63</td>
      <td>2.14</td>
      <td>32.54</td>
      <td>33.93</td>
      <td>34.26</td>
      <td>37.71</td>
      <td>41.95</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>20640.0</td>
      <td>28.64</td>
      <td>12.59</td>
      <td>1.00</td>
      <td>18.00</td>
      <td>29.00</td>
      <td>37.00</td>
      <td>52.00</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>20640.0</td>
      <td>2635.76</td>
      <td>2181.62</td>
      <td>2.00</td>
      <td>1447.75</td>
      <td>2127.00</td>
      <td>3148.00</td>
      <td>39320.00</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>20640.0</td>
      <td>537.87</td>
      <td>419.27</td>
      <td>1.00</td>
      <td>297.00</td>
      <td>438.00</td>
      <td>643.25</td>
      <td>6445.00</td>
    </tr>
    <tr>
      <th>population</th>
      <td>20640.0</td>
      <td>1425.48</td>
      <td>1132.46</td>
      <td>3.00</td>
      <td>787.00</td>
      <td>1166.00</td>
      <td>1725.00</td>
      <td>35682.00</td>
    </tr>
    <tr>
      <th>households</th>
      <td>20640.0</td>
      <td>499.54</td>
      <td>382.33</td>
      <td>1.00</td>
      <td>280.00</td>
      <td>409.00</td>
      <td>605.00</td>
      <td>6082.00</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>20640.0</td>
      <td>3.87</td>
      <td>1.90</td>
      <td>0.50</td>
      <td>2.56</td>
      <td>3.53</td>
      <td>4.74</td>
      <td>15.00</td>
    </tr>
    <tr>
      <th>median_house_value</th>
      <td>20640.0</td>
      <td>206855.82</td>
      <td>115395.62</td>
      <td>14999.00</td>
      <td>119600.00</td>
      <td>179700.00</td>
      <td>264725.00</td>
      <td>500001.00</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Variable predictora (categórica)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Descriptivo de una sola variable categórica solo conteo</span>
<span class="n">conteo</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Descriptivo de una sola variable categórica solo proporcion</span>
<span class="n">proporciones</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Combinar los resultados en un solo DataFrame</span>
<span class="n">resultado</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Conteo&#39;</span><span class="p">:</span> <span class="n">conteo</span><span class="p">,</span>
    <span class="s1">&#39;Proporción&#39;</span><span class="p">:</span> <span class="n">proporciones</span>
<span class="p">})</span>

<span class="c1"># imprimir</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.precision&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">resultado</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                 Conteo  Proporción
ocean_proximity                    
&lt;1H OCEAN          9136      0.4426
INLAND             6551      0.3174
NEAR OCEAN         2658      0.1288
NEAR BAY           2290      0.1109
ISLAND                5      0.0002
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizacion-del-conjunto-de-datos">
<h4>5. <strong>Visualización del conjunto de datos</strong><a class="headerlink" href="#visualizacion-del-conjunto-de-datos" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Variables numéricas</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ignorar advertencias de futuras versiones</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 

<span class="c1"># Extrayendo las variables numéricas del dataset</span>
<span class="n">numerical_columns</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">,</span> <span class="s1">&#39;int64&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span>

<span class="c1"># Ajustar el estilo de Seaborn y el color verde para los gráficos</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.4</span><span class="p">)</span>

<span class="c1"># Crear gráficos de histograma con densidad (KDE) y diagrama de cajas con asimetría y curtosis en color verde</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">numerical_columns</span><span class="p">:</span>
    <span class="c1"># Imprimir asimetría y curtosis</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Columna: &#39;</span><span class="p">,</span> <span class="n">column</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Asimetría (Skew):&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">skew</span><span class="p">(),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Curtosis:&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">kurtosis</span><span class="p">(),</span> <span class="mi">2</span><span class="p">))</span>
    
    <span class="c1"># Crear figura</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    
    <span class="c1"># Subplot para el histograma con KDE (curva de densidad)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df2</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histograma de </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="c1"># Subplot para el diagrama de cajas</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df2</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Diagrama de cajas de </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="c1"># Mostrar la figura con los gráficos</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  longitude
Asimetría (Skew): -0.3
Curtosis: -1.33
</pre></div>
</div>
<img alt="_images/a148df0b017ee0a8b4baa15094e13ee0a3c66dbd8e74685cfffa92b0cd98b0d4.png" src="_images/a148df0b017ee0a8b4baa15094e13ee0a3c66dbd8e74685cfffa92b0cd98b0d4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  latitude
Asimetría (Skew): 0.47
Curtosis: -1.12
</pre></div>
</div>
<img alt="_images/2c6c2523e2d994927e31e866a942980ec815c79deb09e285f1563c6823dfda1a.png" src="_images/2c6c2523e2d994927e31e866a942980ec815c79deb09e285f1563c6823dfda1a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  housing_median_age
Asimetría (Skew): 0.06
Curtosis: -0.8
</pre></div>
</div>
<img alt="_images/892d8a8316098ef3d286a618390afe54259e3799a574dc60ed4f31011a358163.png" src="_images/892d8a8316098ef3d286a618390afe54259e3799a574dc60ed4f31011a358163.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  total_rooms
Asimetría (Skew): 4.15
Curtosis: 32.63
</pre></div>
</div>
<img alt="_images/d193f6fe429d5b1dc2bbdfa7f08adf3e41626c7d229deb34ade07e688557a27c.png" src="_images/d193f6fe429d5b1dc2bbdfa7f08adf3e41626c7d229deb34ade07e688557a27c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  total_bedrooms
Asimetría (Skew): 3.48
Curtosis: 22.24
</pre></div>
</div>
<img alt="_images/f2dced02bb96e1f889686260f9379280b4868d0d3ebcf94b4d73ecf27e99c0d6.png" src="_images/f2dced02bb96e1f889686260f9379280b4868d0d3ebcf94b4d73ecf27e99c0d6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  population
Asimetría (Skew): 4.94
Curtosis: 73.55
</pre></div>
</div>
<img alt="_images/6d5ac6e310f2c19c271449d10cbd7c0f52c6524f14d72dc7b700f606ba8a86f7.png" src="_images/6d5ac6e310f2c19c271449d10cbd7c0f52c6524f14d72dc7b700f606ba8a86f7.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  households
Asimetría (Skew): 3.41
Curtosis: 22.06
</pre></div>
</div>
<img alt="_images/d1d6e5816396f6d776643c159d3f2f4e603e36f08af5ac18001cb5ada8baac8d.png" src="_images/d1d6e5816396f6d776643c159d3f2f4e603e36f08af5ac18001cb5ada8baac8d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  median_income
Asimetría (Skew): 1.65
Curtosis: 4.95
</pre></div>
</div>
<img alt="_images/c9b6e807e2a45e766850ed2d3c786ff6818a5c1e4d9cbc09a014340d883c566a.png" src="_images/c9b6e807e2a45e766850ed2d3c786ff6818a5c1e4d9cbc09a014340d883c566a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Columna:  median_house_value
Asimetría (Skew): 0.98
Curtosis: 0.33
</pre></div>
</div>
<img alt="_images/f9f28127a200698265edb7aa674889377770ed3fbde2f14a6f217294c5b4ba36.png" src="_images/f9f28127a200698265edb7aa674889377770ed3fbde2f14a6f217294c5b4ba36.png" />
</div>
</div>
<ul class="simple">
<li><p>Variable categórica</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ajustar el gráfico aumentando el eje Y para mayor visibilidad de las etiquetas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>

<span class="c1"># Añadir el conteo y el porcentaje encima de cada barra</span>
<span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span>  <span class="c1"># Número total de registros</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">patches</span><span class="p">:</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">percentage</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">count</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="se">\n</span><span class="s1">(</span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="p">,</span> 
                <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">count</span><span class="p">),</span> 
                <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;baseline&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">)</span>

<span class="c1"># Ajustar el límite del eje Y</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.1</span><span class="p">)</span>

<span class="c1"># Personalización del gráfico</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribución de ocean_proximity&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Categorías de ocean_proximity&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frecuencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Rotar las etiquetas para mejor visibilidad</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5a2018d3676fd3b84faa6f2f1f24da288cff09302d41f5d87182b06a247fbc25.png" src="_images/5a2018d3676fd3b84faa6f2f1f24da288cff09302d41f5d87182b06a247fbc25.png" />
</div>
</div>
<ul class="simple">
<li><p>Gráfica bivariada</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Removiendo la variable categórica</span>
<span class="n">df2_cor</span>  <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">])</span>

<span class="c1"># Realizar el pairplot para las variables numéricas sin usar &#39;hue&#39; ya que no tenemos una variable categórica adecuada</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df2_cor</span><span class="p">,</span> <span class="n">diag_kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Pairplot de Variables Numéricas&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c167d328d65d33c7e8367c19fd812e5388f1ba739a651f403e4d4f068bb183fe.png" src="_images/c167d328d65d33c7e8367c19fd812e5388f1ba739a651f403e4d4f068bb183fe.png" />
</div>
</div>
</section>
<section id="correlaciones">
<h4>6. <strong>Correlaciones</strong><a class="headerlink" href="#correlaciones" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Es importante garantizar la ausencia de relación entre atríbutos, por tal razón lo utilizaremos la función <code class="docutils literal notranslate"><span class="pre">corr(method='spearman')</span></code> para verificar que se cumpla esta condición.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># correlation</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.precision&#39;</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">df2_cor</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>longitude</th>
      <td>1.0000</td>
      <td>-0.8792</td>
      <td>-0.1508</td>
      <td>0.0401</td>
      <td>0.0637</td>
      <td>0.1235</td>
      <td>0.0600</td>
      <td>-0.0099</td>
      <td>-0.0697</td>
    </tr>
    <tr>
      <th>latitude</th>
      <td>-0.8792</td>
      <td>1.0000</td>
      <td>0.0324</td>
      <td>-0.0184</td>
      <td>-0.0565</td>
      <td>-0.1236</td>
      <td>-0.0743</td>
      <td>-0.0880</td>
      <td>-0.1657</td>
    </tr>
    <tr>
      <th>housing_median_age</th>
      <td>-0.1508</td>
      <td>0.0324</td>
      <td>1.0000</td>
      <td>-0.3572</td>
      <td>-0.3050</td>
      <td>-0.2839</td>
      <td>-0.2820</td>
      <td>-0.1473</td>
      <td>0.0749</td>
    </tr>
    <tr>
      <th>total_rooms</th>
      <td>0.0401</td>
      <td>-0.0184</td>
      <td>-0.3572</td>
      <td>1.0000</td>
      <td>0.9082</td>
      <td>0.8162</td>
      <td>0.9067</td>
      <td>0.2713</td>
      <td>0.2060</td>
    </tr>
    <tr>
      <th>total_bedrooms</th>
      <td>0.0637</td>
      <td>-0.0565</td>
      <td>-0.3050</td>
      <td>0.9082</td>
      <td>1.0000</td>
      <td>0.8651</td>
      <td>0.9689</td>
      <td>-0.0066</td>
      <td>0.0857</td>
    </tr>
    <tr>
      <th>population</th>
      <td>0.1235</td>
      <td>-0.1236</td>
      <td>-0.2839</td>
      <td>0.8162</td>
      <td>0.8651</td>
      <td>1.0000</td>
      <td>0.9039</td>
      <td>0.0063</td>
      <td>0.0038</td>
    </tr>
    <tr>
      <th>households</th>
      <td>0.0600</td>
      <td>-0.0743</td>
      <td>-0.2820</td>
      <td>0.9067</td>
      <td>0.9689</td>
      <td>0.9039</td>
      <td>1.0000</td>
      <td>0.0303</td>
      <td>0.1127</td>
    </tr>
    <tr>
      <th>median_income</th>
      <td>-0.0099</td>
      <td>-0.0880</td>
      <td>-0.1473</td>
      <td>0.2713</td>
      <td>-0.0066</td>
      <td>0.0063</td>
      <td>0.0303</td>
      <td>1.0000</td>
      <td>0.6768</td>
    </tr>
    <tr>
      <th>median_house_value</th>
      <td>-0.0697</td>
      <td>-0.1657</td>
      <td>0.0749</td>
      <td>0.2060</td>
      <td>0.0857</td>
      <td>0.0038</td>
      <td>0.1127</td>
      <td>0.6768</td>
      <td>1.0000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">median_income</span></code></strong> tiene la mayor correlación positiva con <strong><code class="docutils literal notranslate"><span class="pre">median_house_value</span></code></strong> (0.6768).</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">total_rooms</span></code></strong> y <strong><code class="docutils literal notranslate"><span class="pre">total_bedrooms</span></code></strong> están fuertemente correlacionados (0.9150).</p></li>
<li><p>La correlación entre <strong><code class="docutils literal notranslate"><span class="pre">median_house_value</span></code></strong> y otras variables como <strong><code class="docutils literal notranslate"><span class="pre">total_rooms</span></code></strong>, <strong><code class="docutils literal notranslate"><span class="pre">total_bedrooms</span></code></strong> o <strong><code class="docutils literal notranslate"><span class="pre">population</span></code></strong> es baja.</p></li>
<li><p>Hay una correlación negativa entre <strong><code class="docutils literal notranslate"><span class="pre">latitude</span></code></strong> y <strong><code class="docutils literal notranslate"><span class="pre">median_house_value</span></code></strong> (-0.1657), sugiriendo precios más altos al sur.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">population</span></code></strong> no está correlacionada significativamente con <strong><code class="docutils literal notranslate"><span class="pre">median_house_value</span></code></strong> (0.0038).</p></li>
</ul>
<ul class="simple">
<li><p>Ahora, realicemos la gráfica de correlación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculating the correlation using the Spearman method</span>
<span class="n">correlation_matrix</span> <span class="o">=</span> <span class="n">df2_cor</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;spearman&#39;</span><span class="p">)</span>

<span class="c1"># Plotting the heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">correlation_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm_r&#39;</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;.2f&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Matriz de Correlación de Spearman&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6ab5dbcdf964fe81fe6fcba0fa4ed7200f27cb8bc6b2bab965f3b2dbf4963f46.png" src="_images/6ab5dbcdf964fe81fe6fcba0fa4ed7200f27cb8bc6b2bab965f3b2dbf4963f46.png" />
</div>
</div>
</section>
<section id="construccion-del-modelo-de-regresion">
<h4>7. <strong>Construcción del modelo de regresión</strong><a class="headerlink" href="#construccion-del-modelo-de-regresion" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convertir la variable categórica &#39;ocean_proximity&#39; en variables dummy</span>
<span class="n">df_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separar características y objetivo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="p">[</span><span class="s1">&#39;median_house_value&#39;</span><span class="p">]</span>

<span class="c1"># Dividir los datos en entrenamiento y prueba</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="c1"># Estandarizar las características</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaler</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaler</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Crear y entrenar el modelo de regresión lineal</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.6497
Test set score: 0.6257
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><strong>El rendimiento es similar en ambos conjuntos (entrenamiento y prueba)</strong>: La pequeña diferencia entre los puntajes sugiere que el modelo no está sobreajustado (overfitting) ni subajustado (underfitting). Está generalizando razonablemente bien a los datos no vistos.</p></li>
<li><p><strong>El <span class="math notranslate nohighlight">\(R^2\)</span> no es muy alto</strong>: Un <span class="math notranslate nohighlight">\(R^2\)</span> de <span class="math notranslate nohighlight">\(0.63-0.65\)</span> indica que hay factores adicionales que afectan el valor de las viviendas que no están siendo capturados por el modelo. Es posible que existan otras variables importantes o interacciones no consideradas en el conjunto de datos actual.</p></li>
</ul>
<p>Usando un <code class="docutils literal notranslate"><span class="pre">pipeline</span></code> nos queda:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de regresión lineal</span>
<span class="n">pipeline_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">LinearRegression</span><span class="p">())</span>

<span class="n">pipeline_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.6497
Test set score: 0.6257
</pre></div>
</div>
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Ejercicios</strong></p>
<ol class="arabic simple">
<li><p>Realice el modelo sin las variables que estan correlacionadas.</p></li>
<li><p>Realiza un PCA antes de construir el modelo de regresión</p></li>
</ol>
</div>
</section>
</section>
<section id="regresion-ridge">
<h3><strong>Regresión Ridge</strong><a class="headerlink" href="#regresion-ridge" title="Permalink to this heading">#</a></h3>
<p>La <strong>regularización Ridge</strong> penaliza la suma de los coeficientes elevados al cuadrado, es decir, <span class="math notranslate nohighlight">\(||\beta||_2^2 = \sum_{j=1}^{p} \beta_j^2 \)</span>. Esta penalización, conocida como <span class="math notranslate nohighlight">\(L^{2}\)</span>, tiene el efecto de reducir de forma proporcional el valor de todos los coeficientes del modelo, sin llevarlos a cero. El grado de penalización es controlado por el hiperparámetro <span class="math notranslate nohighlight">\(\lambda\)</span>. Cuando <span class="math notranslate nohighlight">\(\lambda = 0\)</span>, no hay penalización y el modelo es equivalente a un ajuste de mínimos cuadrados ordinarios (OLS). A medida que <span class="math notranslate nohighlight">\(\lambda\)</span> aumenta, la penalización se incrementa y el valor de los coeficientes disminuye.</p>
<p>La función de coste para el modelo Ridge es:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^{p} \beta_j^2
\]</div>
<p>donde el término adicional <span class="math notranslate nohighlight">\(\lambda \sum_{j=1}^{p} \beta_j^2\)</span> representa la penalización. Cuanto mayor es <span class="math notranslate nohighlight">\(\lambda\)</span>, mayor es la penalización aplicada.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del método Ridge</strong></p>
<ul class="simple">
<li><p>La principal ventaja de aplicar Ridge en lugar de mínimos cuadrados ordinarios (OLS) es la reducción de la varianza. En situaciones donde la relación entre la variable respuesta y los predictores es aproximadamente lineal, las estimaciones de OLS tienen bajo sesgo, pero pueden ser muy sensibles a los cambios en los datos de entrenamiento (alta varianza). Esto ocurre especialmente cuando el número de predictores se acerca al número de observaciones, donde OLS puede volverse inestable.</p></li>
<li><p>Al usar un valor adecuado de <span class="math notranslate nohighlight">\(\lambda\)</span>, Ridge logra reducir la varianza con un impacto mínimo en el sesgo, lo que resulta en un error total menor.</p></li>
</ul>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Desventajas del método Ridge</strong></p>
<ul class="simple">
<li><p>Una limitación del método es que no selecciona un subconjunto de predictores; en cambio, incluye todos los predictores en el modelo. Aunque penaliza los coeficientes para que tiendan a cero, estos no se anulan completamente (salvo cuando <span class="math notranslate nohighlight">\(\lambda = \infty\)</span>).</p></li>
<li><p>Ridge es útil para minimizar la influencia de predictores menos relevantes, pero estos seguirán estando presentes en el modelo final. Por lo tanto, aunque esto no sea un problema para la precisión, sí puede afectar la interpretabilidad del modelo.</p></li>
</ul>
</div>
<p>En resumen, la regularización Ridge es una técnica eficaz para mejorar la generalización de los modelos lineales, especialmente en situaciones donde hay muchos predictores en relación con el número de observaciones.</p>
<section id="construccion-del-modelo-rigde">
<h4><strong>Construcción del modelo Rigde</strong><a class="headerlink" href="#construccion-del-modelo-rigde" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importar la libreria  </span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="c1"># Crear y entrenar el modelo de regresión lineal con penalización Ridge</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.6497
Test set score: 0.6258
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como podemos ver, el hecho de que los resultados del modelo Ridge sean prácticamente iguales a los de la regresión lineal estándar (OLS) sugiere que la regularización aplicada por Ridge <strong>no tuvo un impacto significativo</strong>. Esto puede deberse a que el valor predeterminado del hiperparámetro <span class="math notranslate nohighlight">\(\lambda\)</span> (en Ridge, conocido como alpha) es muy bajo. Cuando <span class="math notranslate nohighlight">\(\lambda\)</span> es pequeño, la penalización es mínima, por lo que el modelo de Ridge se comporta de manera muy similar a OLS. En este caso, Ridge, usa <span class="math notranslate nohighlight">\(alpha=1.0\)</span> como parámetro por default (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">sklearn.linear_model.Ridge</a>). Esto es coherente con nuestras expectativas.</p></li>
</ul>
<ul class="simple">
<li><p>Hemos utilizado el parámetro por defecto <span class="math notranslate nohighlight">\(alpha=1.0\)</span>. Sin embargo, no hay ninguna razón por la que este nos dió la mejor compensación. El ajuste óptimo de alpha depende del conjunto de datos concreto que estemos utilizando.</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<p>Aumentar <code class="docutils literal notranslate"><span class="pre">alpha</span></code> obliga a los coeficientes a acercarse más a cero, lo que disminuye el <strong>rendimiento del conjunto de entrenamiento, pero puede ayudar a mejorar la generalización</strong>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># alpha = 0.1</span>
<span class="n">ridge01</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ridge regression con alpha=</span><span class="si">{</span><span class="mf">0.1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 1</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ridge regression con alpha=</span><span class="si">{</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 10</span>
<span class="n">ridge10</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ridge regression con alpha=</span><span class="si">{</span><span class="mi">10</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 100</span>
<span class="n">ridge100</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ridge regression con alpha=</span><span class="si">{</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ridge regression con alpha=0.1
Training set score: 0.6497
Test set score: 0.6257
------------------------------
Ridge regression con alpha=1
Training set score: 0.6497
Test set score: 0.6258
------------------------------
Ridge regression con alpha=10
Training set score: 0.6497
Test set score: 0.6260
------------------------------
Ridge regression con alpha=1
Training set score: 0.6492
Test set score: 0.6274
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Los resultados muestran que al incrementar el valor de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> en el modelo Ridge, los puntajes de entrenamiento y prueba no cambian de manera significativa. Sin embargo, se puede observar una ligera mejora en el rendimiento del conjunto de prueba a medida que aumenta <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, lo que sugiere una pequeña mejora en la generalización del modelo.</p></li>
</ul>
<ul class="simple">
<li><p>Observe cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code> se corresponde con la complejidad del modelo. Discutiremos los <strong>métodos para seleccionar adecuadamente los parámetros</strong> en el capítulo de <strong>evaluación de modelos</strong>. También podemos obtener una visión más cualitativa de cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code> cambia el modelo, inspeccionando el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code> de los modelos con diferentes valores de <strong>alpha</strong>.</p></li>
</ul>
<ul class="simple">
<li><p>Un <code class="docutils literal notranslate"><span class="pre">alpha</span></code> más alto significa un modelo más restringido, por lo que esperamos que las entradas de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> tengan una magnitud menor.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=10&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge100</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=100&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LinearRegression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/a66dc089519899345410fb49141dd1c38c2cfa0ef6e2cd0856dcd0bed5fa9e07.png" src="_images/a66dc089519899345410fb49141dd1c38c2cfa0ef6e2cd0856dcd0bed5fa9e07.png" />
</div>
</div>
</section>
</section>
<section id="regresion-lasso">
<h3><strong>Regresión Lasso</strong><a class="headerlink" href="#regresion-lasso" title="Permalink to this heading">#</a></h3>
<p>La <strong>regularización Lasso</strong> penaliza la suma del valor absoluto de los coeficientes de regresión, es decir, <span class="math notranslate nohighlight">\(||\beta||_1 = \sum_{j=1}^{p} |\beta_j|\)</span>. Esta penalización, conocida como <span class="math notranslate nohighlight">\(L^1\)</span>, tiene el efecto de forzar a que algunos coeficientes de los predictores sean exactamente cero. Esto permite al método Lasso excluir del modelo los predictores menos relevantes, logrando así una forma de selección de variables.</p>
<p>Al igual que en Ridge, el grado de penalización está controlado por el hiperparámetro <span class="math notranslate nohighlight">\(\lambda\)</span>. Cuando <span class="math notranslate nohighlight">\(\lambda = 0\)</span>, la penalización es nula y el modelo es equivalente a un ajuste de mínimos cuadrados ordinarios (OLS). A medida que <span class="math notranslate nohighlight">\(\lambda\)</span> aumenta, la penalización se intensifica, lo que lleva a que más coeficientes se reduzcan a cero, excluyendo así más predictores del modelo.</p>
<p>La función de coste para el modelo Lasso es:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2 + \lambda \sum_{j=1}^{p} |\beta_j|
\]</div>
<p>donde el término adicional <span class="math notranslate nohighlight">\(\lambda \sum_{j=1}^{p} |\beta_j|\)</span> representa la penalización aplicada a los coeficientes.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del método Lasso</strong></p>
<ul class="simple">
<li><p><strong>Selección de características:</strong> Lasso es capaz de llevar a cero los coeficientes de algunos predictores, lo que resulta en un modelo más sencillo y con menos variables. Esto facilita la interpretación del modelo.</p></li>
<li><p><strong>Reducción de la complejidad:</strong> Al excluir predictores menos relevantes, el modelo se vuelve más simple y puede mejorar la generalización a nuevos datos.</p></li>
</ul>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Desventajas del método Lasso</strong></p>
<ul class="simple">
<li><p><strong>Sesgo en los coeficientes seleccionados:</strong> Aunque Lasso reduce la varianza, también puede introducir un sesgo adicional al forzar algunos coeficientes a cero.</p></li>
<li><p><strong>Limitaciones con alta multicolinealidad:</strong> Cuando las variables son altamente correlacionadas, Lasso puede seleccionar una de ellas de manera arbitraria y excluir el resto, lo que puede no ser deseable en ciertos casos.</p></li>
</ul>
</div>
<p>En resumen, la regularización Lasso es útil para crear modelos parsimoniosos, seleccionando automáticamente las variables más relevantes y excluyendo las menos significativas.</p>
<section id="construccion-del-modelo-lasso">
<h4><strong>Construcción del modelo Lasso</strong><a class="headerlink" href="#construccion-del-modelo-lasso" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importar la libreria  </span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>

<span class="c1"># Crear y entrenar el modelo de regresión lineal con penalización lasso</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.6497
Test set score: 0.6257
Number of features used: 12
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como podemos ver, el hecho de que los resultados del modelo <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> sean similares a los de la regresión lineal estándar y <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> sugiere que la regularización aplicada <strong>no está teniendo un impacto significativo en el rendimiento del modelo</strong>. Aunque <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> puede forzar algunos coeficientes a cero, en este caso no parece estar mejorando la generalización o reduciendo la complejidad del modelo de manera significativa. De forma similar a <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> también tiene un parámetro de regularización, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, que controla la fuerza con la que los coeficientes son empujados hacia cero.</p></li>
<li><p>El hecho de que <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> esté utilizando 12 características indica que la mayoría de las variables son útiles para el modelo, por lo que la penalización no está eliminando muchas de ellas.</p></li>
<li><p>El valor por defecto de <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1</span></code> en <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso">sklearn.linear_model.Lasso</a>) podría ser demasiado bajo, por lo que cuando <strong>alpha es pequeño, la penalización es débil</strong>, lo que significa que el modelo se comporta de manera similar a una regresión lineal estándar. En este caso, <strong><code class="docutils literal notranslate"><span class="pre">Lasso</span></code> no está forzando muchos coeficientes a cero</strong>.</p></li>
</ul>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<p>El parámetro <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> en <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> define el número máximo de iteraciones permitidas para que el algoritmo de optimización converja. Cuando se establece un valor más alto para <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>, se le da más tiempo al modelo para encontrar una solución óptima, lo cual puede ser necesario en casos con datos complejos o cuando se usa un valor alto de <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<ol class="arabic simple">
<li><p>En la mayoría de los casos, un valor de <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> de 10,000 es suficiente para que el algoritmo Lasso converja. Sin embargo, si el modelo no está alcanzando la convergencia (por ejemplo, si aparece una advertencia de que el algoritmo no se ha ajustado completamente), puede ser útil aumentar max_iter a 100,000 o más.</p></li>
<li><p>Si se usa un valor de <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> extremadamente alto, como 1,000,000, puede prolongar innecesariamente el tiempo de entrenamiento si el algoritmo ya ha convergido antes de alcanzar ese número de iteraciones.</p></li>
<li><p>Elegir un valor más alto de <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> no necesariamente mejorará los resultados, pero garantiza que el algoritmo tenga suficiente tiempo para converger si es necesario.</p></li>
</ol>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># alpha = 0.1</span>
<span class="n">lasso01</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lasso regression con alpha=</span><span class="si">{</span><span class="mf">0.1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número de características utilizadas:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 1</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lasso regression con alpha=</span><span class="si">{</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número de características utilizadas:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 10</span>
<span class="n">lasso10</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lasso regression con alpha=</span><span class="si">{</span><span class="mi">10</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número de características utilizadas:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

<span class="c1"># alpha = 100</span>
<span class="n">lasso100</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lasso regression con alpha=</span><span class="si">{</span><span class="mi">100</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Número de características utilizadas:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Lasso regression con alpha=0.1
Training set score: 0.6497
Test set score: 0.6257
Número de características utilizadas: 12
------------------------------
Lasso regression con alpha=1
Training set score: 0.6497
Test set score: 0.6257
Número de características utilizadas: 12
------------------------------
Lasso regression con alpha=10
Training set score: 0.6497
Test set score: 0.6257
Número de características utilizadas: 12
------------------------------
Lasso regression con alpha=100
Training set score: 0.6497
Test set score: 0.6257
Número de características utilizadas: 12
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Los resultados muestran que el rendimiento del modelo <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> <strong>no cambia con los diferentes valores de <code class="docutils literal notranslate"><span class="pre">alpha</span></code></strong>, lo que sugiere que <strong>la regularización no está teniendo un impacto significativo en este caso</strong>. El <strong>número de características utilizadas también se mantiene constante en 12</strong>, lo que indica que <strong><code class="docutils literal notranslate"><span class="pre">Lasso</span></code> no está forzando ningún coeficiente a cero</strong>, independientemente del valor de alpha.</p></li>
</ul>
<ul class="simple">
<li><p>Los valores de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> probados pueden no ser lo suficientemente grandes para aplicar una penalización fuerte. Al aumentar <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, se espera que <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> reduzca más coeficientes a cero, pero en este caso, incluso con <code class="docutils literal notranslate"><span class="pre">alpha=100</span></code>, no se observa ese comportamiento.</p></li>
</ul>
<p>Una vez más, podemos trazar <strong>los coeficientes de los diferentes modelos</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">font_scale</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.01&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso10</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.0001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso100</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.0001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LinearRegression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d6180a297871a5ab38467212f19e152c08452c117316048feaac2c707443a547.png" src="_images/d6180a297871a5ab38467212f19e152c08452c117316048feaac2c707443a547.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Ejercicios</strong></p>
<ol class="arabic simple">
<li><p>Explora el modelo con la penalización de <code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code></p></li>
</ol>
</div>
</section>
</section>
<section id="regresion-por-k-vecinos">
<h3><strong>Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong><a class="headerlink" href="#regresion-por-k-vecinos" title="Permalink to this heading">#</a></h3>
<p>La <strong>regresión de k vecinos más cercanos</strong> (K-Nearest Neighbors Regression, KNN Regression) es un método de aprendizaje supervisado que se utiliza para predecir valores continuos. A diferencia de los modelos lineales, no asume una relación específica entre las variables de entrada y la salida. En su lugar, basa la predicción en la similitud entre los puntos de datos.</p>
<section id="como-funciona-knn-regression">
<h4><strong>¿Cómo funciona KNN Regression?</strong><a class="headerlink" href="#como-funciona-knn-regression" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Definir el número de vecinos (k):</strong> El usuario elige un valor de <span class="math notranslate nohighlight">\(k\)</span>, que representa el número de vecinos más cercanos que se utilizarán para hacer la predicción.</p></li>
<li><p><strong>Calcular la distancia:</strong> Para un nuevo punto, se calcula la distancia entre este punto y todos los puntos en el conjunto de entrenamiento. Las distancias comunes utilizadas son la distancia euclidiana o la distancia Manhattan.</p></li>
<li><p><strong>Seleccionar los k vecinos más cercanos:</strong> Se identifican los <span class="math notranslate nohighlight">\(k\)</span> puntos más cercanos al nuevo punto basados en la distancia calculada.</p></li>
<li><p><strong>Predicción:</strong> La predicción para el nuevo punto es el promedio (o la media ponderada) de los valores de salida de los <span class="math notranslate nohighlight">\(k\)</span> vecinos seleccionados.</p></li>
</ol>
<ul class="simple">
<li><p>También existe una <strong>variante de regresión del algoritmo <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos</strong>. Una vez más, vamos a empezar utilizando el <strong>vecino más cercano simple</strong>. Hemos añadido tres puntos de datos de prueba como estrellas verdes en el eje <span class="math notranslate nohighlight">\(x\)</span>. <strong>La predicción utilizando un solo vecino es sólo el valor objetivo del vecino más cercano</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importar mglearn</span>
<span class="kn">import</span> <span class="nn">mglearn</span>

<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7c118ef9b5dc08b7bfcaad5a7daf67017301d23b6153ee9f66ce63abd8b10131.png" src="_images/7c118ef9b5dc08b7bfcaad5a7daf67017301d23b6153ee9f66ce63abd8b10131.png" />
</div>
</div>
<ul class="simple">
<li><p>De nuevo, podemos utilizar más que el único vecino más cercano para la regresión. <strong>Cuando se utilizan varios vecinos más cercanos, la predicción es el promedio, o la media, de los vecinos</strong>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c73adf22647dea783e25b546939fca586ba8cdbfb773cb27ca30a8c5a8da9739.png" src="_images/c73adf22647dea783e25b546939fca586ba8cdbfb773cb27ca30a8c5a8da9739.png" />
</div>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de KNN Regression</strong></p>
<ul class="simple">
<li><p><strong>Simplicidad:</strong> Es fácil de entender e implementar.</p></li>
<li><p><strong>Sin suposiciones sobre la distribución de los datos:</strong> KNN no asume una forma específica para la relación entre las variables, lo que lo hace flexible para problemas no lineales.</p></li>
<li><p><strong>Capacidad para capturar relaciones locales:</strong> KNN puede capturar patrones complejos al basarse en la proximidad de los datos.</p></li>
</ul>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Desventajas de KNN Regression</strong></p>
<ul class="simple">
<li><p><strong>Sensibilidad a la escala de las características:</strong> Si las características no están estandarizadas, las distancias pueden ser dominadas por aquellas con valores más grandes.</p></li>
<li><p><strong>Rendimiento en conjuntos de datos grandes:</strong> A medida que el tamaño del conjunto de datos crece, el tiempo de cómputo para calcular las distancias también aumenta, lo que puede ser computacionalmente costoso.</p></li>
<li><p><strong>Elección del valor de k:</strong> Seleccionar el valor óptimo de <span class="math notranslate nohighlight">\(k\)</span> es crucial; un <span class="math notranslate nohighlight">\(k\)</span> demasiado pequeño puede llevar a un modelo ruidoso y poco generalizable, mientras que un <span class="math notranslate nohighlight">\(k\)</span> demasiado grande puede suavizar en exceso las predicciones.</p></li>
</ul>
</div>
</section>
<section id="consideraciones-al-usar-knn-regression">
<h4><strong>Consideraciones al usar KNN Regression</strong><a class="headerlink" href="#consideraciones-al-usar-knn-regression" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Estandarizar las características:</strong> Para que todas las variables tengan la misma importancia en el cálculo de distancias.</p></li>
<li><p><strong>Optimizar el valor de <span class="math notranslate nohighlight">\(k\)</span>:</strong> Utilizar técnicas de validación cruzada para encontrar el mejor valor de <span class="math notranslate nohighlight">\(k\)</span>.</p></li>
<li><p><strong>Ponderación de los vecinos:</strong> Es posible ponderar los vecinos en función de su distancia al punto de predicción, lo que da más peso a los vecinos más cercanos.</p></li>
</ul>
<p>La regresión de KNN es una técnica útil para problemas donde la relación entre las variables no es lineal y se necesita un enfoque no paramétrico. Sin embargo, su rendimiento puede disminuir con conjuntos de datos muy grandes o con muchas dimensiones.</p>
</section>
<section id="construccion-del-modelo-knn">
<h4><strong>Construcción del modelo KNN</strong><a class="headerlink" href="#construccion-del-modelo-knn" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Como ya tenemos seleccionados los datos de entrenamiento y de prueba, además, aplicado imputacion de datos con la variable dummy y estandarizado, es necesario <strong>encontrar el factor <span class="math notranslate nohighlight">\(k\)</span></strong> que genere los mejores resultados para el algoritmo. Una de las formas de encontrar este factor <span class="math notranslate nohighlight">\(k\)</span> es <strong>realizar una prueba con varios valores y medir los resultados porcentuales</strong>. Será necesario agotar un gran número de posibilidades de <span class="math notranslate nohighlight">\(k\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="c1"># Lista para almacenar los scores de R² para cada valor de k</span>
<span class="n">r2_val</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">best_r2</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>

<span class="c1"># Probar diferentes valores de k</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">):</span>  <span class="c1"># k va de 1 a 20</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    
    <span class="c1"># Guardar el mejor score de R² y el mejor valor de k</span>
    <span class="k">if</span> <span class="n">r2</span> <span class="o">&gt;</span> <span class="n">best_r2</span><span class="p">:</span>
        <span class="n">best_r2</span> <span class="o">=</span> <span class="n">r2</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="c1"># Añadir el score de R² a la lista</span>
    <span class="n">r2_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;R² value for k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1"> is: </span><span class="si">{</span><span class="n">r2</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best R²: </span><span class="si">{</span><span class="n">best_r2</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, Best k: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R² value for k=1 is: 0.566559
R² value for k=2 is: 0.665058
R² value for k=3 is: 0.690577
R² value for k=4 is: 0.704162
R² value for k=5 is: 0.711608
R² value for k=6 is: 0.712243
R² value for k=7 is: 0.713344
R² value for k=8 is: 0.714844
R² value for k=9 is: 0.714638
R² value for k=10 is: 0.715386
R² value for k=11 is: 0.716994
R² value for k=12 is: 0.715765
R² value for k=13 is: 0.716657
R² value for k=14 is: 0.716876
R² value for k=15 is: 0.716550
R² value for k=16 is: 0.716147
R² value for k=17 is: 0.715001
R² value for k=18 is: 0.715611
R² value for k=19 is: 0.715018
R² value for k=20 is: 0.713702
Best R²: 0.716994, Best k: 11
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Lista para almacenar los valores de RMSLE para cada valor de k</span>
<span class="n">rmsle_val</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">best_rmsle</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>  <span class="c1"># Inicializar con un valor grande</span>

<span class="c1"># Probar diferentes valores de k</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">21</span><span class="p">):</span>  <span class="c1"># k va de 1 a 20</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">)</span>
    <span class="n">rmsle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    
    <span class="c1"># Guardar el mejor RMSLE y el mejor valor de k</span>
    <span class="k">if</span> <span class="n">rmsle</span> <span class="o">&lt;</span> <span class="n">best_rmsle</span><span class="p">:</span>
        <span class="n">best_rmsle</span> <span class="o">=</span> <span class="n">rmsle</span>
        <span class="n">best_k</span> <span class="o">=</span> <span class="n">k</span>

    <span class="c1"># Añadir el RMSLE a la lista</span>
    <span class="n">rmsle_val</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rmsle</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;RMSLE value for k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1"> is: </span><span class="si">{</span><span class="n">rmsle</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best RMSLE: </span><span class="si">{</span><span class="n">best_rmsle</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, Best k: </span><span class="si">{</span><span class="n">best_k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSLE value for k=1 is: 0.347331
RMSLE value for k=2 is: 0.311461
RMSLE value for k=3 is: 0.298138
RMSLE value for k=4 is: 0.290783
RMSLE value for k=5 is: 0.286999
RMSLE value for k=6 is: 0.286508
RMSLE value for k=7 is: 0.286187
RMSLE value for k=8 is: 0.284960
RMSLE value for k=9 is: 0.284766
RMSLE value for k=10 is: 0.284915
RMSLE value for k=11 is: 0.284533
RMSLE value for k=12 is: 0.284771
RMSLE value for k=13 is: 0.284532
RMSLE value for k=14 is: 0.284462
RMSLE value for k=15 is: 0.284491
RMSLE value for k=16 is: 0.284311
RMSLE value for k=17 is: 0.284731
RMSLE value for k=18 is: 0.284686
RMSLE value for k=19 is: 0.284976
RMSLE value for k=20 is: 0.285250
Best RMSLE: 0.284311, Best k: 16
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ya que venimos en los ejemplos anteriores usando la métrica de <span class="math notranslate nohighlight">\(R^2\)</span>. Este se usará para <span class="math notranslate nohighlight">\(k\)</span>-vecinos. Por lo que el modelo nos queda</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de regresión knn</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">11</span><span class="p">)</span>

<span class="c1"># Crear y entrenar el modelo de regresión knn</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.7779
Test set score: 0.7170
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Interpretación de los Resultados del KNN</p>
<ul>
<li><p><strong>Mejor desempeño del KNN en el conjunto de prueba</strong>: El modelo KNN tiene un Test set score de 0.7170, que es significativamente mejor que los 0.63 obtenidos con los modelos lineales. Esto indica que KNN captura mejor las relaciones en los datos y tiene una mayor capacidad de generalización para este conjunto de datos.</p></li>
<li><p><strong>Mayor diferencia entre el entrenamiento y la prueba</strong>: El Training set score de 0.7779 en KNN es más alto que su Test set score de 0.7170, lo que sugiere que el modelo KNN puede estar ligeramente sobreajustado. Sin embargo, el puntaje de prueba sigue siendo superior al de los modelos lineales, lo que hace que KNN sea una mejor opción en este caso.</p></li>
</ul>
</li>
</ul>
<p>En conclusión, el modelo KNN es <strong>el mejor entre los probados</strong> (Regresión Lineal, Ridge, Lasso y KNN) para este conjunto de datos, ya que tiene un mejor desempeño en el conjunto de prueba. Esto sugiere que KNN es capaz de capturar relaciones no lineales en los datos que los modelos lineales no logran identificar.</p>
</section>
</section>
<section id="regresion-con-support-vector-machine-svr">
<h3><strong>Regresión con Support Vector Machine (SVR)</strong><a class="headerlink" href="#regresion-con-support-vector-machine-svr" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Las <strong>Máquinas de Soporte Vectorial</strong> (SVM) se pueden utilizar tanto para regresiones lineales como no lineales; en este contexto, se denominan <strong>SVR</strong> (Support Vector Regression).</p></li>
<li><p>A diferencia de las SVM tradicionales, que buscan ajustar el mayor corredor (o calle) posible entre dos clases para maximizar el margen, las SVR intentan mantener la mayor cantidad de observaciones del conjunto de datos dentro de un corredor alrededor de la recta de regresión, limitando el margen máximo de error.</p></li>
<li><p>La anchura del corredor (o calle) en torno a la recta se controla mediante un hiperparámetro llamado <strong>epsilon</strong> <span class="math notranslate nohighlight">\(\epsilon\)</span>, que determina el rango en el que las predicciones se consideran aceptables sin penalización adicional.</p></li>
</ul>
<p><img alt="SVR" src="_images/svr1.png" /></p>
<section id="como-funciona-la-svr">
<h4><strong>¿Cómo funciona la SVR?</strong><a class="headerlink" href="#como-funciona-la-svr" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>La SVR realiza una regresión en un espacio de dimensión superior, conocido como espacio de características. En este espacio, el problema puede ser más fácil de resolver debido a que las relaciones no lineales se pueden transformar en lineales.</p></li>
<li><p>Al construir una SVR, podemos imaginar que cada punto de datos del conjunto de entrenamiento representa una dimensión en este espacio de mayor dimensión. Al evaluar el núcleo (o <strong>kernel</strong>) entre un punto de prueba y cada punto del conjunto de entrenamiento, se obtiene un vector <strong>k</strong>, que es la representación del punto de prueba en el espacio transformado.</p></li>
</ul>
</section>
<section id="funcion-de-decision">
<h4><strong>Función de Decisión</strong><a class="headerlink" href="#funcion-de-decision" title="Permalink to this heading">#</a></h4>
<p>La función de decisión para la SVR se define como:</p>
<div class="math notranslate nohighlight">
\[
f(x) = \sum_{i=1}^{N} (\alpha_i - \alpha_i^*) K(x_i, x) + b
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\alpha_i\)</span> y <span class="math notranslate nohighlight">\(\alpha_i^*\)</span> son los multiplicadores de Lagrange obtenidos del entrenamiento,</p></li>
<li><p><span class="math notranslate nohighlight">\(K(x_i, x)\)</span> es la función de núcleo que mide la similitud entre el punto de prueba <span class="math notranslate nohighlight">\(x\)</span> y los puntos de entrenamiento <span class="math notranslate nohighlight">\(x_i\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span> es el término de sesgo.</p></li>
</ul>
</section>
<section id="definicion-del-nucleo">
<h4><strong>Definición del Núcleo</strong><a class="headerlink" href="#definicion-del-nucleo" title="Permalink to this heading">#</a></h4>
<p>El núcleo <span class="math notranslate nohighlight">\(K(x_i, x)\)</span> permite transformar los datos al espacio de mayor dimensión, y puede ser de diferentes tipos:</p>
<ul class="simple">
<li><p><strong>Lineal</strong>: <span class="math notranslate nohighlight">\(K(x_i, x) = x_i \cdot x\)</span></p></li>
<li><p><strong>Polinómico</strong>: <span class="math notranslate nohighlight">\(K(x_i, x) = (x_i \cdot x + c)^d\)</span></p></li>
<li><p><strong>Gaussiano (RBF)</strong>: <span class="math notranslate nohighlight">\(K(x_i, x) = \exp \left( -\gamma \|x_i - x\|^2 \right)\)</span></p></li>
</ul>
<p>La elección del núcleo y sus parámetros afecta la capacidad del modelo para capturar relaciones complejas en los datos.</p>
<p>Una imagen del modelo escogiendo el kernel</p>
<p><img alt="Kernel" src="_images/kernel.png" /></p>
</section>
<section id="construccion-de-un-modelo-de-svr">
<h4><strong>Construcción de un Modelo de SVR</strong><a class="headerlink" href="#construccion-de-un-modelo-de-svr" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Definir el conjunto de entrenamiento</strong> con pares de datos <span class="math notranslate nohighlight">\((x_i, y_i)\)</span>, donde <span class="math notranslate nohighlight">\(x_i\)</span> son las características y <span class="math notranslate nohighlight">\(y_i\)</span> son los valores objetivo.</p></li>
<li><p><strong>Elegir un núcleo</strong> y sus parámetros, además de realizar la regularización para controlar el sobreajuste.</p></li>
<li><p><strong>Crear la matriz de correlaciones</strong>, que incluye la evaluación del núcleo para cada par de puntos de entrenamiento. La matriz de correlaciones es:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
M_{i,j} = \exp \left( \sum_{k} \theta_k |x_i^k - x_j^k|^2 \right) + \epsilon \delta_{i,j}
\]</div>
<ol class="arabic simple" start="4">
<li><p><strong>Entrenar el modelo</strong> resolviendo un problema de optimización para encontrar los multiplicadores de Lagrange <span class="math notranslate nohighlight">\(\alpha_i\)</span> y <span class="math notranslate nohighlight">\(\alpha_i^*\)</span>.</p></li>
<li><p><strong>Calcular el estimador</strong>, utilizando los multiplicadores de Lagrange y el núcleo seleccionado para hacer predicciones en nuevos datos.</p></li>
</ol>
<p>En este enlace puedes encontrar la documentación de <a class="reference external" href="https://scikit-learn.org/stable/api/sklearn.svm.html#module-sklearn.svm">SVR</a>.</p>
</section>
<section id="resumen">
<h4><strong>Resumen</strong><a class="headerlink" href="#resumen" title="Permalink to this heading">#</a></h4>
<p>Para simplificar, la diferencia clave entre la <strong>regresión lineal</strong> y la <strong>SVR</strong> es el objetivo de optimización:</p>
<ul class="simple">
<li><p>En la <strong>regresión lineal</strong>, se minimiza el error cuadrático medio entre las predicciones y los datos reales.</p></li>
<li><p>En la <strong>SVR</strong>, se busca que las predicciones estén dentro de un margen de error controlado por <span class="math notranslate nohighlight">\(\epsilon\)</span>, de modo que los errores que caen dentro de este margen no se penalizan.</p></li>
</ul>
<p>El modelo optimiza para que los errores estén lo más cerca posible de cero, sin superar el margen especificado por <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
</section>
<section id="construccion-del-modelo-de-svr">
<h4><strong>Construcción del modelo de SVR</strong><a class="headerlink" href="#construccion-del-modelo-de-svr" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">SVR</span></code> - Epsilon-Support Vector Regression</strong></p></li>
</ol>
<p>La <strong>Regresión de Máquinas de Soporte Vectorial con Epsilon (SVR)</strong> es un método de regresión que utiliza máquinas de soporte vectorial. Los parámetros principales que controlan el modelo son <strong>C</strong> y <strong>epsilon</strong>.</p>
<p>La implementación de SVR en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> está basada en <strong>libsvm</strong>. La complejidad del tiempo de ajuste es más que cuadrática en función del número de muestras, lo que puede dificultar su escalabilidad en conjuntos de datos con más de 10,000 muestras. Para conjuntos de datos grandes, se recomienda considerar el uso de <code class="docutils literal notranslate"><span class="pre">LinearSVR</span></code> o <code class="docutils literal notranslate"><span class="pre">SGDRegressor</span></code>, posiblemente después de aplicar una transformación de Nystroem u otra aproximación de núcleos.</p>
<p>Para más información, consulte la <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#svr">Guía del Usuario</a>.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Parámetros</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>kernel</strong>: <code class="docutils literal notranslate"><span class="pre">{'linear',</span> <span class="pre">'poly',</span> <span class="pre">'rbf',</span> <span class="pre">'sigmoid',</span> <span class="pre">'precomputed'}</span></code> o función personalizada, por defecto <code class="docutils literal notranslate"><span class="pre">'rbf'</span></code>.</p>
<ul>
<li><p>Especifica el tipo de núcleo a usar en el algoritmo. Si no se especifica, se utiliza <code class="docutils literal notranslate"><span class="pre">'rbf'</span></code> por defecto. Si se proporciona una función personalizada, se usa para precomputar la matriz de núcleo.</p></li>
</ul>
</li>
<li><p><strong>degree</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p>
<ul>
<li><p>Grado de la función de núcleo polinómico (<code class="docutils literal notranslate"><span class="pre">'poly'</span></code>). Debe ser un valor no negativo. Es ignorado para todos los demás núcleos.</p></li>
</ul>
</li>
<li><p><strong>gamma</strong>: <code class="docutils literal notranslate"><span class="pre">{'scale',</span> <span class="pre">'auto'}</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">'scale'</span></code>.</p>
<ul>
<li><p>Coeficiente del núcleo para los núcleos <code class="docutils literal notranslate"><span class="pre">'rbf'</span></code>, <code class="docutils literal notranslate"><span class="pre">'poly'</span></code> y <code class="docutils literal notranslate"><span class="pre">'sigmoid'</span></code>.</p>
<ul>
<li><p>Si se establece <code class="docutils literal notranslate"><span class="pre">gamma='scale'</span></code> (por defecto), se utiliza el valor <span class="math notranslate nohighlight">\(\frac{1}{n_{\text{features}} \cdot \text{var}(X)}\)</span>.</p></li>
<li><p>Si se establece <code class="docutils literal notranslate"><span class="pre">gamma='auto'</span></code>, se utiliza el valor <span class="math notranslate nohighlight">\(\frac{1}{n_{\text{features}}}\)</span>.</p></li>
<li><p>Si es un valor <code class="docutils literal notranslate"><span class="pre">float</span></code>, debe ser no negativo.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>coef0</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">0.0</span></code>.</p>
<ul>
<li><p>Término independiente en la función de núcleo. Es significativo solo para los núcleos <code class="docutils literal notranslate"><span class="pre">'poly'</span></code> y <code class="docutils literal notranslate"><span class="pre">'sigmoid'</span></code>.</p></li>
</ul>
</li>
<li><p><strong>tol</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">1e-3</span></code>.</p>
<ul>
<li><p>Tolerancia para el criterio de parada.</p></li>
</ul>
</li>
<li><p><strong>C</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">1.0</span></code>.</p>
<ul>
<li><p>Parámetro de regularización. La fuerza de la regularización es inversamente proporcional a <strong>C</strong>. Debe ser un valor estrictamente positivo. La penalización es una norma cuadrada <span class="math notranslate nohighlight">\(L^2\)</span>.</p></li>
</ul>
</li>
<li><p><strong>epsilon</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">0.1</span></code>.</p>
<ul>
<li><p>Epsilon en el modelo epsilon-SVR. Especifica el tubo epsilon dentro del cual no se aplica penalización en la función de pérdida de entrenamiento para puntos que están dentro de una distancia <strong>epsilon</strong> del valor real. Debe ser un valor no negativo.</p></li>
</ul>
</li>
<li><p><strong>shrinking</strong>: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<ul>
<li><p>Indica si se debe usar la heurística de reducción (shrinking). Consulte la <a class="reference external" href="https://scikit-learn.org/stable/modules/svm.html#shrinking-svm">Guía del Usuario</a>.</p></li>
</ul>
</li>
<li><p><strong>cache_size</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">200</span></code>.</p>
<ul>
<li><p>Especifica el tamaño de la caché del núcleo (en MB).</p></li>
</ul>
</li>
<li><p><strong>verbose</strong>: <code class="docutils literal notranslate"><span class="pre">bool</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<ul>
<li><p>Habilita la salida detallada. Esta configuración aprovecha un ajuste a nivel de proceso en libsvm que, si se habilita, puede no funcionar correctamente en un contexto multihilo.</p></li>
</ul>
</li>
<li><p><strong>max_iter</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code>, por defecto <code class="docutils literal notranslate"><span class="pre">-1</span></code>.</p>
<ul>
<li><p>Límite máximo de iteraciones dentro del solucionador, o <code class="docutils literal notranslate"><span class="pre">-1</span></code> para no tener límite.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar la libreria</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>

<span class="c1"># Crear y entrenar el modelo de SVR con kernel lineal</span>
<span class="n">svr_lineal</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
<span class="n">svr_lineal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svr_lineal</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svr_lineal</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.1065
Test set score: 0.1122
</pre></div>
</div>
</div>
</div>
<p>Estos puntajes son bastante bajos en comparación con los obtenidos anteriormente con otros modelos (regresión lineal, Ridge, Lasso y KNN). Esto sugiere que el modelo SVR con un kernel lineal no está capturando bien la relación en los datos y no es una buena opción para este problema.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de SVR con kernel &#39;rbf&#39;</span>
<span class="n">svr_rbf</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">)</span>  <span class="c1"># Usando el kernel RBF</span>
<span class="n">svr_rbf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo de SVR con kernel &#39;rbf&#39;</span>
<span class="n">training_score_rbf</span> <span class="o">=</span> <span class="n">svr_rbf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_score_rbf</span> <span class="o">=</span> <span class="n">svr_rbf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_score_rbf</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score_rbf</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: -0.0479
Test set score: -0.0421
</pre></div>
</div>
</div>
</div>
<p>Estos puntajes negativos indican que el modelo SVR con kernel rbf no se ajusta bien a los datos y su rendimiento es peor que simplemente predecir la media del conjunto de entrenamiento. Esto sugiere que el modelo no está capturando la estructura de los datos de manera efectiva.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de SVR con kernel &#39;poly&#39;</span>
<span class="n">svr_poly</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">)</span>  <span class="c1"># Usando el kernel polinomial</span>
<span class="n">svr_poly</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo de SVR con kernel &#39;poly&#39;</span>
<span class="n">training_score_poly</span> <span class="o">=</span> <span class="n">svr_poly</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">test_score_poly</span> <span class="o">=</span> <span class="n">svr_poly</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_score_poly</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score_poly</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: -0.0454
Test set score: -0.0392
</pre></div>
</div>
</div>
</div>
<p>Al igual que con el kernel rbf, los puntajes negativos indican que el modelo SVR con kernel polinomial no está capturando bien la relación en los datos. Esto sugiere que el modelo no es adecuado en su configuración actual para este problema.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar la libreria</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>

<span class="c1"># Crear y entrenar el modelo de SVR con kernel lineal</span>
<span class="n">svr_lineal</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">svr_lineal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluar el modelo</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svr_lineal</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svr_lineal</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaler</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.6362
Test set score: 0.6119
</pre></div>
</div>
</div>
</div>
<div class="warning admonition">
<p class="admonition-title"><strong>Observación</strong></p>
<p>Para no ingresar los parámetros de manera manual debemos tener unos conceptos claves para mejorar el modelo, que son los siguientes</p>
<ol class="arabic simple">
<li><p><strong>Validación cruzada</strong></p></li>
<li><p><strong>Grid Search</strong></p></li>
</ol>
<p>Esto conceptos los desarrollaremos proximamente</p>
</div>
</section>
</section>
<section id="evaluacion-de-los-modelos">
<h3><strong>Evaluación de los módelos</strong><a class="headerlink" href="#evaluacion-de-los-modelos" title="Permalink to this heading">#</a></h3>
<p>Después de discutir algunos modelos del aprendizaje supervisado y los distintos algoritmos utilizados, pasaremos a abordar la evaluación de modelos y la selección de hiperparámetros. Nos centraremos en los modelos supervisados, particularmente en los problemas de regresión, dado que la evaluación en el aprendizaje no supervisado suele ser más cualitativa y subjetiva.</p>
<p>Una vez que se han definido <strong>las métricas de evaluación</strong>, el siguiente paso es garantizar que el modelo sea capaz de generalizar a datos nuevos. Para ello, se utilizan técnicas como la <strong>validación cruzada</strong> y la <strong>selección de hiperparámetros</strong>.</p>
<section id="validacion-cruzada-cross-validation">
<h4><strong>Validación cruzada (Cross-Validation)</strong><a class="headerlink" href="#validacion-cruzada-cross-validation" title="Permalink to this heading">#</a></h4>
<p>La <strong>validación cruzada</strong> es un método estadístico utilizado para evaluar el rendimiento de un modelo de manera más estable y exhaustiva que simplemente dividiendo los datos en un conjunto de entrenamiento y otro de prueba. En la validación cruzada, los datos se dividen varias veces y se entrenan múltiples modelos para obtener una mejor estimación de la capacidad de generalización del modelo.</p>
<p>La forma más común de validación cruzada es la <strong>validación cruzada k-fold</strong>, donde <span class="math notranslate nohighlight">\(k\)</span> es un número especificado por el usuario, típicamente 5 o 10.</p>
<div class="note admonition">
<p class="admonition-title"><strong>¿Cómo funciona la validación cruzada k-fold?</strong></p>
<p>En la <strong>validación cruzada five-fold (k=5)</strong>, los datos se dividen en cinco partes de tamaño (aproximadamente) igual, llamadas <strong>pliegues (folds)</strong>. Luego, se sigue un proceso iterativo de entrenamiento y evaluación de modelos:</p>
<ol class="arabic simple">
<li><p><strong>Primera iteración:</strong> El primer modelo se entrena utilizando los pliegues 2, 3, 4 y 5 como conjunto de entrenamiento, y el pliegue 1 se utiliza como conjunto de prueba. Se evalúa el rendimiento del modelo, por ejemplo, calculando la métrica de <strong>accuracy</strong>.</p></li>
<li><p><strong>Segunda iteración:</strong> Se construye otro modelo, esta vez utilizando el pliegue 2 como conjunto de prueba y los pliegues 1, 3, 4 y 5 como conjunto de entrenamiento. Se evalúa nuevamente el modelo en el pliegue 2.</p></li>
<li><p><strong>Iteraciones restantes:</strong> El proceso se repite para los pliegues 3, 4 y 5, utilizando cada uno de ellos como conjunto de prueba una vez, mientras que los pliegues restantes se usan para el entrenamiento.</p></li>
</ol>
<p>Al final del proceso, se han entrenado y evaluado cinco modelos, cada uno utilizando un conjunto diferente de datos de prueba. Esto da lugar a cinco valores de <strong>accuracy</strong> (o cualquier otra métrica de evaluación utilizada). La estimación final del rendimiento del modelo se obtiene promediando estos cinco valores, lo que proporciona una medida más robusta y confiable de la capacidad de generalización del modelo.</p>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de la validación cruzada k-fold</strong></p>
<ul class="simple">
<li><p><strong>Mejor estimación de la generalización:</strong> Al evaluar el modelo en diferentes subconjuntos de los datos, se obtiene una estimación más precisa y menos dependiente de una sola partición específica.</p></li>
<li><p><strong>Maximiza el uso de los datos:</strong> Cada muestra en el conjunto de datos se utiliza tanto para el entrenamiento como para la evaluación, lo que es especialmente útil en conjuntos de datos pequeños.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Consideraciones al usar validación cruzada</strong></p>
<ul class="simple">
<li><p><strong>Costo computacional:</strong> Entrenar y evaluar el modelo <span class="math notranslate nohighlight">\(k\)</span> veces puede ser costoso para conjuntos de datos grandes o modelos complejos.</p></li>
<li><p><strong>Elección de <span class="math notranslate nohighlight">\(k\)</span>:</strong> Valores típicos son 5 o 10, aunque un valor mayor de <span class="math notranslate nohighlight">\(k\)</span> puede proporcionar una mejor estimación a costa de un mayor tiempo de cómputo.</p></li>
</ul>
<p>La validación cruzada es una herramienta fundamental en el aprendizaje automático para evaluar de manera confiable el rendimiento de un modelo y evitar problemas de sobreajuste.</p>
</div>
<section id="tipos-de-validacion-cruzada">
<h5><strong>Tipos de validación cruzada</strong><a class="headerlink" href="#tipos-de-validacion-cruzada" title="Permalink to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>Validación cruzada k-fold:</strong></p>
<ul class="simple">
<li><p>Es el enfoque más común y se recomienda para la mayoría de los problemas.</p></li>
<li><p>Un valor típico es <span class="math notranslate nohighlight">\(k = 5\)</span> o <span class="math notranslate nohighlight">\(k = 10\)</span>, aunque se pueden usar valores mayores.</p></li>
<li><p>A medida que <span class="math notranslate nohighlight">\(k\)</span> aumenta, el sesgo de la evaluación disminuye, pero el costo computacional aumenta.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_cross_validation</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aa557bdb5079f148667eb0825fd90cf07b0c8d074e9c1df1bb09be72ea85c648.png" src="_images/aa557bdb5079f148667eb0825fd90cf07b0c8d074e9c1df1bb09be72ea85c648.png" />
</div>
</div>
<p>Normalmente, la primera quinta parte de los datos es conocida como el primer fold, la segunda quinta parte de los datos es el segundo fold, y así sucesivamente.</p>
<ul class="simple">
<li><p>Continuando con el conjunto de datos del <strong>precio promedio de las casas</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Realizar la validación cruzada con 10 folds</span>
<span class="c1"># &#39;lr&#39; es el modelo de regresión logística previamente entrenado</span>
<span class="c1"># &#39;X&#39; son las características del conjunto de datos housing</span>
<span class="c1"># &#39;y&#39; son las etiquetas de las clases en el conjunto de datos Iris</span>
<span class="c1"># &#39;cv=10&#39; especifica que se debe usar validación cruzada con 10 folds</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Imprimir los puntajes obtenidos en cada fold de la validación cruzada</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.65502997 0.64909796 0.66022841 0.64668711 0.62666713]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Una forma habitual de <strong>resumir la precisión de la validación cruzada es calcular la media y la desviación estandar</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar los resultados</span>
<span class="n">mean_score</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">std_score</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">mean_score</span><span class="p">,</span> <span class="n">std_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.6474801707218913, 0.02229181975018435)
</pre></div>
</div>
</div>
</div>
<p>Utilizando la validación cruzada con 10 pliegues (k-fold cross-validation), podemos concluir que esperamos que el modelo tenga una precisión media (medida en términos de <span class="math notranslate nohighlight">\(R^2\)</span>) de aproximadamente 0.49. Esto sugiere que el modelo es capaz de explicar cerca del 49% de la variabilidad en los valores de las viviendas.</p>
<p>Si observamos los resultados de la validación cruzada, la desviación estándar de los puntajes <span class="math notranslate nohighlight">\(R^2\)</span> es de aproximadamente 0.12. Esto indica que hay una variación moderada en la precisión entre los diferentes pliegues. Los puntajes <span class="math notranslate nohighlight">\(R^2\)</span> oscilan alrededor del promedio de 0.49, lo que sugiere que el rendimiento del modelo varía según la partición de los datos utilizada para el entrenamiento y la prueba.</p>
<p><strong>Posibles Implicaciones</strong>:</p>
<ul class="simple">
<li><p><strong>Dependencia de los pliegues:</strong> La variabilidad en los puntajes podría indicar que el modelo es sensible a los pliegues específicos utilizados para el entrenamiento. Esto puede ser un indicio de que el modelo no está generalizando de manera óptima en todas las particiones.</p></li>
<li><p><strong>Tamaño del conjunto de datos:</strong> La variación también podría ser una consecuencia de la cantidad y calidad de los datos disponibles. Si el conjunto de datos es relativamente pequeño o no representa suficientemente la distribución de los datos reales, la validación cruzada puede mostrar una variabilidad mayor en los resultados.</p></li>
</ul>
<p>En resumen, aunque el modelo muestra una precisión media moderada, la variabilidad entre los pliegues sugiere que se podrían considerar ajustes adicionales al modelo o al preprocesamiento de los datos para mejorar la consistencia del rendimiento.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Validación cruzada estratificada:</strong></p>
<ul class="simple">
<li><p>Se usa principalmente en problemas de clasificación, donde la distribución de clases se mantiene aproximadamente igual en cada fold.</p></li>
<li><p>Ayuda a evitar problemas si una clase es mucho menos frecuente que las otras.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_stratified_cross_validation</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/cfc2289b827814972bc54341ab0482a351d0c498542b5ce562db9dd6475c512f.png" src="_images/cfc2289b827814972bc54341ab0482a351d0c498542b5ce562db9dd6475c512f.png" />
</div>
</div>
<ul class="simple">
<li><p>Hagamos la validación cruzada estratificada</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="c1"># Ignorar advertencias de futuras versiones</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 

<span class="c1"># Convertir la variable objetivo en categorías para realizar la estratificación</span>
<span class="c1"># Usaremos los cuartiles para dividir la variable objetivo en 4 categorías</span>
<span class="n">y_binned</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">qcut</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Configurar la validación cruzada estratificada</span>
<span class="n">stratified_kfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Realizar la validación cruzada con estratificación utilizando la regresión lineal</span>
<span class="n">stratified_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">stratified_kfold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Imprimir los puntajes obtenidos en cada fold de la validación cruzada</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stratified_scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.67575123 0.64399604 0.65134703 0.63949908 0.6551713  0.65445309
 0.66368391 0.65250726 0.59160867 0.64839183]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar los resultados</span>
<span class="n">stratified_mean_score</span> <span class="o">=</span> <span class="n">stratified_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">stratified_std_score</span> <span class="o">=</span> <span class="n">stratified_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">stratified_mean_score</span><span class="p">,</span> <span class="n">stratified_std_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.6476409436205404, 0.020994872943330658)
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Shuffle-Split Cross-Validation:</strong></p>
<ul class="simple">
<li><p>Divide el conjunto de datos en un conjunto de entrenamiento y prueba varias veces (número especificado de iteraciones) con un tamaño de muestra diferente en cada iteración.</p></li>
<li><p>Es útil cuando el conjunto de datos es muy grande.</p></li>
</ul>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_shuffle_split</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/93a69c5bb20c86ef358bc7af0a3d733edd8727015f5bb0b0a63667ca0dbb706c.png" src="_images/93a69c5bb20c86ef358bc7af0a3d733edd8727015f5bb0b0a63667ca0dbb706c.png" />
</div>
</div>
<ul class="simple">
<li><p>Hagamos la validación cruzada aleatoria y dividida</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>

<span class="c1"># Configurar la validación cruzada ShuffleSplit</span>
<span class="n">shuffle_split</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Realizar la validación cruzada utilizando ShuffleSplit con la regresión lineal</span>
<span class="n">shuffle_split_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">shuffle_split</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Imprimir los puntajes obtenidos en cada fold de la validación cruzada</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shuffle_split_scores</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validation scores: [0.64701625 0.64923413 0.64515198 0.65042711 0.64160176 0.64603228
 0.66995032 0.6611581  0.62929803 0.65992796]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Mostrar los resultados</span>
<span class="n">shuffle_split_mean_score</span> <span class="o">=</span> <span class="n">shuffle_split_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">shuffle_split_std_score</span> <span class="o">=</span> <span class="n">shuffle_split_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">shuffle_split_mean_score</span><span class="p">,</span> <span class="n">shuffle_split_std_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.6499797919709206, 0.010812486515730819)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El puntaje promedio de <span class="math notranslate nohighlight">\(R^2\)</span> es similar al obtenido con la validación cruzada estratificada (0.6369), lo que indica que el modelo tiene un rendimiento comparable.</p></li>
<li><p>La desviación estándar es más baja (0.0117), lo que sugiere una mayor consistencia en los puntajes de los diferentes pliegues en comparación con la validación cruzada estratificada.</p></li>
</ul>
<p>En general, el uso de <code class="docutils literal notranslate"><span class="pre">ShuffleSplit</span></code> ofrece una buena alternativa para evaluar la capacidad de generalización del modelo, proporcionando resultados estables y consistentes.</p>
<ol class="arabic simple" start="4">
<li><p><strong>Leave-One-Out Cross-Validation (LOOCV):</strong></p>
<ul class="simple">
<li><p>Es un caso especial de k-fold donde <span class="math notranslate nohighlight">\(k\)</span> es igual al número de observaciones en el conjunto de datos.</p></li>
<li><p>Cada muestra se utiliza una vez como conjunto de prueba, y el resto de los datos como conjunto de entrenamiento.</p></li>
<li><p>Es útil en conjuntos de datos muy pequeños, pero puede ser costoso computacionalmente en conjuntos grandes.</p></li>
</ul>
</li>
</ol>
<p>Ahora, <strong>haremos el proceso solo por prueba</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>

<span class="c1"># Configurar la validación cruzada Leave-One-Out</span>
<span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>

<span class="c1"># Realizar la validación cruzada utilizando Leave-One-Out con la regresión lineal</span>
<span class="n">loo_scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train_scaler</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">loo</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Imprimir los puntajes obtenidos en cada fold de la validación cruzada</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validation scores: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loo_scores</span><span class="p">))</span>

<span class="c1"># Mostrar los resultados</span>
<span class="n">loo_mean_score</span> <span class="o">=</span> <span class="n">loo_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">loo_std_score</span> <span class="o">=</span> <span class="n">loo_scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

<span class="n">loo_mean_score</span><span class="p">,</span> <span class="n">loo_std_score</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(nan, nan)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="concepto-de-grid-search-busqueda-de-grilla">
<h4><strong>Concepto de Grid Search (busqueda de grilla)</strong><a class="headerlink" href="#concepto-de-grid-search-busqueda-de-grilla" title="Permalink to this heading">#</a></h4>
<p><strong>Grid Search</strong> es un método de búsqueda exhaustiva para encontrar la mejor combinación de hiperparámetros para un modelo de aprendizaje automático. La idea es definir un conjunto de posibles valores para cada hiperparámetro y probar todas las combinaciones posibles para determinar cuál produce el mejor rendimiento del modelo, normalmente utilizando una métrica de evaluación específica, como la precisión o el error cuadrático medio.</p>
<p>El proceso de Grid Search incluye:</p>
<ol class="arabic simple">
<li><p><strong>Definir la malla de hiperparámetros (<code class="docutils literal notranslate"><span class="pre">param_grid</span></code>)</strong>: Un conjunto de valores posibles para cada hiperparámetro del modelo.</p></li>
<li><p><strong>Entrenar el modelo para cada combinación de hiperparámetros</strong>: Se realiza una validación cruzada para evaluar el rendimiento de cada combinación.</p></li>
<li><p><strong>Seleccionar la mejor combinación</strong>: La combinación de hiperparámetros que obtiene el mejor rendimiento en la métrica de evaluación se selecciona como la óptima.</p></li>
</ol>
<section id="modelos-de-regresion-que-pueden-usar-grid-search-para-hiperparametrizacion">
<h5><strong>Modelos de Regresión que pueden usar Grid Search para hiperparametrización</strong><a class="headerlink" href="#modelos-de-regresion-que-pueden-usar-grid-search-para-hiperparametrizacion" title="Permalink to this heading">#</a></h5>
<p>Grid Search se puede aplicar a varios modelos de regresión que tienen hiperparámetros ajustables. A continuación, se presentan algunos modelos comunes de regresión y la malla de hiperparámetros típica que se puede utilizar para cada uno.</p>
<ol class="arabic simple">
<li><p><strong>Regresión Ridge</strong></p></li>
</ol>
<p>La regresión Ridge es una variante de la regresión lineal que incluye una penalización para reducir la magnitud de los coeficientes del modelo. Los hiperparámetros importantes son:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">alpha</span></code></strong>: Controla la magnitud de la penalización. Un valor más alto implica una mayor regularización.</p></li>
</ul>
<p><strong>Malla de Hiperparámetros para Ridge:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span>  <span class="c1"># Factor de regularización (valor mayor implica más regularización)</span>
        <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span> <span class="s1">&#39;cholesky&#39;</span><span class="p">,</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>  <span class="c1"># Algoritmo para optimización</span>
    <span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p><strong>Regresión Lasso</strong></p></li>
</ol>
<p>La regresión Lasso también es una variante de la regresión lineal, pero utiliza una penalización <span class="math notranslate nohighlight">\(L^1\)</span>, que puede llevar a coeficientes exactamente iguales a cero.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code>: Controla la magnitud de la penalización.</p></li>
</ul>
<p><strong>Malla de Hiperparámetros para Lasso:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span>  <span class="c1"># Regularización L1 que fuerza algunos coeficientes a 0</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span>  <span class="c1"># Número máximo de iteraciones</span>
        <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">],</span>  <span class="c1"># Tolerancia para criterio de convergencia</span>
    <span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Regresión Elastic Net</strong></p></li>
</ol>
<p>Elastic Net combina las penalizaciones de Ridge y Lasso.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">alpha</span></code>: Controla la magnitud de la penalización.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code>: Controla la mezcla entre la penalización <span class="math notranslate nohighlight">\(L^1\)</span> (Lasso) y <span class="math notranslate nohighlight">\(L^2\)</span> (Ridge). Un valor de <span class="math notranslate nohighlight">\(0\)</span> equivale a Ridge, y un valor de 1 equivale a Lasso.</p></li>
</ul>
<p><strong>Malla de Hiperparámetros para ElasticNet:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span>  <span class="c1"># Parámetro de regularización</span>
        <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>  <span class="c1"># Mezcla entre L1 (Lasso) y L2 (Ridge)</span>
        <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span>  <span class="c1"># Número máximo de iteraciones</span>
        <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">],</span>  <span class="c1"># Tolerancia para criterio de convergencia</span>
    <span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p><strong>Regresión de K-Vecinos Más Cercanos (KNN Regression)</strong>
El modelo <code class="docutils literal notranslate"><span class="pre">KNN</span></code> para regresión predice el valor de la variable objetivo basándose en los valores de los vecinos más cercanos.</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code>: Número de vecinos considerados.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weights</span></code>: Función de ponderación (<code class="docutils literal notranslate"><span class="pre">'uniform'</span></code> o <code class="docutils literal notranslate"><span class="pre">'distance'</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code>: Parámetro de la distancia de Minkowski. <span class="math notranslate nohighlight">\(p=2\)</span> es la distancia <strong>euclidiana</strong>, y <span class="math notranslate nohighlight">\(p=1\)</span> es la distancia de <strong>Manhattan</strong>.</p></li>
</ul>
<p><strong>Malla de Hiperparámetros para KNN regression:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>  <span class="c1"># Número de vecinos más cercanos considerados</span>
        <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>  <span class="c1"># Pesos uniformes o basados en la distancia</span>
        <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;ball_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;kd_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;brute&#39;</span><span class="p">],</span>  <span class="c1"># Algoritmo para computar vecinos más cercanos</span>
        <span class="s1">&#39;leaf_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>  <span class="c1"># Tamaño de la hoja en el árbol</span>
        <span class="s1">&#39;p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># Distancia de Minkowski: 1 para Manhattan, 2 para Euclidiana</span>
    <span class="p">}</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p><strong>Support Vector Regression (SVR)</strong>
El modelo SVR es una versión del algoritmo de Máquinas de Soporte Vectorial (SVM) aplicada a problemas de regresión.</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">C</span></code>: Parámetro de penalización que controla el trade-off entre un ajuste perfecto del modelo y la suavidad de la función de decisión.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code>: Coeficiente del kernel que define la influencia de un solo punto de entrenamiento. Aplica a kernels no lineales como <code class="docutils literal notranslate"><span class="pre">'rbf'</span></code> o <code class="docutils literal notranslate"><span class="pre">'poly'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel</span></code>: Tipo de kernel utilizado en el modelo (por ejemplo, ‘linear’, ‘poly’, ‘rbf’).</p></li>
</ul>
<p><strong>Malla de Hiperparámetros para SVR:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span>  <span class="c1"># Tipo de función para transformar el espacio de características</span>
        <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">],</span>  <span class="c1"># Parámetro de penalización para regularización</span>
        <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">],</span>  <span class="c1"># Coeficiente de kernel que define la influencia de cada punto de soporte</span>
        <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>  <span class="c1"># Grado del kernel &#39;poly&#39; (solo si kernel=&#39;poly&#39;)</span>
        <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># Tolerancia a errores en SVR</span>
    <span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="grid-search-con-validacion-cruzada">
<h4><strong>Grid Search con validación cruzada</strong><a class="headerlink" href="#grid-search-con-validacion-cruzada" title="Permalink to this heading">#</a></h4>
<p>Para una mejor estimación del rendimiento de la generalización, <strong>en lugar de usar una única división en un conjunto de entrenamiento y otro de validación, podemos usar la validación cruzada para evaluar el rendimiento de cada combinación de parámetros</strong>.</p>
<ul class="simple">
<li><p>El proceso general de división de los datos, la ejecución de grid search y la evaluación de los parámetros finales se ilustra en la siguiente figura</p></li>
</ul>
<p><img alt="mod" src="_images/mod.png" /></p>
<ul class="simple">
<li><p>Debido a que <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> con <strong>validación cruzada</strong> es un método tan comúnmente utilizado para ajustar parámetros, <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> proporciona la clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, que lo implementa en la forma de un estimador. Para utilizar la clase <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, primero hay que especificar los parámetros sobre los que se quiere buscar utilizando un <strong>diccionario</strong>.</p></li>
</ul>
</section>
<section id="analisis-completo-de-los-modelos">
<h4><strong>Análisis completo de los modelos</strong><a class="headerlink" href="#analisis-completo-de-los-modelos" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Carguemos la libreria</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Cargar sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Separemos el conjunto de entrenamiento y el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">datos</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;ocean_proximity&#39;</span><span class="p">],</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">datos</span> <span class="o">=</span> <span class="n">datos</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">array</span> <span class="o">=</span> <span class="n">datos</span><span class="o">.</span><span class="n">values</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">array</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">8</span><span class="p">],</span> <span class="n">array</span><span class="p">[:,</span> <span class="mi">9</span><span class="p">:</span><span class="mi">12</span><span class="p">]))</span>  <span class="c1"># Ajustar índices según las columnas</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">array</span><span class="p">[:,</span> <span class="mi">8</span><span class="p">]</span>  <span class="c1"># Ajustar índice según la columna de salida</span>
<span class="n">validation_size</span> <span class="o">=</span> <span class="mf">0.20</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="n">validation_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="modelo-rigde">
<h5><strong>Modelo Rigde</strong><a class="headerlink" href="#modelo-rigde" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Encontremos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica Ridge</span>
<span class="n">pipeline_ridge</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">Ridge</span><span class="p">())</span>

<span class="c1"># Definir el rango de valores para el parámetro alpha</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;ridge__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span>  <span class="c1"># Usar &#39;ridge__alpha&#39; para especificar el paso del pipeline</span>
    <span class="s1">&#39;ridge__solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;svd&#39;</span><span class="p">,</span> <span class="s1">&#39;cholesky&#39;</span><span class="p">,</span> <span class="s1">&#39;lsqr&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">]</span>  <span class="c1"># Usar &#39;ridge__solver&#39;</span>
<span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_ridge</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_ridge</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 36 candidates, totalling 180 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-6 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-6 {
  color: var(--sklearn-color-text);
}

#sk-container-id-6 pre {
  padding: 0;
}

#sk-container-id-6 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-6 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-6 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-6 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-6 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-6 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-6 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-6 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-6 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-6 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-6 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-6 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-6 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-6 div.sk-label label.sk-toggleable__label,
#sk-container-id-6 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-6 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-6 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-6 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-6 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-6 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-6 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-6 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-6 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;ridge&#x27;, Ridge())]),
             n_jobs=-1,
             param_grid={&#x27;ridge__alpha&#x27;: [0.01, 0.1, 1, 10, 100, 1000],
                         &#x27;ridge__solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,
                                           &#x27;sag&#x27;, &#x27;saga&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-17" type="checkbox" ><label for="sk-estimator-id-17" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;ridge&#x27;, Ridge())]),
             n_jobs=-1,
             param_grid={&#x27;ridge__alpha&#x27;: [0.01, 0.1, 1, 10, 100, 1000],
                         &#x27;ridge__solver&#x27;: [&#x27;auto&#x27;, &#x27;svd&#x27;, &#x27;cholesky&#x27;, &#x27;lsqr&#x27;,
                                           &#x27;sag&#x27;, &#x27;saga&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-18" type="checkbox" ><label for="sk-estimator-id-18" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;ridge&#x27;, Ridge(alpha=100, solver=&#x27;lsqr&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox" ><label for="sk-estimator-id-19" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox" ><label for="sk-estimator-id-20" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;Ridge<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Ridge.html">?<span>Documentation for Ridge</span></a></label><div class="sk-toggleable__content fitted"><pre>Ridge(alpha=100, solver=&#x27;lsqr&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Estos son los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor valor de alpha:&quot;</span><span class="p">,</span> <span class="n">grid_search_ridge</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;ridge__alpha&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor solver:&quot;</span><span class="p">,</span> <span class="n">grid_search_ridge</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;ridge__solver&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor valor de alpha: 100
Mejor solver: lsqr
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Calculo de las métricas</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_ridge</span> <span class="o">=</span> <span class="n">grid_search_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_ridge</span> <span class="o">=</span> <span class="n">grid_search_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_ridge</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_ridge</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_ridge</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_ridge</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4997226516.784906,
 5148884165.804705,
 70691.06391040458,
 71755.72566565475,
 0.6261738504777423,
 0.6070780762875576)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-lasso">
<h5><strong>Modelo Lasso</strong><a class="headerlink" href="#modelo-lasso" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Hallemos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica Lasso</span>
<span class="n">pipeline_lasso</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">Lasso</span><span class="p">())</span>

<span class="c1"># Definir el rango de valores para el parámetro alpha</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;lasso__alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span>
        <span class="s1">&#39;lasso__max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">],</span>
    <span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_lasso</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_lasso</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 18 candidates, totalling 90 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;lasso&#x27;, Lasso())]),
             n_jobs=-1,
             param_grid={&#x27;lasso__alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000],
                         &#x27;lasso__max_iter&#x27;: [1000, 5000, 10000]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" ><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;lasso&#x27;, Lasso())]),
             n_jobs=-1,
             param_grid={&#x27;lasso__alpha&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000],
                         &#x27;lasso__max_iter&#x27;: [1000, 5000, 10000]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" ><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;lasso&#x27;, Lasso(alpha=10.0))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" ><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" ><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;Lasso<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Lasso.html">?<span>Documentation for Lasso</span></a></label><div class="sk-toggleable__content fitted"><pre>Lasso(alpha=10.0)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor valor de alpha:&quot;</span><span class="p">,</span> <span class="n">grid_search_lasso</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;lasso__alpha&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor número de iteraciones:&quot;</span><span class="p">,</span> <span class="n">grid_search_lasso</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;lasso__max_iter&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor valor de alpha: 10.0
Mejor número de iteraciones: 1000
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Obtención de las métricas</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_lasso</span> <span class="o">=</span> <span class="n">grid_search_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_lasso</span> <span class="o">=</span> <span class="n">grid_search_lasso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_lasso</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_lasso</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_lasso</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_lasso</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(4995286862.525667,
 5159521928.49166,
 70677.34334654683,
 71829.81225432557,
 0.6263189496603991,
 0.6062662867727119)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-por-k-vecinos">
<h5><strong>Modelo por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong><a class="headerlink" href="#modelo-por-k-vecinos" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Encontremos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica KNN</span>
<span class="n">pipeline_knn</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">KNeighborsRegressor</span><span class="p">())</span>

<span class="c1"># Definir el rango de valores para knn regression</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;kneighborsregressor__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span>  <span class="c1"># Número de vecinos a considerar</span>
    <span class="s1">&#39;kneighborsregressor__weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>  <span class="c1"># Pesos uniformes o basados en la distancia</span>
    <span class="s1">&#39;kneighborsregressor__p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>  <span class="c1"># Distancia de Minkowski: 1 para Manhattan, 2 para Euclidiana</span>
<span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_knn</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_knn</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 96 candidates, totalling 480 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-7 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-7 {
  color: var(--sklearn-color-text);
}

#sk-container-id-7 pre {
  padding: 0;
}

#sk-container-id-7 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-7 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-7 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-7 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-7 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-7 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-7 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-7 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-7 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-7 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-7 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-7 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-7 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-7 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-7 div.sk-label label.sk-toggleable__label,
#sk-container-id-7 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-7 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-7 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-7 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-7 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-7 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-7 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-7 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-7 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-7 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-7 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-7" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;kneighborsregressor&#x27;,
                                        KNeighborsRegressor())]),
             n_jobs=-1,
             param_grid={&#x27;kneighborsregressor__n_neighbors&#x27;: range(1, 25),
                         &#x27;kneighborsregressor__p&#x27;: [1, 2],
                         &#x27;kneighborsregressor__weights&#x27;: [&#x27;uniform&#x27;,
                                                          &#x27;distance&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-21" type="checkbox" ><label for="sk-estimator-id-21" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;kneighborsregressor&#x27;,
                                        KNeighborsRegressor())]),
             n_jobs=-1,
             param_grid={&#x27;kneighborsregressor__n_neighbors&#x27;: range(1, 25),
                         &#x27;kneighborsregressor__p&#x27;: [1, 2],
                         &#x27;kneighborsregressor__weights&#x27;: [&#x27;uniform&#x27;,
                                                          &#x27;distance&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-22" type="checkbox" ><label for="sk-estimator-id-22" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;kneighborsregressor&#x27;,
                 KNeighborsRegressor(n_neighbors=13, p=1, weights=&#x27;distance&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox" ><label for="sk-estimator-id-23" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-24" type="checkbox" ><label for="sk-estimator-id-24" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;KNeighborsRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html">?<span>Documentation for KNeighborsRegressor</span></a></label><div class="sk-toggleable__content fitted"><pre>KNeighborsRegressor(n_neighbors=13, p=1, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los parámetros adecuados son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor número de vecinos:&quot;</span><span class="p">,</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;kneighborsregressor__n_neighbors&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor peso :&quot;</span><span class="p">,</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;kneighborsregressor__weights&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor distancia:&quot;</span><span class="p">,</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;kneighborsregressor__p&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor número de vecinos: 13
Mejor peso : distance
Mejor distancia: 1
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Las métricas del modelo son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_knn</span> <span class="o">=</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_knn</span> <span class="o">=</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_knn</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_knn</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_knn</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_knn</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0.0, 3702445077.724001, 0.0, 60847.720398746256, 1.0, 0.7174588133016164)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-por-svr-con-kernel-lineal">
<h5><strong>Modelo por SVR con kernel lineal</strong><a class="headerlink" href="#modelo-por-svr-con-kernel-lineal" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Hallemos los parámetros adecuados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica SVR lineal</span>
<span class="n">pipeline_svrlineal</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>

<span class="c1"># Definir el rango de valores para svr con kernel lineal</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;svr__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">],</span>
        <span class="s1">&#39;svr__gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">],</span>
    <span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_svrlineal</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_svrlineal</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_svrlineal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 8 candidates, totalling 40 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-8 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-8 {
  color: var(--sklearn-color-text);
}

#sk-container-id-8 pre {
  padding: 0;
}

#sk-container-id-8 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-8 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-8 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-8 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-8 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-8 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-8 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-8 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-8 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-8 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-8 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-8 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-8 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-8 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-8 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-8 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-8 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-8 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-8 div.sk-label label.sk-toggleable__label,
#sk-container-id-8 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-8 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-8 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-8 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-8 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-8 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-8 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-8 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-8 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-8 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-8 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-8" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR(kernel=&#x27;linear&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-25" type="checkbox" ><label for="sk-estimator-id-25" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR(kernel=&#x27;linear&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-26" type="checkbox" ><label for="sk-estimator-id-26" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;svr&#x27;, SVR(C=100000, kernel=&#x27;linear&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-27" type="checkbox" ><label for="sk-estimator-id-27" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-28" type="checkbox" ><label for="sk-estimator-id-28" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVR<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html">?<span>Documentation for SVR</span></a></label><div class="sk-toggleable__content fitted"><pre>SVR(C=100000, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor C:&quot;</span><span class="p">,</span> <span class="n">grid_search_svrlineal</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__C&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor gamma :&quot;</span><span class="p">,</span> <span class="n">grid_search_svrlineal</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__gamma&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor C: 100000
Mejor gamma : scale
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Las métricas del modelo son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_svrlineal</span> <span class="o">=</span> <span class="n">grid_search_svrlineal</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_svrlineal</span> <span class="o">=</span> <span class="n">grid_search_svrlineal</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrlineal</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrlineal</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrlineal</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrlineal</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5167509129.217195,
 5336539014.078915,
 71885.3888437504,
 73051.61883270564,
 0.6134355659268336,
 0.5927577494743119)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-por-svr-con-kernel-polinomial">
<h5><strong>Modelo por SVR con kernel polinomial</strong><a class="headerlink" href="#modelo-por-svr-con-kernel-polinomial" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Hallemos los parámetros adecuados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica SVR polinomial</span>
<span class="n">pipeline_svrpoly</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">))</span>

<span class="c1"># Definir el rango de valores para svr con kernel polinomial</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;svr__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">],</span>
        <span class="s1">&#39;svr__gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">],</span>
    <span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_svrpoly</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_svrpoly</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_svrpoly</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 8 candidates, totalling 40 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR(kernel=&#x27;poly&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-17" type="checkbox" ><label for="sk-estimator-id-17" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR(kernel=&#x27;poly&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-18" type="checkbox" ><label for="sk-estimator-id-18" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;svr&#x27;, SVR(C=10000, kernel=&#x27;poly&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox" ><label for="sk-estimator-id-19" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox" ><label for="sk-estimator-id-20" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVR<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html">?<span>Documentation for SVR</span></a></label><div class="sk-toggleable__content fitted"><pre>SVR(C=10000, kernel=&#x27;poly&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor C:&quot;</span><span class="p">,</span> <span class="n">grid_search_svrpoly</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__C&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor gamma :&quot;</span><span class="p">,</span> <span class="n">grid_search_svrpoly</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__gamma&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor C: 10000
Mejor gamma : scale
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Las métricas del modelo son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_svrpoly</span> <span class="o">=</span> <span class="n">grid_search_svrpoly</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_svrpoly</span> <span class="o">=</span> <span class="n">grid_search_svrpoly</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrpoly</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrpoly</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrpoly</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrpoly</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(5487810335.070073,
 5633444245.625004,
 74079.75658079657,
 75056.27385918518,
 0.5894748817214769,
 0.5701003015724625)
</pre></div>
</div>
</div>
</div>
</section>
<section id="modelo-por-svr-con-kernel-rbf">
<h5><strong>Modelo por SVR con kernel RBF</strong><a class="headerlink" href="#modelo-por-svr-con-kernel-rbf" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Hallemos los parámetros adecuados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear un pipeline que estandariza los datos y aplica SVR radial</span>
<span class="n">pipeline_svrrbf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">))</span>

<span class="c1"># Definir el rango de valores para svr con kernel rbf</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;svr__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">],</span>
        <span class="s1">&#39;svr__gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">],</span>
    <span class="p">}</span>

<span class="c1"># Configurar el Grid Search con validación cruzada</span>
<span class="n">grid_search_svrrbf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipeline_svrrbf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Ejecutar el Grid Search (mejor modelo)</span>
<span class="n">grid_search_svrrbf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 8 candidates, totalling 40 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-9 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-9 {
  color: var(--sklearn-color-text);
}

#sk-container-id-9 pre {
  padding: 0;
}

#sk-container-id-9 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-9 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-9 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-9 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-9 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-9 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-9 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-9 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-9 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-9 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-9 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-9 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-9 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-9 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-9 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-9 div.sk-label label.sk-toggleable__label,
#sk-container-id-9 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-9 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-9 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-9 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-9 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-9 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-9 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-9 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-9 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-9 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-9 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-9 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-9" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR())]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-29" type="checkbox" ><label for="sk-estimator-id-29" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=5,
             estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                                       (&#x27;svr&#x27;, SVR())]),
             n_jobs=-1,
             param_grid={&#x27;svr__C&#x27;: [1000, 10000, 100000, 1000000],
                         &#x27;svr__gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;]},
             scoring=&#x27;r2&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-30" type="checkbox" ><label for="sk-estimator-id-30" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),
                (&#x27;svr&#x27;, SVR(C=1000000, gamma=&#x27;auto&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-31" type="checkbox" ><label for="sk-estimator-id-31" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;StandardScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html">?<span>Documentation for StandardScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>StandardScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-32" type="checkbox" ><label for="sk-estimator-id-32" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVR<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVR.html">?<span>Documentation for SVR</span></a></label><div class="sk-toggleable__content fitted"><pre>SVR(C=1000000, gamma=&#x27;auto&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimir los mejores parámetros encontrados</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor C:&quot;</span><span class="p">,</span> <span class="n">grid_search_svrrbf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__C&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejor gamma :&quot;</span><span class="p">,</span> <span class="n">grid_search_svrrbf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">[</span><span class="s1">&#39;svr__gamma&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejor C: 1000000
Mejor gamma : auto
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Las métricas del modelo son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predecir utilizando el modelo ajustado y calcular métricas</span>
<span class="n">y_train_preds_svrrbf</span> <span class="o">=</span> <span class="n">grid_search_svrrbf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_test_preds_svrrbf</span> <span class="o">=</span> <span class="n">grid_search_svrrbf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">mse_train</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrrbf</span><span class="p">)</span>
<span class="n">rmse_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_train</span><span class="p">)</span>

<span class="n">mse_test</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrrbf</span><span class="p">)</span>
<span class="n">rmse_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_test</span><span class="p">)</span>

<span class="c1"># Calcular el R^2</span>
<span class="n">r2_test</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_preds_svrrbf</span><span class="p">)</span>
<span class="n">r2_train</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_train_preds_svrrbf</span><span class="p">)</span>

<span class="c1">#imprimir</span>
<span class="n">mse_train</span><span class="p">,</span> <span class="n">mse_test</span><span class="p">,</span> <span class="n">rmse_train</span><span class="p">,</span> <span class="n">rmse_test</span><span class="p">,</span> <span class="n">r2_train</span><span class="p">,</span> <span class="n">r2_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(3076233718.8355017,
 3484771151.73479,
 55463.80548461764,
 59031.95026199617,
 0.7698770303326818,
 0.7340699575782237)
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparacion-de-rendimiento-de-modelos">
<h5><strong>Comparación de rendimiento de modelos</strong><a class="headerlink" href="#comparacion-de-rendimiento-de-modelos" title="Permalink to this heading">#</a></h5>
<p>A continuación realizamos la estandarización y división de los datos, de igual forma se define el <code class="docutils literal notranslate"><span class="pre">scoring</span></code> como métrica para la evaluación del rendimiento de cada uno de los modelos aplicados en este informe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Definir parámetros para RL</span>
<span class="n">modelo_rl_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">LinearRegression</span><span class="p">())</span>

<span class="c1">#Definir parámetros para Ridge</span>
<span class="n">modelo_ridge_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lsqr&#39;</span><span class="p">))</span>

<span class="c1">#Definir parámetros para Lasso</span>
<span class="n">modelo_lasso_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>

<span class="c1"># Definir parámetros para KNN</span>
<span class="n">model_knn_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;distance&#39;</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1">#Definir parámetros para SVR linear</span>
<span class="n">modelo_svml_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;scale&#39;</span><span class="p">,</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>

<span class="c1">#Definir parámetros para SVR poly</span>
<span class="n">modelo_svmp_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">))</span>

<span class="c1">#Definir parámetros para SVR RBF</span>
<span class="n">modelo_svmrbf_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span><span class="n">SVR</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span> <span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Chequeo de algoritmos</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RL&#39;</span><span class="p">,</span> <span class="n">modelo_rl_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;RIDGE&#39;</span><span class="p">,</span> <span class="n">modelo_ridge_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;LASSO&#39;</span><span class="p">,</span> <span class="n">modelo_lasso_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;k-NN&#39;</span><span class="p">,</span> <span class="n">model_knn_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;SVM-Linear&#39;</span><span class="p">,</span> <span class="n">modelo_svml_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;SVM-Poly&#39;</span><span class="p">,</span> <span class="n">modelo_svmp_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;SVM-RBF&#39;</span><span class="p">,</span> <span class="n">modelo_svmrbf_plot</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Comparemos los modelos, calculando la media y la desviación estándar de MSE para cada uno de éstos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#ok</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#n_jobs = -1 es para que el codigo se ejecute mas rapido</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>
    <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">cv_results</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">,.3f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">cv_results</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">,.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RL: 0.625 (0.021)
RIDGE: 0.625 (0.021)
LASSO: 0.625 (0.021)
k-NN: 0.721 (0.019)
SVM-Linear: 0.613 (0.020)
SVM-Poly: 0.453 (0.372)
SVM-RBF: 0.750 (0.018)
</pre></div>
</div>
</div>
</div>
<p>Gráfica de las estimaciones de cada modelo por validación cruzada</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare Algorithms</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Algorithm Comparison&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/8e30e5ea58e0fe3d5230de09dde4a5d037d00ed38159b26398a4ba998ad3fe5f.png" src="_images/8e30e5ea58e0fe3d5230de09dde4a5d037d00ed38159b26398a4ba998ad3fe5f.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Ejercicios</strong></p>
<p>Exploralos modelos de regresión de <code class="docutils literal notranslate"><span class="pre">Random</span> <span class="pre">Forest</span></code> y <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code>, para el conjunto de datos <code class="docutils literal notranslate"><span class="pre">housing</span></code>.</p>
</div>
</section>
</section>
</section>
</section>
<section id="clasificacion">
<h2><strong>Clasificación</strong><a class="headerlink" href="#clasificacion" title="Permalink to this heading">#</a></h2>
<p>Los <strong>modelos de clasificación</strong> son algoritmos de aprendizaje automático que se utilizan para asignar una etiqueta o clase a cada muestra de datos de entrada. En otras palabras, estos modelos predicen categorías discretas o etiquetas de clase. Por ejemplo, en un problema de clasificación binaria, el objetivo puede ser predecir si se le entrega o no una tarjeta de credito. Para la clasificación multiclase, el modelo puede asignar una imagen a una de varias categorías, como perros, gatos o caballos.</p>
<section id="tipos-de-modelos-de-clasificacion">
<h3><strong>Tipos de Modelos de Clasificación</strong><a class="headerlink" href="#tipos-de-modelos-de-clasificacion" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Modelos Lineales</strong></p></li>
</ol>
<ul class="simple">
<li><p>Utilizan una combinación lineal de las características para predecir la clase.</p></li>
<li><p><strong>Ejemplos:</strong></p>
<ul>
<li><p><strong>Regresión Logística</strong>: Utiliza la función sigmoide para modelar la probabilidad de una clase binaria.</p></li>
<li><p><strong>Máquinas de Vectores de Soporte (SVM)</strong> con kernel lineal: Encuentra un hiperplano que separa las clases en el espacio de características.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Modelos basados en árboles</strong></p></li>
</ol>
<ul class="simple">
<li><p>Construyen un árbol de decisiones donde cada nodo representa una pregunta basada en las características, y las ramas llevan a diferentes decisiones (clases).</p></li>
<li><p><strong>Ejemplos:</strong></p>
<ul>
<li><p><strong>Árboles de Decisión</strong>: Separan los datos en subgrupos basados en características, de forma jerárquica.</p></li>
<li><p><strong>Random Forest</strong>: Combina múltiples árboles de decisión para mejorar la precisión y reducir el sobreajuste.</p></li>
<li><p><strong>Gradient Boosting</strong>: Construye árboles secuencialmente, corrigiendo los errores de los modelos anteriores.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Modelos de vecinos cercanos (KNN)</strong></p></li>
</ol>
<ul class="simple">
<li><p>Clasifican una muestra basándose en las etiquetas de sus vecinos más cercanos en el espacio de características.</p></li>
<li><p><strong>K-Nearest Neighbors (KNN)</strong>: Asigna la clase más común entre los ‘k’ vecinos más cercanos.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p><strong>Modelos Probabilísticos</strong></p></li>
</ol>
<ul class="simple">
<li><p>Utilizan la teoría de probabilidad para predecir la clase más probable dada una muestra de entrada.</p></li>
<li><p><strong>Ejemplos:</strong></p>
<ul>
<li><p><strong>Naive Bayes</strong>: Asume que las características son independientes entre sí, dado el valor de la clase.</p></li>
<li><p><strong>Gaussian Mixture Models (GMM)</strong>: Modela la distribución de datos como una combinación de múltiples distribuciones gaussianas.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Redes Neuronales</strong></p></li>
</ol>
<ul class="simple">
<li><p>Compuestas por capas de neuronas artificiales que transforman las entradas de manera no lineal para clasificar las muestras.</p></li>
<li><p><strong>Ejemplos:</strong></p>
<ul>
<li><p><strong>Redes Neuronales Artificiales (ANN)</strong>: Pueden ser simples con pocas capas o profundas (Deep Learning) con muchas capas.</p></li>
<li><p><strong>Convolutional Neural Networks (CNN)</strong>: Especialmente efectivas para clasificación de imágenes y datos con estructura espacial.</p></li>
<li><p><strong>Recurrent Neural Networks (RNN)</strong>: Utilizadas para secuencias de datos, como clasificación de texto.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="6">
<li><p><strong>Modelos Basados en Ensamble</strong></p></li>
</ol>
<ul class="simple">
<li><p>Combinan múltiples modelos para mejorar la precisión de las predicciones.</p></li>
<li><p><strong>Ejemplos:</strong></p>
<ul>
<li><p><strong>Bagging (Bootstrap Aggregating)</strong>: Ejemplo típico es Random Forest.</p></li>
<li><p><strong>Boosting</strong>: Algoritmos como AdaBoost y XGBoost mejoran secuencialmente los errores cometidos por modelos anteriores.</p></li>
</ul>
</li>
</ul>
</section>
<section id="regresion-logistica">
<h3><strong>Regresión logística</strong><a class="headerlink" href="#regresion-logistica" title="Permalink to this heading">#</a></h3>
<p>El <strong>modelo de regresión logística</strong> es un algoritmo de aprendizaje automático utilizado para resolver problemas de clasificación binaria. Se usa cuando el objetivo es predecir una de dos clases posibles, como “sí” o “no”, “positivo” o “negativo”. La regresión logística estima la probabilidad de pertenencia a una clase basándose en una combinación lineal de las características de entrada.</p>
<section id="caracteristicas-claves">
<h4><strong>Características claves</strong><a class="headerlink" href="#caracteristicas-claves" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Función Sigmoide</strong>: La regresión logística utiliza la función sigmoide para transformar el resultado de una combinación lineal de las características en una probabilidad, que está acotada entre 0 y 1. La función sigmoide se define como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
  \sigma(y) = \frac{1}{1 + e^{-y}},
\]</div>
<p>donde <span class="math notranslate nohighlight">\(y\)</span> es el resultado de la combinación lineal de las características: <span class="math notranslate nohighlight">\( y = b_0 + b_1x_1 + b_2x_2 + \ldots + b_nx_n\)</span>.</p>
<ul class="simple">
<li><p><strong>Predicción de Clase</strong>: La salida del modelo se interpreta como la probabilidad de pertenencia a la clase positiva (por ejemplo, “1”). Si la probabilidad es mayor o igual a 0.5, el modelo predice la clase positiva; de lo contrario, predice la clase negativa (por ejemplo, “0”).</p></li>
<li><p><strong>Función de Costo</strong>: Utiliza la <strong>entropía cruzada</strong> (log-loss) como función de costo para evaluar la diferencia entre las predicciones del modelo y las etiquetas reales. La función de costo se define como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \right]
\]</div>
<p>donde <span class="math notranslate nohighlight">\(h_\theta(x)\)</span> es la predicción del modelo y <span class="math notranslate nohighlight">\(y\)</span> es el valor real.</p>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de la regresión logística</strong></p>
<ul class="simple">
<li><p><strong>Simplicidad</strong>: Fácil de implementar e interpretar.</p></li>
<li><p><strong>Eficiente para conjuntos de datos grandes</strong>: Funciona bien en problemas de clasificación binaria con un gran número de muestras.</p></li>
<li><p><strong>Probabilidad de predicción</strong>: Proporciona una probabilidad asociada con cada predicción, lo cual puede ser útil para la toma de decisiones.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de la regresión logística</strong></p>
<ul class="simple">
<li><p><strong>No linealidad</strong>: No puede resolver problemas donde la relación entre las características y la variable objetivo no es lineal.</p></li>
<li><p><strong>Sobreajuste</strong>: Si hay muchas características irrelevantes, el modelo puede sobreajustarse.</p></li>
<li><p><strong>Multicolinealidad</strong>: La presencia de características altamente correlacionadas puede afectar la precisión del modelo.</p></li>
</ul>
</div>
</section>
<section id="idea-de-la-regresion-logistica">
<h4><strong>Idea de la regresión logística</strong><a class="headerlink" href="#idea-de-la-regresion-logistica" title="Permalink to this heading">#</a></h4>
<p>Veamos una idea visual de la regresión logística</p>
<p><img alt="rl_1" src="_images/rl1.png" /></p>
<p><img alt="rl_2" src="_images/rl2.png" /></p>
<p><img alt="rl_3" src="_images/rl3.png" /></p>
<p><img alt="rl_4" src="_images/rl4.png" /></p>
<p><img alt="rl_5" src="_images/rl5.png" /></p>
<p><img alt="rl_6" src="_images/rl6.png" /></p>
<p><img alt="rl_7" src="_images/rl7.png" /></p>
<p><img alt="rl_8" src="_images/rl8.png" /></p>
<p><img alt="rl_9" src="_images/rl9.png" /></p>
</section>
<section id="modelo-de-clasificacion-usando-regresion-logistica-de-entrega-o-no-de-tarjetas-de-creditos">
<h4><strong>Modelo de clasificación usando regresión logística de entrega o no de tarjetas de créditos</strong><a class="headerlink" href="#modelo-de-clasificacion-usando-regresion-logistica-de-entrega-o-no-de-tarjetas-de-creditos" title="Permalink to this heading">#</a></h4>
<p>Los bancos comerciales reciben <em>muchas</em> solicitudes de tarjetas de crédito.
Muchas de ellas son rechazadas por muchas razones, como saldos de préstamos elevados, bajos niveles de ingresos o demasiadas consultas en el informe crediticio de una persona, por ejemplo. Analizar manualmente estas solicitudes es una tarea rutinaria, propensa a errores y requiere mucho tiempo (¡y el tiempo es dinero!). Por suerte, esta tarea puede automatizarse con el poder del aprendizaje automático y casi todos los bancos comerciales lo hacen hoy en día. En colab, construiremos un predictor automático de aprobación de tarjetas de crédito utilizando técnicas de aprendizaje automático, tal y como hacen los bancos de verdad.</p><p><img alt="tarjeta" src="_images/images.png" /></p>
<p>Utilizaremos el conjunto de datos  <a href="http://archive.ics.uci.edu/ml/datasets/credit+approval">Credit Card Approval</a> del UCI Machine Learning Repository. La estructura de este cuaderno es la siguiente:</p>
<ul><section id="importar-las-librerias">
<h5>1. <strong>Importar las librerias</strong><a class="headerlink" href="#importar-las-librerias" title="Permalink to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar </span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h5>2. <strong>Lectura de los datos</strong><a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar el conjunto de datos</span>
<span class="n">cc_apps</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/Users/cdeor/OneDrive/Documentos/MachineLearningDipSerfinanzas/jbook_ml202430/docs/_data/dataml/cc_approvals.data&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Inspeccionar los datos</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">cc_apps</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b</td>
      <td>30.83</td>
      <td>0.000</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.25</td>
      <td>t</td>
      <td>t</td>
      <td>1</td>
      <td>f</td>
      <td>g</td>
      <td>00202</td>
      <td>0</td>
      <td>+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a</td>
      <td>58.67</td>
      <td>4.460</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>3.04</td>
      <td>t</td>
      <td>t</td>
      <td>6</td>
      <td>f</td>
      <td>g</td>
      <td>00043</td>
      <td>560</td>
      <td>+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a</td>
      <td>24.50</td>
      <td>0.500</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>1.50</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00280</td>
      <td>824</td>
      <td>+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b</td>
      <td>27.83</td>
      <td>1.540</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>3.75</td>
      <td>t</td>
      <td>t</td>
      <td>5</td>
      <td>t</td>
      <td>g</td>
      <td>00100</td>
      <td>3</td>
      <td>+</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b</td>
      <td>20.17</td>
      <td>5.625</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.71</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>s</td>
      <td>00120</td>
      <td>0</td>
      <td>+</td>
    </tr>
    <tr>
      <th>685</th>
      <td>b</td>
      <td>21.08</td>
      <td>10.085</td>
      <td>y</td>
      <td>p</td>
      <td>e</td>
      <td>h</td>
      <td>1.25</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00260</td>
      <td>0</td>
      <td>-</td>
    </tr>
    <tr>
      <th>686</th>
      <td>a</td>
      <td>22.67</td>
      <td>0.750</td>
      <td>u</td>
      <td>g</td>
      <td>c</td>
      <td>v</td>
      <td>2.00</td>
      <td>f</td>
      <td>t</td>
      <td>2</td>
      <td>t</td>
      <td>g</td>
      <td>00200</td>
      <td>394</td>
      <td>-</td>
    </tr>
    <tr>
      <th>687</th>
      <td>a</td>
      <td>25.25</td>
      <td>13.500</td>
      <td>y</td>
      <td>p</td>
      <td>ff</td>
      <td>ff</td>
      <td>2.00</td>
      <td>f</td>
      <td>t</td>
      <td>1</td>
      <td>t</td>
      <td>g</td>
      <td>00200</td>
      <td>1</td>
      <td>-</td>
    </tr>
    <tr>
      <th>688</th>
      <td>b</td>
      <td>17.92</td>
      <td>0.205</td>
      <td>u</td>
      <td>g</td>
      <td>aa</td>
      <td>v</td>
      <td>0.04</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00280</td>
      <td>750</td>
      <td>-</td>
    </tr>
    <tr>
      <th>689</th>
      <td>b</td>
      <td>35.00</td>
      <td>3.375</td>
      <td>u</td>
      <td>g</td>
      <td>c</td>
      <td>h</td>
      <td>8.29</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>t</td>
      <td>g</td>
      <td>00000</td>
      <td>0</td>
      <td>-</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>El resultado puede parecer un poco confuso a primera vista, pero vamos a intentar averiguar las características más importantes de una solicitud de tarjeta de crédito.
Las características de este conjunto de datos se han anonimizado para proteger la privacidad, pero <a href="http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html">este blog</a> nos da una visión general bastante buena de las características probables. Las características probables de una solicitud de tarjeta de crédito típica son <code>Sexo</code>, <code>Edad</code>, <code>Deuda</code>, <code>Casado</code>, <code>Cliente bancario</code>, <code>Nivel educativo</code>, <code>Origen étnico</code>, <code>Años de empleo</code>, <code>Impago anterior</code>, <code>Empleado</code>, <code>Puntuación crediticia</code>, <code>Permiso de conducir</code>, <code>Ciudadano</code>, <code>Código postal</code>, <code>Ingresos</code> y, por último, <code>Estado de aprobación</code>. Esto nos da un punto de partida bastante bueno, y podemos mapear estas características con respecto a las columnas en la salida.   </p>
<p>Como podemos ver en nuestro primer vistazo a los datos, el conjunto de datos tiene una mezcla de características numéricas y categóricas. Esto se puede arreglar con un poco de preprocesamiento, pero antes de hacerlo, vamos a aprender un poco más sobre el conjunto de datos para ver si hay otros problemas de conjunto de datos que necesitan ser corregidos.</p><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># nombres de las columnas</span>
<span class="n">cc_apps</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Debt&#39;</span><span class="p">,</span><span class="s1">&#39;Married&#39;</span><span class="p">,</span><span class="s1">&#39;BankCustomer&#39;</span><span class="p">,</span><span class="s1">&#39;EducationLevel&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;Ethnicity&#39;</span><span class="p">,</span><span class="s1">&#39;YearsEmployed&#39;</span><span class="p">,</span><span class="s1">&#39;PriorDefault&#39;</span><span class="p">,</span><span class="s1">&#39;Employed&#39;</span><span class="p">,</span><span class="s1">&#39;CreditScore&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;DriversLicense&#39;</span><span class="p">,</span><span class="s1">&#39;Citizen&#39;</span><span class="p">,</span><span class="s1">&#39;ZipCode&#39;</span><span class="p">,</span><span class="s1">&#39;Income&#39;</span><span class="p">,</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span>

<span class="n">cc_apps</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sex</th>
      <th>Age</th>
      <th>Debt</th>
      <th>Married</th>
      <th>BankCustomer</th>
      <th>EducationLevel</th>
      <th>Ethnicity</th>
      <th>YearsEmployed</th>
      <th>PriorDefault</th>
      <th>Employed</th>
      <th>CreditScore</th>
      <th>DriversLicense</th>
      <th>Citizen</th>
      <th>ZipCode</th>
      <th>Income</th>
      <th>Approved</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b</td>
      <td>30.83</td>
      <td>0.000</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.25</td>
      <td>t</td>
      <td>t</td>
      <td>1</td>
      <td>f</td>
      <td>g</td>
      <td>00202</td>
      <td>0</td>
      <td>+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a</td>
      <td>58.67</td>
      <td>4.460</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>3.04</td>
      <td>t</td>
      <td>t</td>
      <td>6</td>
      <td>f</td>
      <td>g</td>
      <td>00043</td>
      <td>560</td>
      <td>+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a</td>
      <td>24.50</td>
      <td>0.500</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>1.50</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00280</td>
      <td>824</td>
      <td>+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b</td>
      <td>27.83</td>
      <td>1.540</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>3.75</td>
      <td>t</td>
      <td>t</td>
      <td>5</td>
      <td>t</td>
      <td>g</td>
      <td>00100</td>
      <td>3</td>
      <td>+</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b</td>
      <td>20.17</td>
      <td>5.625</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.71</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>s</td>
      <td>00120</td>
      <td>0</td>
      <td>+</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># imprimir información del conjunto de datos</span>
<span class="n">cc_apps</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 690 entries, 0 to 689
Data columns (total 16 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   Sex             690 non-null    object 
 1   Age             690 non-null    object 
 2   Debt            690 non-null    float64
 3   Married         690 non-null    object 
 4   BankCustomer    690 non-null    object 
 5   EducationLevel  690 non-null    object 
 6   Ethnicity       690 non-null    object 
 7   YearsEmployed   690 non-null    float64
 8   PriorDefault    690 non-null    object 
 9   Employed        690 non-null    object 
 10  CreditScore     690 non-null    int64  
 11  DriversLicense  690 non-null    object 
 12  Citizen         690 non-null    object 
 13  ZipCode         690 non-null    object 
 14  Income          690 non-null    int64  
 15  Approved        690 non-null    object 
dtypes: float64(2), int64(2), object(12)
memory usage: 86.4+ KB
</pre></div>
</div>
</div>
</div>
</section>
<section id="datos-faltantes-o-atipicos">
<h5>3. <strong>Datos faltantes o atípicos</strong><a class="headerlink" href="#datos-faltantes-o-atipicos" title="Permalink to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">missing_values</span> <span class="o">=</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">total_rows</span> <span class="o">=</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">missing_vars</span> <span class="o">=</span> <span class="n">missing_values</span><span class="p">[</span><span class="n">missing_values</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">missing_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Datos faltantes&#39;</span><span class="p">:</span> <span class="n">missing_vars</span><span class="p">,</span>
    <span class="s1">&#39;Porcentaje (%)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">((</span><span class="n">missing_vars</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)})</span>

<span class="n">missing_info_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datos faltantes</th>
      <th>Porcentaje (%)</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div></div></div>
</div>
<p>Debemos tener con la variable <code class="docutils literal notranslate"><span class="pre">Age</span></code>, ya que es una variable numérica y nos muestra en la información que es <code class="docutils literal notranslate"><span class="pre">object</span></code>. Debemos hacer una revisión un poco más minuciosa de las variables</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Inspeccionar los valores en el conjunto de datos</span>
<span class="n">cc_apps</span><span class="o">.</span><span class="n">Sex</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;b&#39;, &#39;a&#39;, &#39;?&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<p>Así, vemos que hay datos atípicos, podemos ver que tenemos datos llenados con <code class="docutils literal notranslate"><span class="pre">'?'</span></code>. De ejercicio queda la revisión de cada una de las variables.</p>
</section>
<section id="etl-conjunto-de-entrenamiento-y-prueba">
<h5><strong>4. ETL, conjunto de entrenamiento y prueba</strong><a class="headerlink" href="#etl-conjunto-de-entrenamiento-y-prueba" title="Permalink to this heading">#</a></h5>
<p>Cambiemos los interrogantes por <code class="docutils literal notranslate"><span class="pre">NAN</span></code>s.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replazar los &#39;?&#39;s con NaN en los conjuntos de datos</span>
<span class="n">cc_apps_2</span> <span class="o">=</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;?&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Datos faltantes</span>
<span class="n">missing_values</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">total_rows</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">missing_vars</span> <span class="o">=</span> <span class="n">missing_values</span><span class="p">[</span><span class="n">missing_values</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">missing_info_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;Datos faltantes&#39;</span><span class="p">:</span> <span class="n">missing_vars</span><span class="p">,</span>
    <span class="s1">&#39;Porcentaje (%)&#39;</span><span class="p">:</span> <span class="nb">round</span><span class="p">((</span><span class="n">missing_vars</span> <span class="o">/</span> <span class="n">total_rows</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span><span class="mi">2</span><span class="p">)})</span>

<span class="n">missing_info_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Datos faltantes</th>
      <th>Porcentaje (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Sex</th>
      <td>12</td>
      <td>1.74</td>
    </tr>
    <tr>
      <th>Age</th>
      <td>12</td>
      <td>1.74</td>
    </tr>
    <tr>
      <th>Married</th>
      <td>6</td>
      <td>0.87</td>
    </tr>
    <tr>
      <th>BankCustomer</th>
      <td>6</td>
      <td>0.87</td>
    </tr>
    <tr>
      <th>EducationLevel</th>
      <td>9</td>
      <td>1.30</td>
    </tr>
    <tr>
      <th>Ethnicity</th>
      <td>9</td>
      <td>1.30</td>
    </tr>
    <tr>
      <th>ZipCode</th>
      <td>13</td>
      <td>1.88</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul>
<li><p>Además, variables como <code>Permiso de conducir</code> y <code>Código postal</code> no son tan importantes como las demás características del conjunto de datos para predecir las aprobaciones de tarjetas de crédito.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cambiar la variable Age que esta en objeto por float</span>
<span class="n">cc_apps_2</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># Eliminar las variables 11 y 13</span>
<span class="n">cc_apps_3</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DriversLicense&#39;</span><span class="p">,</span> <span class="s1">&#39;ZipCode&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul>
<li><p>Reemplazamos todos los signos de interrogación por NaNs. Esto nos va a ayudar en el siguiente tratamiento de valores perdidos que vamos a realizar.</p> <p>Una cuestión importante que se plantea aquí es <em>¿por qué damos tanta importancia a los valores perdidos?</em> ¿No podemos simplemente ignorarlos? Ignorar los valores perdidos puede afectar gravemente al rendimiento de un modelo de aprendizaje automático. Al ignorar los valores perdidos, nuestro modelo de aprendizaje automático puede perder información sobre el conjunto de datos que puede ser útil para su formación.  </p> <p>Por lo tanto, para evitar este problema, vamos a imputar los valores perdidos con una estrategia llamada imputación media.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imputar los valores perdidos con imputación de medias para variables numéricas</span>
<span class="n">cc_apps_3</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Contar el número de NaNs en los conjuntos de datos e imprimir los recuentos para verificar</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sex               12
Age                0
Debt               0
Married            6
BankCustomer       6
EducationLevel     9
Ethnicity          9
YearsEmployed      0
PriorDefault       0
Employed           0
CreditScore        0
Citizen            0
Income             0
Approved           0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imputación de datos para variables categóricas</span>

<span class="c1"># Iterar sobre cada columna de cc_apps_3</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cc_apps_3</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Comprobar si la columna es de tipo objeto</span>
    <span class="k">if</span> <span class="n">cc_apps_3</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">==</span> <span class="s1">&#39;object&#39;</span><span class="p">:</span>
        <span class="n">cc_apps_3</span> <span class="o">=</span> <span class="n">cc_apps_3</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Contar el número de NaNs en el conjunto de datos e imprimir los recuentos para verificar</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sex               0
Age               0
Debt              0
Married           0
BankCustomer      0
EducationLevel    0
Ethnicity         0
YearsEmployed     0
PriorDefault      0
Employed          0
CreditScore       0
Citizen           0
Income            0
Approved          0
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Cambiemos los niveles de la variable objetivo <code class="docutils literal notranslate"><span class="pre">Approved</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Supongamos que tu variable está en una columna llamada &#39;variable&#39;</span>
<span class="c1"># + indica aprobado es 1</span>
<span class="c1"># - indica no aprobado es 0</span>
<span class="n">cc_apps_3</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cc_apps_3</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;+&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Veamos el gráfico de barras de la variable objetivo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ignorar advertencias de futuras versiones</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span> 

<span class="c1"># Ajustar el gráfico aumentando el eje Y para mayor visibilidad de las etiquetas</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Approved&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">cc_apps_3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkblue&#39;</span><span class="p">)</span>

<span class="c1"># Añadir el conteo y el porcentaje encima de cada barra</span>
<span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="p">)</span>  <span class="c1"># Número total de registros</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">patches</span><span class="p">:</span>
    <span class="n">count</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">percentage</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">count</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="se">\n</span><span class="s1">(</span><span class="si">{</span><span class="n">percentage</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%)&#39;</span><span class="p">,</span> 
                <span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">,</span> <span class="n">count</span><span class="p">),</span> 
                <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;baseline&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">xytext</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">textcoords</span><span class="o">=</span><span class="s1">&#39;offset points&#39;</span><span class="p">)</span>

<span class="c1"># Ajustar el límite del eje Y</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ax</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.1</span><span class="p">)</span>

<span class="c1"># Personalización del gráfico</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribución de Approved&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Categorías de Approved&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frecuencia&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># Rotar las etiquetas para mejor visibilidad</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2d2bcf245a36198b0c27037d852827b9e78bbbeed4a5b5fb82d2991388b0ab4c.png" src="_images/2d2bcf245a36198b0c27037d852827b9e78bbbeed4a5b5fb82d2991388b0ab4c.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Ejercicios</strong></p>
<p>Termine de realizar un análisis exploratorio de los datos, sin los datos faltantes.</p>
</div>
</section>
<section id="preprocesamiento-de-los-datos">
<h5>5. <strong>Preprocesamiento de los datos</strong><a class="headerlink" href="#preprocesamiento-de-los-datos" title="Permalink to this heading">#</a></h5>
<ul>
<li><p>Los valores perdidos ya se han tratado correctamente.</p> <p>Antes de proceder a la construcción de nuestro modelo de aprendizaje automático, aún es necesario realizar algunos preprocesamientos de datos menores pero esenciales. Vamos a dividir estos pasos de preprocesamiento restantes en dos tareas principales:</p>
  <ol>
  <li>Convertir los datos categóricos en numéricos.</li>
  <li>Escalar los valores de las variables a un rango uniforme.</li>
  </ol>
</li>
<li><p>En primer lugar, convertiremos todos los valores categóricos en numéricos. Hacemos esto porque no sólo resulta en un cálculo más rápido, sino también muchos modelos de aprendizaje automático (como XGBoost) (y especialmente los desarrollados utilizando scikit-learn) requieren que los datos estén en un formato estrictamente numérico. Para ello utilizaremos el método <code>get_dummies()</code> de pandas.</p>
</li>
<li><p>Ahora, dividiremos nuestros datos en un conjunto de entrenamiento y un conjunto de prueba para prepararlos para dos fases distintas del modelado de aprendizaje automático: entrenamiento y prueba. Lo ideal es que no se utilice ninguna información de los datos de prueba para preprocesar los datos de entrenamiento ni para dirigir el proceso de entrenamiento de un modelo de aprendizaje automático. Por lo tanto, primero dividimos los datos y luego los preprocesamos.</p> </li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convertir las variables categóricas en variables dummy</span>
<span class="n">df_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="p">,</span>
               <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">,</span><span class="s1">&#39;Married&#39;</span><span class="p">,</span><span class="s1">&#39;BankCustomer&#39;</span><span class="p">,</span><span class="s1">&#39;EducationLevel&#39;</span><span class="p">,</span><span class="s1">&#39;Ethnicity&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;PriorDefault&#39;</span><span class="p">,</span><span class="s1">&#39;Employed&#39;</span><span class="p">,</span><span class="s1">&#39;Citizen&#39;</span><span class="p">],</span>
               <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separar características y objetivo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span>

<span class="c1"># Dividir en conjuntos de entrenamiento (80%) y prueba (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h5>6. <strong>Construcción del modelo</strong><a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h5>
<p>Ahora sólo nos queda un último paso de preprocesamiento, el escalado, antes de poder ajustar un modelo de aprendizaje automático a los datos. </p>
<p>Intentemos comprender qué significan estos valores escalados en el mundo real. Utilicemos la <code>puntuación crediticia</code> como ejemplo. La puntuación crediticia de una persona es su solvencia basada en su historial de crédito. Cuanto más alto sea este número, más solvente se considera a una persona. Así, la <code>puntuacion crediticia</code> de 1 es el más alto ya que estamos reescalando todos los valores al rango de 0-1.</p><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de regresión logística</span>
<span class="n">pipeline_logreg</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span><span class="n">LogisticRegression</span><span class="p">())</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">pipeline_logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-10 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-10 {
  color: var(--sklearn-color-text);
}

#sk-container-id-10 pre {
  padding: 0;
}

#sk-container-id-10 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-10 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-10 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-10 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-10 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-10 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-10 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-10 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-10 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-10 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-10 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-10 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-10 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-10 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-10 div.sk-label label.sk-toggleable__label,
#sk-container-id-10 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-10 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-10 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-10 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-10 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-10 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-10 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-10 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-10 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-10 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-10 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-10 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-33" type="checkbox" ><label for="sk-estimator-id-33" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-34" type="checkbox" ><label for="sk-estimator-id-34" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-35" type="checkbox" ><label for="sk-estimator-id-35" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div>
</div>
<p>Para tener los mejores parámetros en regresión logística hay que tener cuenta los hiperparámtros:</p>
<p><code class="docutils literal notranslate"><span class="pre">Hiperparámetros</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">Regresión</span> <span class="pre">Logística</span></code>:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">C</span></code></strong>: Inversa de la fuerza de regularización. Un valor pequeño de <code class="docutils literal notranslate"><span class="pre">C</span></code> aumenta la regularización, lo que ayuda a reducir el sobreajuste.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">penalty</span></code></strong>: Tipo de regularización utilizada, que puede ser:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'l2'</span></code>: Regularización de Tikhonov o Ridge.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'l1'</span></code>: Regularización Lasso, que permite la selección de características al reducir algunos coeficientes a cero.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'elasticnet'</span></code>: Combinación de <code class="docutils literal notranslate"><span class="pre">'l1'</span></code> y <code class="docutils literal notranslate"><span class="pre">'l2'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'none'</span></code>: No aplica regularización.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">solver</span></code></strong>: Algoritmo de optimización utilizado para ajustar el modelo. Algunos de los más comunes son:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'lbfgs'</span></code>: Bueno para problemas de multiclase y comúnmente utilizado con <code class="docutils literal notranslate"><span class="pre">'l2'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'liblinear'</span></code>: Útil para problemas pequeños y funciona con <code class="docutils literal notranslate"><span class="pre">l1</span></code> y <code class="docutils literal notranslate"><span class="pre">l2</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'saga'</span></code>: Adecuado para problemas grandes y admite <code class="docutils literal notranslate"><span class="pre">l1</span></code>, <code class="docutils literal notranslate"><span class="pre">l2</span></code> y <code class="docutils literal notranslate"><span class="pre">elasticnet</span></code>.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">max_iter</span></code></strong>: Número máximo de iteraciones para la convergencia del modelo.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">tol</span></code></strong>: Tolerancia para la condición de parada. Determina cuándo detener el entrenamiento si no hay mejoras en las pérdidas.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">fit_intercept</span></code></strong>: Indica si se debe incluir el término independiente en el modelo.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></strong>: Manejo del desbalance en clases. Puede ser <code class="docutils literal notranslate"><span class="pre">None</span></code> o <code class="docutils literal notranslate"><span class="pre">'balanced'</span></code>, ajustando los pesos inversamente proporcionales a las frecuencias de las clases.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">multi_class</span></code></strong>: Estrategia de clasificación multiclase. Puede ser <code class="docutils literal notranslate"><span class="pre">'ovr'</span></code> (One-vs-Rest) o <code class="docutils literal notranslate"><span class="pre">'multinomial'</span></code> para tratar todas las clases simultáneamente.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">warm_start</span></code></strong>: Si es <code class="docutils literal notranslate"><span class="pre">True</span></code>, reutiliza la solución anterior como punto de partida para la nueva llamada a <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
</ul>
<p>En python</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diccionario de hiperparámetros para regresión logística</span>
<span class="n">parametros</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>  <span class="c1"># Inversa de la regularización</span>
    <span class="s1">&#39;penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;elasticnet&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">],</span>  <span class="c1"># Tipo de regularización</span>
    <span class="s1">&#39;solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>  <span class="c1"># Algoritmo de optimización</span>
    <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>  <span class="c1"># Número máximo de iteraciones</span>
    <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">],</span>  <span class="c1"># Tolerancia para la condición de parada</span>
    <span class="s1">&#39;fit_intercept&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>  <span class="c1"># Si se debe incluir el intercepto</span>
    <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">],</span>  <span class="c1"># Manejo del desbalance en clases</span>
    <span class="s1">&#39;multi_class&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;ovr&#39;</span><span class="p">,</span> <span class="s1">&#39;multinomial&#39;</span><span class="p">],</span>  <span class="c1"># Estrategia de clasificación multiclase</span>
    <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>  <span class="c1"># Si se debe reutilizar la solución anterior</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Crear y entrenar el modelo de regresión logística</span>
<span class="n">pipeline_logreg</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span><span class="n">LogisticRegression</span><span class="p">())</span>

<span class="c1"># Definiendo la malla de hyperparámetros para su optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;logisticregression__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s1">&#39;logisticregression__penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;elasticnet&#39;</span><span class="p">,</span> <span class="s1">&#39;none&#39;</span><span class="p">],</span>
    <span class="s1">&#39;logisticregression__solver&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;newton-cg&#39;</span><span class="p">,</span> <span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="s1">&#39;sag&#39;</span><span class="p">,</span> <span class="s1">&#39;saga&#39;</span><span class="p">],</span>
    <span class="s1">&#39;logisticregression__class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Definiendo un KFold para realizar validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Definiendo la búsqueda de hyperparámetros con validación cruzada y F1 score para que el modelo maximice la capacidad de predicción de ambas clases</span>
<span class="n">grid_search_logreg</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_logreg</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustando el modelo</span>
<span class="n">grid_search_logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 240 candidates, totalling 1200 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-11 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-11 {
  color: var(--sklearn-color-text);
}

#sk-container-id-11 pre {
  padding: 0;
}

#sk-container-id-11 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-11 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-11 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-11 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-11 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-11 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-11 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-11 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-11 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-11 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-11 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-11 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-11 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-11 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-11 div.sk-label label.sk-toggleable__label,
#sk-container-id-11 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-11 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-11 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-11 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-11 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-11 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-11 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-11 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-11 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-11 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-11 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-11" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;logisticregression&#x27;,
                                        LogisticRegression())]),
             n_jobs=-1,
             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,
                                                   100],
                         &#x27;logisticregression__class_weight&#x27;: [None, &#x27;balanced&#x27;],
                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;,
                                                         &#x27;elasticnet&#x27;, &#x27;none&#x27;],
                         &#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,
                                                        &#x27;liblinear&#x27;, &#x27;sag&#x27;,
                                                        &#x27;saga&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-36" type="checkbox" ><label for="sk-estimator-id-36" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;logisticregression&#x27;,
                                        LogisticRegression())]),
             n_jobs=-1,
             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1, 10,
                                                   100],
                         &#x27;logisticregression__class_weight&#x27;: [None, &#x27;balanced&#x27;],
                         &#x27;logisticregression__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;,
                                                         &#x27;elasticnet&#x27;, &#x27;none&#x27;],
                         &#x27;logisticregression__solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;,
                                                        &#x27;liblinear&#x27;, &#x27;sag&#x27;,
                                                        &#x27;saga&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-37" type="checkbox" ><label for="sk-estimator-id-37" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;logisticregression&#x27;,
                 LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-38" type="checkbox" ><label for="sk-estimator-id-38" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-39" type="checkbox" ><label for="sk-estimator-id-39" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression(C=0.1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<p>Los mejores parámetros para el modelo son:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imprimiendo los mejores parámetros y score</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros encontrados: &quot;</span><span class="p">,</span> <span class="n">grid_search_logreg</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros encontrados:  {&#39;logisticregression__C&#39;: 0.1, &#39;logisticregression__class_weight&#39;: None, &#39;logisticregression__penalty&#39;: &#39;l1&#39;, &#39;logisticregression__solver&#39;: &#39;liblinear&#39;}
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="metricas-de-evaluacion-de-un-modelo">
<h4><strong>Métricas de evaluación de un modelo</strong><a class="headerlink" href="#metricas-de-evaluacion-de-un-modelo" title="Permalink to this heading">#</a></h4>
<p>Las <strong>métricas de evaluación en un modelo de clasificación</strong> son fundamentales para medir el desempeño del modelo y entender qué tan bien clasifica las instancias. Cada métrica proporciona <strong>información diferente sobre la calidad del modelo</strong> y es <strong>importante seleccionar la métrica adecuada según el contexto del problema</strong>.</p>
<section id="matriz-de-confunsion">
<h5><strong>Matriz de confunsión</strong><a class="headerlink" href="#matriz-de-confunsion" title="Permalink to this heading">#</a></h5>
<p>La <strong>matriz de confusión</strong> organiza las predicciones del modelo en una tabla de contingencia para mostrar cuántas instancias fueron clasificadas correctamente o incorrectamente para cada clase. Es especialmente útil para problemas de clasificación binaria, pero también se puede extender a la clasificación multiclase.</p>
<ol class="arabic simple">
<li><p><strong>Fórmula Matemática</strong></p></li>
</ol>
<p>Para un problema de clasificación binaria, la matriz de confusión tiene la siguiente estructura:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Positiva</p></th>
<th class="head"><p>Predicción Negativa</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Positiva (Real)</strong></p></td>
<td><p>Verdaderos Positivos (TP)</p></td>
<td><p>Falsos Negativos (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Negativa (Real)</strong></p></td>
<td><p>Falsos Positivos (FP)</p></td>
<td><p>Verdaderos Negativos (TN)</p></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li><p><strong>TP (True Positives)</strong>: Instancias correctamente predichas como positivas.</p></li>
<li><p><strong>FP (False Positives)</strong>: Instancias incorrectamente predichas como positivas (error tipo I).</p></li>
<li><p><strong>FN (False Negatives)</strong>: Instancias incorrectamente predichas como negativas (error tipo II).</p></li>
<li><p><strong>TN (True Negatives)</strong>: Instancias correctamente predichas como negativas.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Características</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>Muestra el Rendimiento Completo del Modelo</strong>:</p>
<ul>
<li><p>Permite ver en detalle cuántos errores comete el modelo y el tipo de error (falsos positivos o falsos negativos).</p></li>
</ul>
</li>
<li><p><strong>Utilizable para Multiclase</strong>:</p>
<ul>
<li><p>Para problemas con múltiples clases, la matriz de confusión puede extenderse para incluir más filas y columnas, mostrando las predicciones para cada clase.</p></li>
</ul>
</li>
<li><p><strong>Base para Calcular Otras Métricas</strong>:</p>
<ul>
<li><p>La matriz de confusión es la base para calcular métricas como precisión, recall, F1-score, especificidad, etc.</p></li>
</ul>
</li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de la matriz de confusión</strong></p>
<ol class="arabic simple">
<li><p><strong>Análisis Detallado de Errores</strong>:</p>
<ul class="simple">
<li><p>Permite identificar los tipos específicos de errores cometidos por el modelo, lo que ayuda a mejorarlo.</p></li>
</ul>
</li>
<li><p><strong>Aplicación en Clasificación Multiclase</strong>:</p>
<ul class="simple">
<li><p>Puede extenderse fácilmente para analizar modelos que predicen múltiples categorías.</p></li>
</ul>
</li>
<li><p><strong>Cálculo de Múltiples Métricas</strong>:</p>
<ul class="simple">
<li><p>Facilita el cálculo de métricas como la exactitud, precisión, sensibilidad, F1-score y especificidad.</p></li>
</ul>
</li>
</ol>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de la matriz de confusión</strong></p>
<ol class="arabic simple">
<li><p><strong>Interpretación Compleja para Multiclase</strong>:</p>
<ul class="simple">
<li><p>Para problemas con muchas clases, la matriz de confusión puede volverse grande y difícil de interpretar.</p></li>
</ul>
</li>
<li><p><strong>No Indica Directamente el Desempeño General</strong>:</p>
<ul class="simple">
<li><p>Aunque proporciona detalles sobre los errores, no da una única medida del rendimiento del modelo, por lo que puede ser necesario combinarla con otras métricas.</p></li>
</ul>
</li>
<li><p><strong>Sensibilidad a Clases Desbalanceadas</strong>:</p>
<ul class="simple">
<li><p>Puede ser engañosa si las clases están desbalanceadas, ya que un alto número de verdaderos negativos podría ocultar un bajo rendimiento en la clase minoritaria.</p></li>
</ul>
</li>
</ol>
</div>
<ol class="arabic simple" start="3">
<li><p><strong>Ejemplo</strong></p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. El modelo clasifica si una solicitud es aprobada (positiva) o rechazada (negativa). Se tienen los siguientes resultados:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>En este ejemplo:</p>
<ul class="simple">
<li><p><strong>TP = 70</strong>: 70 solicitudes fueron correctamente predichas como aprobadas.</p></li>
<li><p><strong>FN = 20</strong>: 20 solicitudes que debieron ser aprobadas fueron incorrectamente predichas como rechazadas.</p></li>
<li><p><strong>FP = 10</strong>: 10 solicitudes fueron incorrectamente predichas como aprobadas, aunque debieron ser rechazadas.</p></li>
<li><p><strong>TN = 100</strong>: 100 solicitudes fueron correctamente predichas como rechazadas.</p></li>
</ul>
</section>
<section id="exactitud-accuracy">
<h5><strong>Exactitud (Accuracy)</strong><a class="headerlink" href="#exactitud-accuracy" title="Permalink to this heading">#</a></h5>
<p>La <strong>exactitud</strong> mide la proporción de predicciones correctas (tanto aprobadas como rechazadas) en comparación con el total de predicciones realizadas. Es una métrica simple y fácil de entender que proporciona una idea general de cuán bien está funcionando el modelo.</p>
<ol class="arabic simple">
<li><p>Fórmula matemática</p></li>
</ol>
<p>La fórmula para calcular la exactitud es:</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><strong>TP</strong>: Verdaderos positivos (solicitudes correctamente aprobadas).</p></li>
<li><p><strong>TN</strong>: Verdaderos negativos (solicitudes correctamente rechazadas).</p></li>
<li><p><strong>FP</strong>: Falsos positivos (solicitudes incorrectamente aprobadas).</p></li>
<li><p><strong>FN</strong>: Falsos negativos (solicitudes incorrectamente rechazadas).</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del accuracy</strong></p>
<ul class="simple">
<li><p>Es fácil de calcular e interpretar.</p></li>
<li><p>Proporciona una visión general del rendimiento del modelo.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del accuracy</strong></p>
<ul class="simple">
<li><p>Puede ser engañosa en casos de clases desbalanceadas. Por ejemplo, si la mayoría de las solicitudes son rechazadas, un modelo que siempre predice “rechazada” podría tener una alta exactitud sin ser realmente útil.</p></li>
</ul>
</div>
<ol class="arabic simple" start="2">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. Se tienen los siguientes resultados en la matriz de confusión:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>En este caso:</p>
<ul class="simple">
<li><p><strong>TP = 70</strong>: 70 solicitudes fueron correctamente predichas como aprobadas.</p></li>
<li><p><strong>TN = 100</strong>: 100 solicitudes fueron correctamente predichas como rechazadas.</p></li>
<li><p><strong>FP = 10</strong>: 10 solicitudes fueron incorrectamente predichas como aprobadas.</p></li>
<li><p><strong>FN = 20</strong>: 20 solicitudes que debieron ser aprobadas fueron predichas como rechazadas.</p></li>
</ul>
<p>Aplicando la fórmula para calcular la exactitud:</p>
<div class="math notranslate nohighlight">
\[
\text{Accuracy} = \frac{70 + 100}{70 + 100 + 10 + 20} = \frac{170}{200} = 0.85
\]</div>
<p>Por lo tanto, la exactitud es 0.85, lo que significa que el 85% de las predicciones del modelo fueron correctas.</p>
</section>
<section id="precision-precision">
<h5><strong>Precisión (Precision)</strong><a class="headerlink" href="#precision-precision" title="Permalink to this heading">#</a></h5>
<p>La <strong>precisión</strong> mide la proporción de predicciones positivas correctas frente al total de predicciones positivas realizadas por el modelo. En otras palabras, evalúa cuántas de las solicitudes predichas como aprobadas realmente deberían haber sido aprobadas.</p>
<ol class="arabic simple">
<li><p>Fórmula matemática</p></li>
</ol>
<p>La fórmula para calcular la precisión es:</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{TP}{TP + FP}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><strong>TP</strong>: Verdaderos positivos (solicitudes correctamente aprobadas).</p></li>
<li><p><strong>FP</strong>: Falsos positivos (solicitudes incorrectamente aprobadas).</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de la precisión</strong></p>
<ul class="simple">
<li><p>Es útil cuando el objetivo es minimizar los falsos positivos. Por ejemplo, en el contexto de aprobación de tarjetas de crédito, podría ser importante evitar aprobar solicitudes incorrectamente.</p></li>
<li><p>Es una métrica clave cuando el costo de un falso positivo es alto.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de la precisión</strong></p>
<ul class="simple">
<li><p>No considera los falsos negativos. Por lo tanto, si hay muchos casos en los que el modelo no aprueba solicitudes que deberían haber sido aprobadas (falsos negativos), la precisión no reflejará este problema.</p></li>
</ul>
</div>
<ol class="arabic simple" start="2">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. Se tienen los siguientes resultados en la matriz de confusión:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>En este caso:</p>
<ul class="simple">
<li><p><strong>TP = 70</strong>: 70 solicitudes fueron correctamente predichas como aprobadas.</p></li>
<li><p><strong>FP = 10</strong>: 10 solicitudes fueron incorrectamente predichas como aprobadas.</p></li>
</ul>
<p>Aplicando la fórmula para calcular la precisión:</p>
<div class="math notranslate nohighlight">
\[
\text{Precision} = \frac{70}{70 + 10} = \frac{70}{80} = 0.875
\]</div>
<p>Por lo tanto, la precisión es 0.875, lo que significa que el 87.5% de las solicitudes predichas como aprobadas realmente eran aprobables.</p>
</section>
<section id="recall-sensibilidad">
<h5><strong>Recall (Sensibilidad)</strong><a class="headerlink" href="#recall-sensibilidad" title="Permalink to this heading">#</a></h5>
<p>El <strong>recall</strong>, o sensibilidad, mide la proporción de instancias positivas que fueron correctamente identificadas por el modelo. En otras palabras, indica cuántas de las solicitudes que realmente debían ser aprobadas fueron efectivamente aprobadas por el modelo.</p>
<ol class="arabic simple">
<li><p>Fórmula matemática</p></li>
</ol>
<p>La fórmula para calcular el recall es:</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{TP}{TP + FN}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><strong>TP</strong>: Verdaderos positivos (solicitudes correctamente aprobadas).</p></li>
<li><p><strong>FN</strong>: Falsos negativos (solicitudes que debían ser aprobadas pero fueron rechazadas).</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del recall</strong></p>
<ul class="simple">
<li><p>Es útil cuando el objetivo es minimizar los falsos negativos. Por ejemplo, en el contexto de aprobación de tarjetas de crédito, es importante identificar todas las solicitudes que deberían ser aprobadas.</p></li>
<li><p>Es clave en problemas donde las consecuencias de no detectar un caso positivo son severas (como en diagnósticos médicos).</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del recall</strong></p>
<ul class="simple">
<li><p>Puede dar lugar a un mayor número de falsos positivos si se prioriza el recall sobre la precisión.</p></li>
<li><p>No proporciona información sobre la cantidad de predicciones incorrectas hechas en la clase positiva (falsos positivos).</p></li>
</ul>
</div>
<ol class="arabic simple" start="2">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. Se tienen los siguientes resultados en la matriz de confusión:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>En este caso:</p>
<ul class="simple">
<li><p><strong>TP = 70</strong>: 70 solicitudes fueron correctamente predichas como aprobadas.</p></li>
<li><p><strong>FN = 20</strong>: 20 solicitudes que debían ser aprobadas fueron incorrectamente predichas como rechazadas.</p></li>
</ul>
<p>Aplicando la fórmula para calcular el recall:</p>
<div class="math notranslate nohighlight">
\[
\text{Recall} = \frac{70}{70 + 20} = \frac{70}{90} \approx 0.777
\]</div>
<p>Por lo tanto, el recall es 0.777, lo que significa que el 77.7% de las solicitudes que debían ser aprobadas fueron correctamente identificadas como aprobadas por el modelo.</p>
</section>
<section id="especificidad-specificity">
<h5><strong>Especificidad (Specificity)</strong><a class="headerlink" href="#especificidad-specificity" title="Permalink to this heading">#</a></h5>
<p>La <strong>especificidad</strong> mide la proporción de instancias negativas que fueron correctamente identificadas por el modelo. En otras palabras, indica cuántas de las solicitudes que realmente debían ser rechazadas fueron efectivamente rechazadas por el modelo.</p>
<ol class="arabic simple">
<li><p>Fórmula matemática</p></li>
</ol>
<p>La fórmula para calcular la especificidad es:</p>
<div class="math notranslate nohighlight">
\[
\text{Specificity} = \frac{TN}{TN + FP}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><strong>TN</strong>: Verdaderos negativos (solicitudes correctamente rechazadas).</p></li>
<li><p><strong>FP</strong>: Falsos positivos (solicitudes que debían ser rechazadas pero fueron aprobadas).</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de la especificidad</strong></p>
<ul class="simple">
<li><p>Es útil cuando el objetivo es minimizar los falsos positivos. Por ejemplo, en la aprobación de tarjetas de crédito, puede ser importante evitar aprobar solicitudes que deberían ser rechazadas.</p></li>
<li><p>Complementa el recall, proporcionando una visión completa del rendimiento del modelo en ambas clases (positiva y negativa).</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de la especificidad</strong></p>
<ul class="simple">
<li><p>No proporciona información sobre el rendimiento del modelo para identificar correctamente las instancias positivas (verdaderos positivos).</p></li>
<li><p>Puede ser menos relevante en problemas donde la prioridad es detectar todos los casos positivos, como en el diagnóstico de enfermedades graves.</p></li>
</ul>
</div>
<ol class="arabic simple" start="2">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. Se tienen los siguientes resultados en la matriz de confusión:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>En este caso:</p>
<ul class="simple">
<li><p><strong>TN = 100</strong>: 100 solicitudes fueron correctamente predichas como rechazadas.</p></li>
<li><p><strong>FP = 10</strong>: 10 solicitudes que debían ser rechazadas fueron incorrectamente predichas como aprobadas.</p></li>
</ul>
<p>Aplicando la fórmula para calcular la especificidad:</p>
<div class="math notranslate nohighlight">
\[
\text{Specificity} = \frac{100}{100 + 10} = \frac{100}{110} \approx 0.909
\]</div>
<p>Por lo tanto, la especificidad es 0.909, lo que significa que el 90.9% de las solicitudes que debían ser rechazadas fueron correctamente identificadas como rechazadas por el modelo.</p>
</section>
<section id="f1-score">
<h5><strong>F1-Score</strong><a class="headerlink" href="#f1-score" title="Permalink to this heading">#</a></h5>
<p>El <strong>F1-Score</strong> es la media armónica de la precisión y el recall. Proporciona una medida del equilibrio entre estos dos aspectos, siendo especialmente útil cuando existe un desbalance entre los falsos positivos y los falsos negativos. El F1-Score es alto cuando tanto la precisión como el recall son altos.</p>
<p>1 Fórmula matemática</p>
<p>La fórmula para calcular el F1-Score es:</p>
<div class="math notranslate nohighlight">
\[
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><strong>Precision</strong>: Proporción de verdaderos positivos respecto al total de predicciones positivas.</p></li>
<li><p><strong>Recall</strong>: Proporción de verdaderos positivos respecto al total de instancias que son realmente positivas.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de F1-Score</strong></p>
<ul class="simple">
<li><p>Es útil cuando se necesita un equilibrio entre la precisión y el recall.</p></li>
<li><p>Es especialmente valioso en problemas con clases desbalanceadas, ya que evita que un alto número de verdaderos negativos influya en la métrica.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de F1-Score</strong></p>
<ul class="simple">
<li><p>Puede ser difícil de interpretar en comparación con métricas individuales como la precisión o el recall.</p></li>
<li><p>No considera la proporción de verdaderos negativos, lo que puede ser una limitación en algunos problemas específicos.</p></li>
</ul>
</div>
<ol class="arabic simple" start="2">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos un problema de clasificación donde un banco quiere decidir si aprueba o no las solicitudes de tarjetas de crédito de los clientes. Se tienen los siguientes resultados en la matriz de confusión:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>Predicción Aprobada</p></th>
<th class="head"><p>Predicción Rechazada</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Clase Aprobada (Real)</strong></p></td>
<td><p>70 (TP)</p></td>
<td><p>20 (FN)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Clase Rechazada (Real)</strong></p></td>
<td><p>10 (FP)</p></td>
<td><p>100 (TN)</p></td>
</tr>
</tbody>
</table>
<p>Ya calculamos anteriormente:</p>
<ul class="simple">
<li><p><strong>Precisión (Precision)</strong>:
$<span class="math notranslate nohighlight">\(
\text{Precision} = \frac{TP}{TP + FP} = \frac{70}{70 + 10} = 0.875
\)</span>$</p></li>
<li><p><strong>Recall (Sensibilidad)</strong>:
$<span class="math notranslate nohighlight">\(
\text{Recall} = \frac{TP}{TP + FN} = \frac{70}{70 + 20} \approx 0.777
\)</span>$</p></li>
</ul>
<p>Aplicando la fórmula para calcular el F1-Score:</p>
<div class="math notranslate nohighlight">
\[
F1 = 2 \cdot \frac{0.875 \cdot 0.777}{0.875 + 0.777} \approx 2 \cdot \frac{0.680}{1.652} \approx 0.823
\]</div>
<p>Por lo tanto, el F1-Score es aproximadamente 0.823, lo que significa que el equilibrio entre la precisión y el recall del modelo es del 82.3%.</p>
</section>
<section id="curva-roc-y-auc-roc">
<h5><strong>Curva ROC y AUC-ROC</strong><a class="headerlink" href="#curva-roc-y-auc-roc" title="Permalink to this heading">#</a></h5>
<p>La <strong>curva ROC (Receiver Operating Characteristic)</strong> es un gráfico que muestra la relación entre la tasa de verdaderos positivos (recall) y la tasa de falsos positivos para diferentes umbrales de decisión. El <strong>AUC-ROC (Área Bajo la Curva)</strong> mide el área total bajo la curva ROC, proporcionando una métrica que resume la capacidad del modelo para discriminar entre clases positivas y negativas.</p>
<ol class="arabic simple">
<li><p>Definiciones y sus formulas matemáticas</p></li>
</ol>
<ul class="simple">
<li><p><strong>Tasa de Verdaderos Positivos (TPR o Sensibilidad)</strong>:
$<span class="math notranslate nohighlight">\(
 \text{TPR} = \frac{TP}{TP + FN}
 \)</span>$
Mide la proporción de instancias positivas correctamente identificadas por el modelo.</p></li>
<li><p><strong>Tasa de Falsos Positivos (FPR)</strong>:
$<span class="math notranslate nohighlight">\(
 \text{FPR} = \frac{FP}{FP + TN}
 \)</span>$
Mide la proporción de instancias negativas que fueron incorrectamente clasificadas como positivas.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Curva ROC</p></li>
</ol>
<p>La curva ROC se genera trazando la TPR (eje Y) frente a la FPR (eje X) para diferentes umbrales de decisión del modelo. Cada punto en la curva representa un par de valores (TPR, FPR) correspondientes a un umbral específico.</p>
<ol class="arabic simple" start="3">
<li><p>AUC-ROC</p></li>
</ol>
<p>El <strong>AUC (Área Bajo la Curva)</strong> mide el área total debajo de la curva ROC. El valor del AUC oscila entre 0 y 1:</p>
<ul class="simple">
<li><p><strong>AUC = 1</strong>: El modelo tiene una capacidad perfecta para discriminar entre clases.</p></li>
<li><p><strong>AUC = 0.5</strong>: El modelo no es mejor que adivinar al azar.</p></li>
<li><p><strong>AUC &lt; 0.5</strong>: El modelo tiene un rendimiento peor que el azar (es poco común y normalmente indica que el modelo necesita ajustes).</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de ROC</strong></p>
<ul class="simple">
<li><p>El AUC-ROC es útil para evaluar la capacidad del modelo para clasificar correctamente tanto las clases positivas como negativas, sin depender de un umbral específico.</p></li>
<li><p>Es una métrica estándar para comparar diferentes modelos de clasificación.</p></li>
<li><p>Es aplicable incluso en problemas con clases desbalanceadas, ya que se basa en la tasa de verdaderos y falsos positivos.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de ROC</strong></p>
<ul class="simple">
<li><p>En algunos casos, el AUC-ROC puede no ser adecuado si las probabilidades predichas están concentradas en valores extremos (cercanos a 0 o 1).</p></li>
<li><p>La curva ROC puede ser menos informativa cuando se tienen muchos umbrales similares o cuando se buscan métricas específicas para un solo umbral.</p></li>
</ul>
</div>
<ol class="arabic simple" start="4">
<li><p>Ejemplo</p></li>
</ol>
<p>Supongamos que un banco utiliza un modelo para decidir si aprueba o no las solicitudes de tarjetas de crédito. El modelo genera una probabilidad para cada solicitud, y al variar el umbral de decisión, podemos observar cómo cambian la TPR y la FPR.</p>
<p>Consideremos algunos valores para diferentes umbrales:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Umbral</p></th>
<th class="head"><p>TPR (Recall)</p></th>
<th class="head"><p>FPR</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0.1</p></td>
<td><p>0.95</p></td>
<td><p>0.70</p></td>
</tr>
<tr class="row-odd"><td><p>0.3</p></td>
<td><p>0.85</p></td>
<td><p>0.40</p></td>
</tr>
<tr class="row-even"><td><p>0.5</p></td>
<td><p>0.78</p></td>
<td><p>0.20</p></td>
</tr>
<tr class="row-odd"><td><p>0.7</p></td>
<td><p>0.65</p></td>
<td><p>0.10</p></td>
</tr>
<tr class="row-even"><td><p>0.9</p></td>
<td><p>0.40</p></td>
<td><p>0.05</p></td>
</tr>
</tbody>
</table>
<p>Al graficar estos puntos en un gráfico ROC (con FPR en el eje X y TPR en el eje Y), obtendremos la curva ROC. El AUC se calcula como el área bajo esta curva. En este ejemplo, si el área es 0.85, significa que el modelo tiene un buen rendimiento para discriminar entre las clases (un AUC más cercano a 1 indica un mejor rendimiento).</p>
</section>
<section id="metricas-de-evaluacion-del-modelo-de-regresion-logistica">
<h5><strong>Metricas de evaluación del modelo de regresión logística</strong><a class="headerlink" href="#metricas-de-evaluacion-del-modelo-de-regresion-logistica" title="Permalink to this heading">#</a></h5>
<ul class="simple">
<li><p>Hagamos el modelo de los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo logistico</span>
<span class="n">modelo_logistico</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                 <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_logistico</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-12 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-12 {
  color: var(--sklearn-color-text);
}

#sk-container-id-12 pre {
  padding: 0;
}

#sk-container-id-12 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-12 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-12 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-12 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-12 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-12 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-12 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-12 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-12 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-12 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-12 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-12 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-12 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-12 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-12 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-12 div.sk-label label.sk-toggleable__label,
#sk-container-id-12 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-12 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-12 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-12 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-12 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-12 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-12 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-12 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-12 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-12 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-12 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-12 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-12" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;logisticregression&#x27;,
                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-40" type="checkbox" ><label for="sk-estimator-id-40" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;logisticregression&#x27;,
                 LogisticRegression(C=10, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-41" type="checkbox" ><label for="sk-estimator-id-41" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-42" type="checkbox" ><label for="sk-estimator-id-42" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;LogisticRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a></label><div class="sk-toggleable__content fitted"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>La exactitud del conjunto train y test es:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_logistico</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_logistico</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_logistico</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_logistico</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular la precisión del train (accuracy)</span>
<span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precisión train (Accuracy): </span><span class="si">{</span><span class="n">accuracy_train</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Calcular la precisión del test (accuracy)</span>
<span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precisión test (Accuracy): </span><span class="si">{</span><span class="n">accuracy_test</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Precisión train (Accuracy): 0.89
--------------------------------
Precisión test (Accuracy): 0.82
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La matriz de confusión es:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular la matriz de confusión del train</span>
<span class="n">conf_matrix_train</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>

<span class="c1"># Calcular la matriz de confusión</span>
<span class="n">conf_matrix_test</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Matriz de Confusión test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Matriz de Confusión train:
[[276  39]
 [ 19 218]]
----------------------------
Matriz de Confusión test:
[[56 12]
 [13 57]]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El reporte de clasificación del conjunto de train y test es:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       0.94      0.88      0.90       315
           1       0.85      0.92      0.88       237

    accuracy                           0.89       552
   macro avg       0.89      0.90      0.89       552
weighted avg       0.90      0.89      0.90       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82        68
           1       0.83      0.81      0.82        70

    accuracy                           0.82       138
   macro avg       0.82      0.82      0.82       138
weighted avg       0.82      0.82      0.82       138
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Gráfica de la curva de ROC para el conjunto de train y test</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3a09bd9250225e7c6cddf75d7c4cfd19aba1f4325bf513aa9eb60c8739da2d63.png" src="_images/3a09bd9250225e7c6cddf75d7c4cfd19aba1f4325bf513aa9eb60c8739da2d63.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2ce9d96f69d80e385c670ba8a5f941ac4bbf46a8a06659a4773dbe3040908757.png" src="_images/2ce9d96f69d80e385c670ba8a5f941ac4bbf46a8a06659a4773dbe3040908757.png" />
</div>
</div>
</section>
</section>
</section>
<section id="modelo-de-clasificacion-de-knn">
<h3><strong>Modelo de clasificación de KNN</strong><a class="headerlink" href="#modelo-de-clasificacion-de-knn" title="Permalink to this heading">#</a></h3>
<p><strong>K-Nearest Neighbors (KNN)</strong> es un algoritmo de aprendizaje supervisado utilizado tanto para clasificación como para regresión. En la clasificación, asigna una clase a una nueva instancia basada en las clases de sus <strong>k</strong> vecinos más cercanos en el espacio de características. La proximidad o cercanía se mide usando diversas métricas de distancia, como la <strong>distancia euclidiana</strong>, <strong>Manhattan</strong>, o <strong>Minkowski</strong>.</p>
<section id="caracteristicas">
<h4><strong>Características</strong>:<a class="headerlink" href="#caracteristicas" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Simple y fácil de implementar</strong>: El algoritmo es intuitivo, ya que se basa en medir distancias entre puntos para clasificar las instancias.</p></li>
<li><p><strong>Aprendizaje perezoso</strong>: No “aprende” un modelo explícitamente, sino que almacena los datos de entrenamiento y hace las predicciones calculando distancias en el momento de la clasificación.</p></li>
<li><p><strong>Sensibilidad a la escala de los datos</strong>: Las características con escalas diferentes pueden dominar el cálculo de distancias. Es común normalizar o estandarizar los datos antes de aplicar KNN.</p></li>
<li><p><strong>Parámetro k</strong>: El número de vecinos a considerar (k) es un hiperparámetro clave que debe ajustarse adecuadamente. Un valor bajo puede ser sensible al ruido, mientras que un valor alto puede hacer el modelo demasiado general.</p></li>
<li><p><strong>Necesita almacenar todos los datos de entrenamiento</strong>: Requiere mantener todos los ejemplos en memoria para calcular las distancias durante la predicción.</p></li>
</ol>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del KNN</strong></p>
<ul class="simple">
<li><p><strong>Fácil de entender e implementar</strong>: Es un algoritmo intuitivo y no requiere parámetros complejos.</p></li>
<li><p><strong>No asume distribuciones específicas</strong>: Es un método no paramétrico, lo que significa que no necesita suposiciones sobre la distribución subyacente de los datos.</p></li>
<li><p><strong>Puede funcionar bien en conjuntos de datos pequeños</strong>: Es efectivo para datasets pequeños o con pocas características.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del KNN</strong></p>
<ol class="arabic simple">
<li><p><strong>Computacionalmente costoso</strong>: La clasificación de una nueva instancia implica calcular la distancia a todos los puntos del conjunto de datos, lo cual puede ser ineficiente para grandes volúmenes de datos.</p></li>
<li><p><strong>Sensibilidad al ruido</strong>: Puede verse afectado negativamente si el conjunto de datos contiene ruido o está desbalanceado.</p></li>
<li><p><strong>Maldición de la dimensionalidad</strong>: A medida que aumenta el número de dimensiones, la distancia entre los puntos se vuelve menos significativa, lo que afecta el rendimiento del algoritmo.</p></li>
<li><p><strong>Requiere un buen valor de k</strong>: La elección del valor de <strong>k</strong> es crítica y puede requerir experimentación.</p></li>
</ol>
</div>
</section>
<section id="metricas-de-distancia">
<h4><strong>Métricas de distancia</strong><a class="headerlink" href="#metricas-de-distancia" title="Permalink to this heading">#</a></h4>
<ol class="arabic">
<li><p><strong>Distancia Euclidiana</strong>:<br />
La distancia euclidiana mide la “distancia recta” entre dos puntos en un espacio euclidiano. Para dos puntos <span class="math notranslate nohighlight">\(x = (x_1, x_2, \ldots, x_n)\)</span> y <span class="math notranslate nohighlight">\(y = (y_1, y_2, \ldots, y_n)\)</span>, se calcula como:</p>
<div class="math notranslate nohighlight">
\[
   d_{\text{euclidiana}}(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
   \]</div>
<p>Es una medida común cuando la diferencia cuadrática es significativa.</p>
</li>
<li><p><strong>Distancia Manhattan</strong>:<br />
La distancia Manhattan (o distancia <span class="math notranslate nohighlight">\(L_1\)</span>) mide la distancia a lo largo de los ejes. Se define como:</p>
<div class="math notranslate nohighlight">
\[
   d_{\text{manhattan}}(x, y) = \sum_{i=1}^{n} |x_i - y_i|
   \]</div>
<p>Es útil en problemas donde la diferencia absoluta en cada característica es importante.</p>
</li>
<li><p><strong>Distancia de Minkowski</strong>:<br />
Es una generalización de las distancias Euclidiana y Manhattan. Está dada por:</p>
<div class="math notranslate nohighlight">
\[
   d_{\text{minkowski}}(x, y) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{\frac{1}{p}}
   \]</div>
<p>Donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( p \)</span> es un parámetro que determina la forma de la distancia. Cuando <span class="math notranslate nohighlight">\( p=2 \)</span>, se convierte en la distancia Euclidiana; y cuando <span class="math notranslate nohighlight">\( p=1 \)</span>, se convierte en la distancia Manhattan.</p></li>
</ul>
</li>
<li><p><strong>Distancia Chebyshev</strong>:<br />
La distancia Chebyshev mide la mayor diferencia absoluta entre las coordenadas de dos puntos:</p>
<div class="math notranslate nohighlight">
\[
   d_{\text{chebyshev}}(x, y) = \max_{i} |x_i - y_i|
   \]</div>
<p>Es útil en aplicaciones donde el movimiento es limitado a lo largo de un solo eje.</p>
</li>
</ol>
<p>Estas métricas ayudan a determinar qué tan cerca están dos puntos en el espacio de características y son fundamentales para que el algoritmo KNN determine los vecinos más cercanos. La elección de la métrica depende del tipo de datos y la naturaleza del problema.</p>
</section>
<section id="idea-del-knn">
<h4><strong>Idea del KNN</strong><a class="headerlink" href="#idea-del-knn" title="Permalink to this heading">#</a></h4>
<p>La idea visual de KNN es la siguiente:</p>
<p><img alt="knn_1" src="_images/knn1.png" /></p>
<ul class="simple">
<li><p><strong>¿Como lo hace?</strong></p>
<ol class="arabic simple">
<li><p>Elegir el <strong>número K</strong> de vecinos.</p></li>
<li><p>Tomar los <strong>K</strong> vecinos más cercanos del nuevo dato, según la distancia escogida.</p></li>
<li><p>Entre esos <span class="math notranslate nohighlight">\(K\)</span> vecinos, contar el <strong>número de puntos que pertenecen a cada categoría</strong></p></li>
<li><p>Asignar el **nuevo dato a la categoría con más vecinos en ella.</p></li>
</ol>
</li>
</ul>
<p><img alt="knn_4" src="_images/knn4.png" /></p>
<p><img alt="knn_5" src="_images/knn5.png" /></p>
<p><img alt="knn_6" src="_images/knn6.png" /></p>
<p><img alt="knn_7" src="_images/knn7.png" /></p>
<p><img alt="knn_8" src="_images/knn8.png" /></p>
</section>
<section id="construccion-del-modelo-de-knn-con-sus-metricas">
<h4><strong>Construcción del modelo de KNN con sus métricas</strong><a class="headerlink" href="#construccion-del-modelo-de-knn-con-sus-metricas" title="Permalink to this heading">#</a></h4>
<p>Los hiperparámetros para KNN para Clasificación son:</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code></strong>: Número de vecinos a considerar. Es un parámetro crítico que afecta la clasificación.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">weights</span></code></strong>: Función que asigna pesos a los vecinos. Puede ser:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'uniform'</span></code>: Todos los vecinos tienen el mismo peso.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'distance'</span></code>: Los vecinos más cercanos tienen más peso.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">algorithm</span></code></strong>: Algoritmo utilizado para calcular los vecinos más cercanos. Puede ser:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'auto'</span></code>: Elige el mejor algoritmo basado en los datos.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'ball_tree'</span></code>: Utiliza el árbol de bolas.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'kd_tree'</span></code>: Utiliza el árbol K-D.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'brute'</span></code>: Búsqueda por fuerza bruta.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">metric</span></code></strong>: Métrica utilizada para calcular la distancia entre puntos. Puede ser:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'euclidean'</span></code>: Distancia euclidiana.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'manhattan'</span></code>: Distancia de Manhattan.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'chebyshev'</span></code>: Distancia de Chebyshev.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'minkowski'</span></code>: Distancia de Minkowski (por defecto).</p></li>
<li><p>Otras métricas personalizadas.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">p</span></code></strong>: Potencia de la distancia utilizada para la métrica Minkowski. Cuando <code class="docutils literal notranslate"><span class="pre">p=1</span></code>, se utiliza la distancia de Manhattan, y cuando <code class="docutils literal notranslate"><span class="pre">p=2</span></code>, se utiliza la distancia euclidiana.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">leaf_size</span></code></strong>: Tamaño de la hoja para el árbol K-D o árbol de bolas. Afecta la velocidad de la consulta y la memoria utilizada.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">metric_params</span></code></strong>: Parámetros adicionales para la métrica, que pueden ser utilizados según la métrica seleccionada.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code></strong>: Número de trabajos a ejecutar en paralelo. <code class="docutils literal notranslate"><span class="pre">-1</span></code> utiliza todos los núcleos disponibles.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diccionario de hiperparámetros para KNN</span>
<span class="n">parametros</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span>  <span class="c1"># Número de vecinos a considerar</span>
    <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>  <span class="c1"># Asignación de pesos a los vecinos</span>
    <span class="s1">&#39;algorithm&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;ball_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;kd_tree&#39;</span><span class="p">,</span> <span class="s1">&#39;brute&#39;</span><span class="p">],</span>  <span class="c1"># Algoritmo para calcular vecinos</span>
    <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span> <span class="s1">&#39;manhattan&#39;</span><span class="p">,</span> <span class="s1">&#39;chebyshev&#39;</span><span class="p">,</span> <span class="s1">&#39;minkowski&#39;</span><span class="p">],</span>  <span class="c1"># Métrica de distancia</span>
    <span class="s1">&#39;p&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>  <span class="c1"># Potencia de la distancia para Minkowski</span>
    <span class="s1">&#39;leaf_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">],</span>  <span class="c1"># Tamaño de la hoja para árboles</span>
    <span class="s1">&#39;metric_params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span>  <span class="c1"># Parámetros adicionales para la métrica</span>
    <span class="s1">&#39;n_jobs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Número de trabajos a ejecutar en paralelo</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># importar paquete</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1"># Crear y entrenar el modelo de K-Nearest Neighbors</span>
<span class="n">pipeline_knn</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>

<span class="c1"># Definir la malla de hiperparámetros para optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;kneighborsclassifier__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">),</span>
    <span class="s1">&#39;kneighborsclassifier__weights&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">,</span> <span class="s1">&#39;distance&#39;</span><span class="p">],</span>
    <span class="s1">&#39;kneighborsclassifier__metric&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;euclidean&#39;</span><span class="p">,</span> <span class="s1">&#39;manhattan&#39;</span><span class="p">,</span> <span class="s1">&#39;minkowski&#39;</span><span class="p">],</span>
    <span class="s1">&#39;kneighborsclassifier__leaf_size&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_knn</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_knn</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 576 candidates, totalling 2880 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-13 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-13 {
  color: var(--sklearn-color-text);
}

#sk-container-id-13 pre {
  padding: 0;
}

#sk-container-id-13 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-13 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-13 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-13 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-13 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-13 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-13 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-13 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-13 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-13 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-13 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-13 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-13 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-13 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-13 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-13 div.sk-label label.sk-toggleable__label,
#sk-container-id-13 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-13 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-13 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-13 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-13 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-13 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-13 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-13 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-13 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-13" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;kneighborsclassifier&#x27;,
                                        KNeighborsClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;kneighborsclassifier__leaf_size&#x27;: [30, 40, 50, 60],
                         &#x27;kneighborsclassifier__metric&#x27;: [&#x27;euclidean&#x27;,
                                                          &#x27;manhattan&#x27;,
                                                          &#x27;minkowski&#x27;],
                         &#x27;kneighborsclassifier__n_neighbors&#x27;: range(1, 25),
                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,
                                                           &#x27;distance&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-43" type="checkbox" ><label for="sk-estimator-id-43" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;kneighborsclassifier&#x27;,
                                        KNeighborsClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;kneighborsclassifier__leaf_size&#x27;: [30, 40, 50, 60],
                         &#x27;kneighborsclassifier__metric&#x27;: [&#x27;euclidean&#x27;,
                                                          &#x27;manhattan&#x27;,
                                                          &#x27;minkowski&#x27;],
                         &#x27;kneighborsclassifier__n_neighbors&#x27;: range(1, 25),
                         &#x27;kneighborsclassifier__weights&#x27;: [&#x27;uniform&#x27;,
                                                           &#x27;distance&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-44" type="checkbox" ><label for="sk-estimator-id-44" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;kneighborsclassifier&#x27;,
                 KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7,
                                      weights=&#x27;distance&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-45" type="checkbox" ><label for="sk-estimator-id-45" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-46" type="checkbox" ><label for="sk-estimator-id-46" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para KNN:&quot;</span><span class="p">,</span> <span class="n">grid_search_knn</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para KNN: {&#39;kneighborsclassifier__leaf_size&#39;: 30, &#39;kneighborsclassifier__metric&#39;: &#39;manhattan&#39;, &#39;kneighborsclassifier__n_neighbors&#39;: 7, &#39;kneighborsclassifier__weights&#39;: &#39;distance&#39;}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construcción del modelo KNN con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo knn</span>
<span class="n">modelo_knn</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                           <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s1">&#39;manhattan&#39;</span><span class="p">,</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                                                <span class="n">leaf_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span><span class="n">weights</span><span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-14 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-14 {
  color: var(--sklearn-color-text);
}

#sk-container-id-14 pre {
  padding: 0;
}

#sk-container-id-14 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-14 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-14 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-14 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-14 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-14 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-14 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-14 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-14 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-14 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-14 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-14 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-14 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-14 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-14 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-14 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-14 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-14 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-14 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-14 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-14 div.sk-label label.sk-toggleable__label,
#sk-container-id-14 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-14 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-14 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-14 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-14 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-14 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-14 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-14 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-14 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-14 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-14 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-14 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-14" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;kneighborsclassifier&#x27;,
                 KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7,
                                      weights=&#x27;distance&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-47" type="checkbox" ><label for="sk-estimator-id-47" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;kneighborsclassifier&#x27;,
                 KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7,
                                      weights=&#x27;distance&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-48" type="checkbox" ><label for="sk-estimator-id-48" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-49" type="checkbox" ><label for="sk-estimator-id-49" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(metric=&#x27;manhattan&#x27;, n_neighbors=7, weights=&#x27;distance&#x27;)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Hallemos las metricas del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span><span class="n">modelo_knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_knn</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       315
           1       1.00      1.00      1.00       237

    accuracy                           1.00       552
   macro avg       1.00      1.00      1.00       552
weighted avg       1.00      1.00      1.00       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.78      0.85      0.82        68
           1       0.84      0.77      0.81        70

    accuracy                           0.81       138
   macro avg       0.81      0.81      0.81       138
weighted avg       0.81      0.81      0.81       138
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La curva de ROC para el conjunto de entrenamiento y prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9954dfe5d2ed0b83e7c5e996ac460309e03ce425039c3d8f98984d8d4f1ffee1.png" src="_images/9954dfe5d2ed0b83e7c5e996ac460309e03ce425039c3d8f98984d8d4f1ffee1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e394ee432860aa0d49ab057dfa722952ab292e5c6575977720e5816a43577c49.png" src="_images/e394ee432860aa0d49ab057dfa722952ab292e5c6575977720e5816a43577c49.png" />
</div>
</div>
</section>
</section>
<section id="modelo-de-maquina-de-soporte-vectorial">
<h3><strong>Modelo de Máquina de Soporte Vectorial</strong><a class="headerlink" href="#modelo-de-maquina-de-soporte-vectorial" title="Permalink to this heading">#</a></h3>
<p>Las <strong>Máquinas de Soporte Vectorial</strong> (SVM, por sus siglas en inglés) son un conjunto de métodos de aprendizaje supervisado utilizados para clasificación y regresión. La idea principal detrás de SVM es encontrar el “hiperplano” que mejor separa las clases en un espacio multidimensional. Este hiperplano se elige de manera que maximice el margen entre las clases, es decir, la distancia entre el hiperplano y los puntos de datos más cercanos de cada clase, llamados vectores de soporte. En el caso de clasificación binaria, SVM trata de maximizar la distancia (o margen) entre el hiperplano de separación y los puntos de datos más cercanos de cada clase, conocidos como <strong>vectores de soporte</strong>. Esto hace que el modelo sea robusto y tenga un buen rendimiento en casos donde las clases están bien separadas.</p>
<section id="caracteristicas-de-los-modelos-svm">
<h4><strong>Características de los Modelos SVM</strong><a class="headerlink" href="#caracteristicas-de-los-modelos-svm" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Hiperplano</strong>: La superficie que separa diferentes clases en el espacio de características.</p></li>
<li><p><strong>Vectores de soporte</strong>: Son los puntos de datos que están más cerca del hiperplano y que, si se eliminaran, cambiarían la posición del hiperplano.</p></li>
<li><p><strong>Margen</strong>: La distancia máxima entre los vectores de soporte de diferentes clases y el hiperplano.</p></li>
<li><p><strong>Kernel</strong>: Funciones que permiten transformar los datos a un espacio de mayor dimensión para que sean linealmente separables. Existen diferentes tipos de kernels como:</p>
<ul>
<li><p><strong>Lineal</strong>: Utiliza un hiperplano lineal.</p></li>
<li><p><strong>Polinómico</strong>: Utiliza un polinomio de un grado específico.</p></li>
<li><p><strong>Radial Basis Function (RBF)</strong>: Un kernel basado en la distancia que puede manejar relaciones no lineales.</p></li>
<li><p><strong>Sigmoide</strong>: Basado en la función sigmoide.</p></li>
</ul>
</li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del KNN</strong></p>
<ul class="simple">
<li><p><strong>Eficacia en Espacios Altamente Dimensionales</strong>: SVM es efectivo en problemas de alta dimensionalidad y cuando el número de dimensiones es mayor que el número de muestras.</p></li>
<li><p><strong>Versatilidad</strong>: Se puede utilizar tanto para clasificación como para regresión.</p></li>
<li><p><strong>Manejo de No Linealidad</strong>: Gracias al uso de kernels, SVM puede manejar problemas no lineales.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del KNN</strong></p>
<ul class="simple">
<li><p><strong>Requiere Ajuste de Hiperparámetros</strong>: El rendimiento de SVM puede depender significativamente de la elección de parámetros como el tipo de kernel y su configuración.</p></li>
<li><p><strong>Costoso en Cómputo</strong>: Para conjuntos de datos grandes, SVM puede ser ineficiente en términos de memoria y tiempo de entrenamiento.</p></li>
<li><p><strong>Difícil Interpretación</strong>: Los resultados de SVM no son tan fáciles de interpretar como los de modelos lineales.</p></li>
</ul>
</div>
</section>
<section id="idea-de-maquina-de-soporte-vectorial">
<h4><strong>Idea de maquina de soporte vectorial</strong><a class="headerlink" href="#idea-de-maquina-de-soporte-vectorial" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>¿Comó separamos estos puntos?</p></li>
</ul>
<p><img alt="svc_1" src="_images/svc1.png" /></p>
<ul class="simple">
<li><p>Podriamos crear una linea horizontal o vertical o diagonal</p></li>
</ul>
<p><img alt="svc_2" src="_images/svc2.png" /></p>
<p><img alt="svc_3" src="_images/svc3.png" /></p>
<p><img alt="svc_6" src="_images/svc6.png" /></p>
<ul class="simple">
<li><p>La linea que buscamos es:</p></li>
</ul>
<p><img alt="svc_7" src="_images/svc7.png" /></p>
<ul class="simple">
<li><p>Estos dos puntos son los <strong>vectores de soporte</strong></p></li>
</ul>
<p><img alt="svc_8" src="_images/svc8.png" /></p>
<ul class="simple">
<li><p>El hiperplano es:</p></li>
</ul>
<p><img alt="svc_9" src="_images/svc9.png" /></p>
</section>
<section id="idea-del-kernel-de-maquina-de-soporte-vectorial">
<h4><strong>Idea del kernel de maquina de soporte vectorial</strong><a class="headerlink" href="#idea-del-kernel-de-maquina-de-soporte-vectorial" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>No siempre debemos usar un kernel lineal, ya que no siempre funciona</p></li>
</ul>
<p><img alt="svc_11" src="_images/svc11.png" /></p>
<ul class="simple">
<li><p>Ahora, hagamos transformación a una dimensión superior para separar. Usando una sola dimensión</p></li>
</ul>
<p><img alt="svc_12" src="_images/svc12.png" /></p>
<p><img alt="svc_13" src="_images/svc13.png" /></p>
<ul class="simple">
<li><p>Ahora, usando dos dimensiones</p></li>
</ul>
<p><img alt="svc_10" src="_images/svc10.png" /></p>
<p><img alt="svc_14" src="_images/svc14.png" /></p>
<p><img alt="svc_15" src="_images/svc15.png" /></p>
</section>
<section id="construccion-del-modelo-de-svm-con-sus-metricas">
<h4><strong>Construcción del modelo de SVM con sus métricas</strong><a class="headerlink" href="#construccion-del-modelo-de-svm-con-sus-metricas" title="Permalink to this heading">#</a></h4>
<p>Aquí tenemos los principales hiperparámetros que puedes ajustar en un modelo SVM para la clasificación.</p>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">C</span></code></strong>: Parámetro de regularización. Controla el trade-off entre maximizar el margen y minimizar el error de clasificación. Un valor más pequeño implica un margen más amplio, pero puede aumentar el error de clasificación.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">kernel</span></code></strong>: Tipo de kernel a utilizar. Puede ser:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'linear'</span></code>: Hiperplano lineal.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'poly'</span></code>: Kernel polinómico.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'rbf'</span></code>: Kernel de función de base radial.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'sigmoid'</span></code>: Kernel sigmoide.</p></li>
</ul>
</li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">degree</span></code></strong>: (Solo para kernel polinómico) Grado del polinomio.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">gamma</span></code></strong>: Parámetro del kernel. Controla la influencia de un solo ejemplo de entrenamiento. Un valor pequeño implica una influencia amplia, mientras que un valor grande implica una influencia reducida.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">coef0</span></code></strong>: Término independiente para kernels polinómicos y sigmoides. Influye en la relación entre los términos de mayor y menor grado.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">shrinking</span></code></strong>: Si es <code class="docutils literal notranslate"><span class="pre">True</span></code>, utiliza la heurística de reducción para acelerar la optimización.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">probability</span></code></strong>: Si se establece en <code class="docutils literal notranslate"><span class="pre">True</span></code>, habilita el modo de probabilidad, lo que permite obtener probabilidades de predicción.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></strong>: Puede ser <code class="docutils literal notranslate"><span class="pre">None</span></code>, <code class="docutils literal notranslate"><span class="pre">'balanced'</span></code> o un diccionario que asigna pesos a las clases para manejar el desbalance en el conjunto de datos.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">max_iter</span></code></strong>: Número máximo de iteraciones para el optimizador.</p></li>
</ul>
<p>En python</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>  <span class="c1"># Parámetro de regularización</span>
    <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">],</span>  <span class="c1"># Tipo de kernel</span>
    <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>  <span class="c1"># Grado del polinomio, solo relevante para kernel &#39;poly&#39;</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Parámetro de gamma</span>
    <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>  <span class="c1"># Término independiente en el kernel polinómico y sigmoide</span>
    <span class="s1">&#39;shrinking&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>  <span class="c1"># Habilitar la heurística de reducción</span>
    <span class="s1">&#39;probability&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>  <span class="c1"># Activar la estimación de probabilidad</span>
    <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">],</span>  <span class="c1"># Tolerancia para criterios de parada</span>
    <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span>  <span class="c1"># Número máximo de iteraciones</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Hallemos los mejores hiperparámetros con <code class="docutils literal notranslate"><span class="pre">kernel='linear'</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar librerias</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># Crear y entrenar el modelo de Support Vector Classifier con kernel lineal</span>
<span class="n">pipeline_svc</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">))</span>

<span class="c1"># Definir la malla de hiperparámetros para optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;svc__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span>
    <span class="s1">&#39;svc__class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_svc_lineal</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_svc</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_svc_lineal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 14 candidates, totalling 70 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-15 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-15 {
  color: var(--sklearn-color-text);
}

#sk-container-id-15 pre {
  padding: 0;
}

#sk-container-id-15 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-15 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-15 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-15 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-15 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-15 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-15 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-15 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-15 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-15 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-15 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-15 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-15 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-15 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-15 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-15 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-15 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-15 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-15 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-15 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-15 div.sk-label label.sk-toggleable__label,
#sk-container-id-15 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-15 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-15 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-15 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-15 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-15 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-15 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-15 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-15 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-15 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-15 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-15 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-15" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svc__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],
                         &#x27;svc__class_weight&#x27;: [None, &#x27;balanced&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-50" type="checkbox" ><label for="sk-estimator-id-50" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;svc&#x27;, SVC(kernel=&#x27;linear&#x27;))]),
             n_jobs=-1,
             param_grid={&#x27;svc__C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100, 1000],
                         &#x27;svc__class_weight&#x27;: [None, &#x27;balanced&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-51" type="checkbox" ><label for="sk-estimator-id-51" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;svc&#x27;, SVC(C=0.01, kernel=&#x27;linear&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-52" type="checkbox" ><label for="sk-estimator-id-52" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-53" type="checkbox" ><label for="sk-estimator-id-53" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a></label><div class="sk-toggleable__content fitted"><pre>SVC(C=0.01, kernel=&#x27;linear&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para SVC con kernel lineal:&quot;</span><span class="p">,</span> <span class="n">grid_search_svc_lineal</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para SVC con kernel lineal: {&#39;svc__C&#39;: 0.01, &#39;svc__class_weight&#39;: None}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construcción del modelo de <code class="docutils literal notranslate"><span class="pre">SVC</span></code> con los mejores parámetros y kernel lineal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo logistico</span>
<span class="n">modelo_svc_lineal</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                  <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                      <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_svc_lineal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-16 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-16 {
  color: var(--sklearn-color-text);
}

#sk-container-id-16 pre {
  padding: 0;
}

#sk-container-id-16 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-16 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-16 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-16 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-16 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-16 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-16 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-16 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-16 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-16 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-16 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-16 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-16 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-16 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-16 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-16 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-16 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-16 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-16 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-16 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-16 div.sk-label label.sk-toggleable__label,
#sk-container-id-16 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-16 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-16 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-16 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-16 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-16 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-16 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-16 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-16 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-16 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-16 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-16 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-16" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;svc&#x27;, SVC(C=0.01, kernel=&#x27;linear&#x27;, probability=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-54" type="checkbox" ><label for="sk-estimator-id-54" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;svc&#x27;, SVC(C=0.01, kernel=&#x27;linear&#x27;, probability=True))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-55" type="checkbox" ><label for="sk-estimator-id-55" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-56" type="checkbox" ><label for="sk-estimator-id-56" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;SVC<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html">?<span>Documentation for SVC</span></a></label><div class="sk-toggleable__content fitted"><pre>SVC(C=0.01, kernel=&#x27;linear&#x27;, probability=True)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Ahora, calculemos las métricas del modelo de <code class="docutils literal notranslate"><span class="pre">SVC</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_svc_lineal</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_svc_lineal</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_svc_lineal</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_svc_lineal</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       0.94      0.81      0.87       315
           1       0.79      0.94      0.86       237

    accuracy                           0.86       552
   macro avg       0.87      0.87      0.86       552
weighted avg       0.88      0.86      0.86       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.87      0.76      0.81        68
           1       0.79      0.89      0.84        70

    accuracy                           0.83       138
   macro avg       0.83      0.83      0.83       138
weighted avg       0.83      0.83      0.83       138
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Hagamos la curva de ROC de <code class="docutils literal notranslate"><span class="pre">SVC</span></code> con el kernel lineal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/38745a82bd4f9a4ad43d903f4435da24b01d35b6528c69cab00395bca7ce4a86.png" src="_images/38745a82bd4f9a4ad43d903f4435da24b01d35b6528c69cab00395bca7ce4a86.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b01cf094c7a39721aad1800c5cdb77ca1bc4ad45d22e7bb2a476a581d71ad33a.png" src="_images/b01cf094c7a39721aad1800c5cdb77ca1bc4ad45d22e7bb2a476a581d71ad33a.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Ejercicios</strong></p>
<p>Ya realizaste el modelo de <code class="docutils literal notranslate"><span class="pre">SVC</span></code> con kernel lineal. Ahora encuentra el modelo con <strong>kernel polinomial, radial y sigmoide</strong> con los mejores parámetros. También, halla sus métricas y gráfica la curva de <code class="docutils literal notranslate"><span class="pre">ROC</span></code>.</p>
</div>
</section>
</section>
<section id="modelo-de-naives-bayes">
<h3><strong>Modelo de Naives-Bayes</strong><a class="headerlink" href="#modelo-de-naives-bayes" title="Permalink to this heading">#</a></h3>
<p>El <strong>Clasificador Naive Bayes</strong> es un modelo de aprendizaje supervisado basado en la <strong>Regla de Bayes</strong>, que se utiliza para problemas de clasificación. Este clasificador asume que las características son independientes entre sí dado el valor de la clase, lo que simplifica el cálculo de las probabilidades. Aunque esta suposición de independencia rara vez se cumple completamente en la práctica, el modelo es efectivo y eficiente para problemas de clasificación, especialmente en el análisis de texto y problemas multiclase.</p>
<section id="definicion-de-la-regla-de-bayes">
<h4><strong>Definición de la Regla de Bayes</strong><a class="headerlink" href="#definicion-de-la-regla-de-bayes" title="Permalink to this heading">#</a></h4>
<p>La <strong>Regla de Bayes</strong> es un principio fundamental en probabilidad y estadística que permite calcular la probabilidad de que un evento ocurra dado que otro evento ya ha ocurrido. Esta regla es clave para la inferencia estadística y es la base de varios modelos probabilísticos, como el clasificador Naive Bayes. La Regla de Bayes se puede expresar como:</p>
<div class="math notranslate nohighlight">
\[
P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A | B)\)</span>: Probabilidad de <span class="math notranslate nohighlight">\(A\)</span> dado <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B | A)\)</span>: Probabilidad de <span class="math notranslate nohighlight">\(B\)</span> dado <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span>: Probabilidad a priori de <span class="math notranslate nohighlight">\(A\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B)\)</span>: Probabilidad a priori de <span class="math notranslate nohighlight">\(B\)</span>.</p></li>
</ul>
</section>
<section id="ejemplo-de-la-regla-de-bayes">
<h4><strong>Ejemplo de la regla de Bayes</strong><a class="headerlink" href="#ejemplo-de-la-regla-de-bayes" title="Permalink to this heading">#</a></h4>
<p>Supongamos que un banco quiere evaluar la probabilidad de que un cliente esté en alto riesgo de incumplimiento de pago de un préstamo (es decir, que no lo pague) dado que tiene un historial crediticio bajo. Usaremos la <strong>Regla de Bayes</strong> para calcular esta probabilidad.</p>
<ol class="arabic">
<li><p><strong>Definimos los eventos:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(A\)</span>: El cliente está en alto riesgo de incumplimiento.</p></li>
<li><p><span class="math notranslate nohighlight">\(B\)</span>: El cliente tiene un historial crediticio bajo.</p></li>
</ul>
</li>
<li><p><strong>Datos disponibles:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(A)\)</span>: Probabilidad de que cualquier cliente esté en alto riesgo de incumplimiento (por ejemplo, un 10%, o <span class="math notranslate nohighlight">\(P(A) = 0.1\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B | A)\)</span>: Probabilidad de que un cliente tenga un historial crediticio bajo si está en alto riesgo de incumplimiento (por ejemplo, un 80%, o <span class="math notranslate nohighlight">\(P(B | A) = 0.8\)</span>).</p></li>
<li><p><span class="math notranslate nohighlight">\(P(B)\)</span>: Probabilidad de que un cliente tenga un historial crediticio bajo (por ejemplo, un 20%, o <span class="math notranslate nohighlight">\(P(B) = 0.2\)</span>).</p></li>
</ul>
</li>
<li><p><strong>Aplicamos la Regla de Bayes:</strong></p>
<p>Usamos la fórmula de Bayes para calcular <span class="math notranslate nohighlight">\(P(A | B)\)</span>, la probabilidad de que un cliente esté en alto riesgo de incumplimiento dado que tiene un historial crediticio bajo:</p>
<div class="math notranslate nohighlight">
\[
   P(A | B) = \frac{P(B | A) \cdot P(A)}{P(B)}
   \]</div>
<p>Sustituimos los valores:</p>
<div class="math notranslate nohighlight">
\[
   P(A | B) = \frac{0.8 \cdot 0.1}{0.2} = \frac{0.08}{0.2} = 0.4
   \]</div>
</li>
<li><p><strong>Interpretación del resultado:</strong></p>
<p>La probabilidad de que un cliente esté en alto riesgo de incumplimiento dado que tiene un historial crediticio bajo es del 40%. Este resultado puede ayudar al banco a tomar decisiones informadas sobre la aprobación de préstamos y a gestionar mejor el riesgo.</p>
</li>
</ol>
<p>Este ejemplo muestra cómo la Regla de Bayes permite al banco actualizar las probabilidades de riesgo en función de la información disponible sobre el historial crediticio del cliente.</p>
</section>
<section id="clasificador-naive-bayes">
<h4><strong>Clasificador Naive Bayes</strong><a class="headerlink" href="#clasificador-naive-bayes" title="Permalink to this heading">#</a></h4>
<p>El <strong>Clasificador Naive Bayes</strong> es un modelo de aprendizaje supervisado basado en la <strong>Regla de Bayes</strong>. Se utiliza para problemas de clasificación, asumiendo que las características de cada instancia son independientes entre sí dado el valor de la clase. Aunque esta suposición rara vez es completamente cierta, el modelo es efectivo y eficiente para muchas aplicaciones prácticas, especialmente en el análisis de texto y problemas multiclase.</p>
<ol class="arabic simple">
<li><p><strong>Fórmula Matemática del Clasificador Naive Bayes</strong></p></li>
</ol>
<p>Para un conjunto de datos con una instancia <span class="math notranslate nohighlight">\(x = (x_1, x_2, \dots, x_n)\)</span> y una clase <span class="math notranslate nohighlight">\(C_k\)</span>, la probabilidad de que la instancia pertenezca a la clase <span class="math notranslate nohighlight">\(C_k\)</span> se expresa como:</p>
<div class="math notranslate nohighlight">
\[
P(C_k | x) \propto P(C_k) \prod_{i=1}^{n} P(x_i | C_k)
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(C_k | x)\)</span>: Probabilidad posterior de la clase <span class="math notranslate nohighlight">\(C_k\)</span> dado el conjunto de características <span class="math notranslate nohighlight">\(x\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(C_k)\)</span>: Probabilidad a priori de la clase <span class="math notranslate nohighlight">\(C_k\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(x_i | C_k)\)</span>: Probabilidad condicional de la característica <span class="math notranslate nohighlight">\(x_i\)</span> dado que la clase es <span class="math notranslate nohighlight">\(C_k\)</span>.</p></li>
</ul>
<p>El clasificador calcula la probabilidad de cada clase y selecciona la clase con la mayor probabilidad como la predicción.</p>
<ol class="arabic simple" start="2">
<li><p><strong>Características del Clasificador Naive Bayes</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>Suposición de independencia</strong>: Se asume que las características son independientes entre sí dado el valor de la clase, lo que simplifica el cálculo de probabilidades.</p></li>
<li><p><strong>Modelo probabilístico</strong>: Calcula la probabilidad de que una instancia pertenezca a una clase en particular utilizando las probabilidades condicionales de cada característica.</p></li>
<li><p><strong>Multiclase</strong>: Puede ser utilizado para problemas con múltiples clases de salida.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del Clasificador Naive Bayes</strong></p>
<ol class="arabic simple">
<li><p><strong>Eficiencia</strong>: Es rápido y eficiente, ideal para grandes conjuntos de datos, ya que requiere menos datos para entrenarse y clasificar.</p></li>
<li><p><strong>Rendimiento en problemas de texto</strong>: Funciona bien en la clasificación de texto y filtrado de spam, donde la suposición de independencia es razonable.</p></li>
<li><p><strong>Manejo de datos faltantes</strong>: Puede manejar datos faltantes ignorando las características que no están presentes.</p></li>
<li><p><strong>Escalable</strong>: Funciona bien con muchos tipos de datos y es escalable a problemas de clasificación multiclase.</p></li>
</ol>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del Clasificador Naive Bayes</strong></p>
<ol class="arabic simple">
<li><p><strong>Suposición de independencia</strong>: La suposición de independencia rara vez se cumple en la práctica, lo que limita su precisión en algunos contextos.</p></li>
<li><p><strong>Sensibilidad a datos de entrenamiento</strong>: Su rendimiento puede ser afectado por la cantidad y calidad de los datos de entrenamiento.</p></li>
<li><p><strong>No apto para datos continuos sin discretización</strong>: Para manejar datos continuos, se suele requerir discretización o asumir una distribución, como la distribución normal, lo cual puede no siempre ser adecuado.</p></li>
</ol>
</div>
<p>El clasificador Naive Bayes es una herramienta poderosa y sencilla para tareas de clasificación rápida y efectiva, siempre que las características sean aproximadamente independientes.</p>
</section>
<section id="modelos-de-naive-bayes-para-clasificacion">
<h4><strong>Modelos de Naive Bayes para clasificación</strong><a class="headerlink" href="#modelos-de-naive-bayes-para-clasificacion" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Gaussian Naive Bayes (<code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code>)</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>Uso</strong>: Adecuado para problemas de clasificación donde las características son continuas y se asume que siguen una distribución normal (gaussiana).</p></li>
<li><p><strong>Ejemplo de aplicación</strong>:</p>
<ul>
<li><p>Clasificación de textos.</p></li>
<li><p>Detección de fraudes.</p></li>
<li><p>Problemas donde las características numéricas pueden considerarse distribuciones normales.</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Multinomial Naive Bayes (<code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code>)</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>Uso</strong>: Ideal para clasificar datos discretos, especialmente con características que representan recuentos o frecuencias, como el texto en procesamiento de lenguaje natural.</p></li>
<li><p><strong>Ejemplo de aplicación</strong>:</p>
<ul>
<li><p>Clasificación de documentos.</p></li>
<li><p>Análisis de sentimientos.</p></li>
<li><p>Detección de spam.</p></li>
<li><p>Tareas donde las características se pueden contar (frecuencia de palabras en un texto).</p></li>
</ul>
</li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Bernoulli Naive Bayes (<code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code>)</strong></p></li>
</ol>
<ul class="simple">
<li><p><strong>Uso</strong>: Similar a <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code>, pero se utiliza para características binarias (0 o 1). Asume que las características son variables binarias.</p></li>
<li><p><strong>Ejemplo de aplicación</strong>:</p>
<ul>
<li><p>Clasificación de textos donde la presencia o ausencia de una palabra es más importante que la frecuencia (si una palabra está presente o no en un documento).</p></li>
</ul>
</li>
</ul>
<p>En resumen de cuándo usar cada modelo</p>
<ul class="simple">
<li><p><strong>GaussianNB</strong>: Usa cuando tus datos son continuos y se distribuyen normalmente.</p></li>
<li><p><strong>MultinomialNB</strong>: Usa para datos discretos y en tareas de clasificación de texto donde las características representan recuentos o frecuencias.</p></li>
<li><p><strong>BernoulliNB</strong>: Usa para datos binarios donde la presencia o ausencia de características es relevante.</p></li>
</ul>
</section>
<section id="id4">
<h4><strong>Construcción del modelo</strong><a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h4>
<p>Aquí, tenemos los principales hiperparámetros del modelo de Gaussian Naive Bayes <code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">priors</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Lista de probabilidades a priori de las clases. Si se establece, las probabilidades a priori son normalizadas de acuerdo a estas.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">array-like</span></code>, forma (n_classes,)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">var_smoothing</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Valor de suavizado para evitar que la varianza sea cero. Se agrega a la varianza de cada característica antes de realizar la predicción.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">1e-9</span></code></p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hiperparámetros de Gaussian Naive Bayes</span>
<span class="n">hyperparameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;priors&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="kc">None</span><span class="p">,</span>               <span class="c1"># No se establecen probabilidades a priori</span>
        <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>        <span class="c1"># Probabilidades a priori iguales</span>
        <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span>        <span class="c1"># Probabilidades a priori</span>
        <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>        <span class="c1"># Probabilidades a priori</span>
    <span class="p">],</span>
    <span class="s1">&#39;var_smoothing&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="mf">1e-9</span><span class="p">,</span>              <span class="c1"># Valor de suavizado bajo</span>
        <span class="mf">1e-8</span><span class="p">,</span>              <span class="c1"># Valor de suavizado ligeramente mayor</span>
        <span class="mf">1e-7</span><span class="p">,</span>              <span class="c1"># Valor de suavizado medio</span>
        <span class="mf">1e-6</span><span class="p">,</span>              <span class="c1"># Valor de suavizado alto</span>
        <span class="mf">1e-5</span>               <span class="c1"># Valor de suavizado aún más alto</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Hallemos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar librerías necesarias</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>

<span class="c1"># Crear y entrenar el modelo de Naive Bayes</span>
<span class="n">pipeline_nb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">GaussianNB</span><span class="p">())</span>

<span class="c1"># Definir la malla de hiperparámetros (aunque Naive Bayes no tiene tantos hiperparámetros como SVC)</span>
<span class="n">param_grid_nb</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># No hay muchos hiperparámetros para ajustar en GaussianNB, pero podrías agregar algunos si tuvieras opciones</span>
    <span class="s1">&#39;gaussiannb__var_smoothing&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-9</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">]</span>  <span class="c1"># Ajuste de varianza</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_nb</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_nb</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid_nb</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 4 candidates, totalling 20 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-17 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-17 {
  color: var(--sklearn-color-text);
}

#sk-container-id-17 pre {
  padding: 0;
}

#sk-container-id-17 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-17 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-17 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-17 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-17 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-17 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-17 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-17 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-17 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-17 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-17 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-17 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-17 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-17 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-17 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-17 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-17 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-17 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-17 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-17 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-17 div.sk-label label.sk-toggleable__label,
#sk-container-id-17 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-17 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-17 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-17 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-17 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-17 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-17 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-17 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-17 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-17 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-17 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-17 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-17" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),
             n_jobs=-1,
             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09, 1e-08, 1e-07,
                                                       1e-06]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-57" type="checkbox" ><label for="sk-estimator-id-57" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;gaussiannb&#x27;, GaussianNB())]),
             n_jobs=-1,
             param_grid={&#x27;gaussiannb__var_smoothing&#x27;: [1e-09, 1e-08, 1e-07,
                                                       1e-06]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-58" type="checkbox" ><label for="sk-estimator-id-58" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;gaussiannb&#x27;, GaussianNB(var_smoothing=1e-06))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-59" type="checkbox" ><label for="sk-estimator-id-59" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-60" type="checkbox" ><label for="sk-estimator-id-60" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;GaussianNB<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html">?<span>Documentation for GaussianNB</span></a></label><div class="sk-toggleable__content fitted"><pre>GaussianNB(var_smoothing=1e-06)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Estos son los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para naive-bayes:&quot;</span><span class="p">,</span> <span class="n">grid_search_nb</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para naive-bayes: {&#39;gaussiannb__var_smoothing&#39;: 1e-06}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construcción del modelo de naive bayes con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo logistico</span>
<span class="n">modelo_nb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">GaussianNB</span><span class="p">(</span><span class="n">var_smoothing</span> <span class="o">=</span> <span class="mf">1e-06</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-18 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-18 {
  color: var(--sklearn-color-text);
}

#sk-container-id-18 pre {
  padding: 0;
}

#sk-container-id-18 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-18 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-18 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-18 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-18 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-18 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-18 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-18 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-18 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-18 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-18 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-18 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-18 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-18 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-18 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-18 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-18 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-18 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-18 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-18 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-18 div.sk-label label.sk-toggleable__label,
#sk-container-id-18 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-18 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-18 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-18 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-18 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-18 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-18 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-18 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-18 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-18 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-18 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-18 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-18" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;gaussiannb&#x27;, GaussianNB(var_smoothing=1e-06))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-61" type="checkbox" ><label for="sk-estimator-id-61" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;gaussiannb&#x27;, GaussianNB(var_smoothing=1e-06))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-62" type="checkbox" ><label for="sk-estimator-id-62" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-63" type="checkbox" ><label for="sk-estimator-id-63" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;GaussianNB<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.GaussianNB.html">?<span>Documentation for GaussianNB</span></a></label><div class="sk-toggleable__content fitted"><pre>GaussianNB(var_smoothing=1e-06)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Ahora calculemos las métricas del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_nb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_nb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el train</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       0.76      0.94      0.84       315
           1       0.88      0.62      0.72       237

    accuracy                           0.80       552
   macro avg       0.82      0.78      0.78       552
weighted avg       0.81      0.80      0.79       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.67      0.85      0.75        68
           1       0.81      0.60      0.69        70

    accuracy                           0.72       138
   macro avg       0.74      0.73      0.72       138
weighted avg       0.74      0.72      0.72       138
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1e89c80b989c4f14fbfd7774b1256e5628722ad820fb699fc8f7c8a80dc1ac68.png" src="_images/1e89c80b989c4f14fbfd7774b1256e5628722ad820fb699fc8f7c8a80dc1ac68.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b24ce3af5b158ccbf6bf273ed788203426f607b60c2aab1d7e4da30867a25678.png" src="_images/b24ce3af5b158ccbf6bf273ed788203426f607b60c2aab1d7e4da30867a25678.png" />
</div>
</div>
</section>
</section>
<section id="modelo-de-arbol-de-decision">
<h3><strong>Modelo de arbol de decisión</strong><a class="headerlink" href="#modelo-de-arbol-de-decision" title="Permalink to this heading">#</a></h3>
<p>Los <strong>árboles de decisión</strong> son modelos predictivos que utilizan reglas binarias (sí/no) para segmentar las observaciones en función de sus atributos, permitiendo predecir el valor de la variable objetivo. Este tipo de modelo es ideal para problemas con múltiples predictores que interactúan de manera compleja y no lineal, ya que divide el espacio de predictores en regiones simples donde resulta más fácil gestionar estas interacciones.</p>
<p>Muchos métodos predictivos construyen modelos globales, donde una única ecuación representa el comportamiento de todo el espacio de datos. Sin embargo, en casos con interacciones complejas entre predictores, resulta difícil encontrar un modelo global que capture adecuadamente las relaciones entre las variables. Los métodos estadísticos y de machine learning basados en árboles son <strong>técnicas supervisadas no paramétricas</strong> que segmentan el espacio de los predictores, dividiéndolo en subespacios más manejables. Esta característica de segmentación es una de las principales razones por las que estos modelos son tan efectivos.</p>
<p>Gracias a su capacidad para capturar relaciones complejas, los métodos basados en árboles se han consolidado como una herramienta fundamental en el ámbito predictivo, proporcionando buenos resultados en una variedad de problemas. Este documento explora en detalle cómo se construyen y aplican los árboles de decisión para tareas de <strong>clasificación y regresión</strong>, y presenta cómo estos modelos forman la base de técnicas más avanzadas como <strong>Random Forest</strong> y <strong>Gradient Boosting Machine</strong>.</p>
<section id="componentes-de-un-arbol-de-decision">
<h4><strong>Componentes de un árbol de decisión</strong><a class="headerlink" href="#componentes-de-un-arbol-de-decision" title="Permalink to this heading">#</a></h4>
<ol class="arabic simple">
<li><p><strong>Nodo raíz</strong>:</p>
<ul class="simple">
<li><p>Es el primer nodo del árbol y representa la característica inicial que divide el conjunto de datos en dos o más subconjuntos. La selección de esta característica se realiza en base a la que aporta la mejor pureza en la partición de datos.</p></li>
</ul>
</li>
<li><p><strong>Nodos internos</strong>:</p>
<ul class="simple">
<li><p>Son los nodos intermedios donde se toman decisiones adicionales en base a características específicas. Cada nodo interno representa una división adicional del conjunto de datos, con el objetivo de aumentar la homogeneidad de los subconjuntos en función de la métrica seleccionada (como el índice de Gini o la entropía).</p></li>
</ul>
</li>
<li><p><strong>Hojas (o nodos terminales)</strong>:</p>
<ul class="simple">
<li><p>Son los nodos finales que representan el resultado del modelo. En árboles de clasificación, cada hoja asigna una clase, mientras que en árboles de regresión, asigna un valor específico. Las hojas no se dividen más, ya que cumplen con un criterio de parada o porque los datos dentro del nodo son suficientemente homogéneos.</p></li>
</ul>
</li>
<li><p><strong>Ramas</strong>:</p>
<ul class="simple">
<li><p>Las conexiones entre los nodos representan las condiciones de decisión en cada nivel del árbol. Cada rama conecta un nodo con sus nodos hijos y representa un camino de decisiones basado en el valor de una característica.</p></li>
</ul>
</li>
</ol>
<p>Un árbol de decisión puede visualizarse como una estructura jerárquica de decisiones, donde cada nivel del árbol divide los datos en subconjuntos más homogéneos en función de las características seleccionadas en cada nodo.</p>
</section>
<section id="construccion-del-arbol">
<h4><strong>Construcción del arbol</strong><a class="headerlink" href="#construccion-del-arbol" title="Permalink to this heading">#</a></h4>
<p>Para construir un árbol de clasificación, se utiliza el mismo método de <strong>recursive binary splitting</strong> que se emplea en árboles de regresión. Sin embargo, cuando la variable de respuesta es cualitativa, no se puede utilizar el <strong>RSS</strong> (Residual Sum of Squares) como criterio de selección de divisiones óptimas. Existen varias alternativas, cuyo objetivo es encontrar nodos lo más puros y homogéneos posible. Las métricas más comunes son:</p>
<ol class="arabic">
<li><p>Tasa de error de clasificación (Classification Error Rate)</p>
<p>La tasa de error de clasificación se define como la proporción de observaciones que no pertenecen a la clase mayoritaria del nodo. Se calcula con la fórmula:</p>
<div class="math notranslate nohighlight">
\[
    E_m = 1 - \max_k(\hat{p}_{mk})
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{p}_{mk}\)</span> representa la proporción de observaciones en el nodo <span class="math notranslate nohighlight">\(m\)</span> que pertenecen a la clase <span class="math notranslate nohighlight">\(k\)</span>. Aunque esta métrica es sencilla de entender, no es lo suficientemente sensible para construir árboles de alta calidad; por esta razón, en la práctica no suele utilizarse como métrica principal.</p>
</li>
</ol>
<ol class="arabic" start="2">
<li><p>El <strong>Índice de Gini</strong> es una métrica que mide la pureza de un nodo en un árbol de decisión. Cuantifica la varianza total de las <span class="math notranslate nohighlight">\(K\)</span> clases presentes en el nodo <span class="math notranslate nohighlight">\(m\)</span>. Se calcula con la siguiente fórmula:</p>
<div class="math notranslate nohighlight">
\[
   G_m = \sum_{k=1}^{K} \hat{p}_{mk} \cdot (1 - \hat{p}_{mk})
   \]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{p}_{mk}\)</span> es la proporción de observaciones en el nodo <span class="math notranslate nohighlight">\(m\)</span> que pertenecen a la clase <span class="math notranslate nohighlight">\(k\)</span>. Si <span class="math notranslate nohighlight">\(\hat{p}_{mk}\)</span> está cerca de 0 o 1 (es decir, el nodo contiene principalmente observaciones de una sola clase), el producto <span class="math notranslate nohighlight">\(\hat{p}_{mk} \cdot (1 - \hat{p}_{mk})\)</span> será pequeño. Por lo tanto, un nodo es más puro cuanto menor es su valor de Gini.</p>
<p>El algoritmo <strong>CART</strong> (<em>Classification and Regression Trees</em>) utiliza el índice de Gini como criterio de división para maximizar la homogeneidad de los nodos.</p>
<ul>
<li><p><strong>Ejemplo de índice de Gini</strong></p>
<p>Supongamos que tenemos un nodo con 100 observaciones distribuidas en tres clases: A, B y C.</p>
 <div align="center">
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Clase</p></th>
<th class="head"><p>Cantidad de observaciones</p></th>
<th class="head"><p>Proporción (<span class="math notranslate nohighlight">\(\hat{p}_{mk}\)</span>)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>50</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>30</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>20</p></td>
<td><p>0.2</p></td>
</tr>
</tbody>
</table>
 </div>
<p>Para calcular el índice de Gini en este nodo, utilizamos la fórmula:</p>
<div class="math notranslate nohighlight">
\[
      G_m = \sum_{k=1}^{K} \hat{p}_{mk} \cdot (1 - \hat{p}_{mk})
      \]</div>
<ol class="arabic simple">
<li><p>Para la clase A:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
      \hat{p}_{A} = 0.5, \quad 0.5 \cdot (1 - 0.5) = 0.5 \cdot 0.5 = 0.25
      \]</div>
<ol class="arabic simple" start="2">
<li><p>Para la clase B:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
      \hat{p}_{B} = 0.3, \quad 0.3 \cdot (1 - 0.3) = 0.3 \cdot 0.7 = 0.21
      \]</div>
<ol class="arabic simple" start="3">
<li><p>Para la clase C:</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
      \hat{p}_{C} = 0.2, \quad 0.2 \cdot (1 - 0.2) = 0.2 \cdot 0.8 = 0.16
      \]</div>
<p>Sumamos los valores obtenidos para cada clase para obtener el índice de Gini total del nodo:</p>
<div class="math notranslate nohighlight">
\[
      G_m = 0.25 + 0.21 + 0.16 = 0.62
      \]</div>
<p>Por lo tanto, el índice de Gini para este nodo es <strong>0.62</strong>. Esto indica que el nodo tiene un grado moderado de impureza; el valor de Gini será menor a medida que el nodo contenga una mayor proporción de observaciones en una sola clase.</p>
</li>
</ul>
</li>
</ol>
<ol class="arabic" start="3">
<li><p><strong>Ganancia de Información: Entropía Cruzada</strong></p>
<p>La <strong>entropía</strong> es otra métrica que mide el nivel de desorden o impureza en un nodo. En un nodo completamente puro (que contiene observaciones de una sola clase), la entropía es cero. Por el contrario, cuando las observaciones están repartidas equitativamente entre todas las clases, la entropía alcanza su valor máximo de 1. La fórmula para calcular la entropía es:</p>
<div class="math notranslate nohighlight">
\[
   D = - \sum_{k=1}^{K} \hat{p}_{mk} \cdot \log(\hat{p}_{mk})
   \]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{p}_{mk}\)</span> es la proporción de observaciones en el nodo <span class="math notranslate nohighlight">\(m\)</span> que pertenecen a la clase <span class="math notranslate nohighlight">\(k\)</span>. La entropía se utiliza en los algoritmos <strong>C4.5</strong> y <strong>C5.0</strong> para calcular la <strong>ganancia de información</strong> (<em>information gain</em>), que determina la mejor división al maximizar la reducción del desorden en los nodos.</p>
<p>La <strong>ganancia de información</strong> permite segmentar el espacio de características de manera más eficiente, creando nodos que son lo más homogéneos posible en términos de su clase.</p>
<ul>
<li><p><strong>Ejemplo de entropía</strong></p>
<p>Supongamos que tenemos un nodo con 100 observaciones distribuidas en tres clases: A, B y C.</p>
 <div align="center">
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Clase</p></th>
<th class="head"><p>Cantidad de observaciones</p></th>
<th class="head"><p>Proporción (( \hat{p}_{mk} ))</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>A</p></td>
<td><p>50</p></td>
<td><p>0.5</p></td>
</tr>
<tr class="row-odd"><td><p>B</p></td>
<td><p>30</p></td>
<td><p>0.3</p></td>
</tr>
<tr class="row-even"><td><p>C</p></td>
<td><p>20</p></td>
<td><p>0.2</p></td>
</tr>
</tbody>
</table>
 </div>
<p>Para calcular la entropía en este nodo, utilizamos la fórmula:</p>
<div class="math notranslate nohighlight">
\[
      D = - \sum_{k=1}^{K} \hat{p}_{mk} \cdot \log_2(\hat{p}_{mk})
      \]</div>
<ol class="arabic simple">
<li><p>Para la clase A:
$<span class="math notranslate nohighlight">\(
\hat{p}_{A} = 0.5, \quad -0.5 \cdot \log_2(0.5) = -0.5 \cdot (-1) = 0.5
\)</span>$</p></li>
<li><p>Para la clase B:
$<span class="math notranslate nohighlight">\(
\hat{p}_{B} = 0.3, \quad -0.3 \cdot \log_2(0.3) \approx -0.3 \cdot (-1.737) \approx 0.521
\)</span>$</p></li>
<li><p>Para la clase C:
$<span class="math notranslate nohighlight">\(
\hat{p}_{C} = 0.2, \quad -0.2 \cdot \log_2(0.2) \approx -0.2 \cdot (-2.322) \approx 0.464
\)</span>$</p></li>
</ol>
<p>Sumamos los valores obtenidos para cada clase para obtener la entropía total del nodo:</p>
<div class="math notranslate nohighlight">
\[
      D = 0.5 + 0.521 + 0.464 = 1.485
      \]</div>
<p>Por lo tanto, la entropía para este nodo es aproximadamente <strong>1.485</strong>. Este valor indica un grado moderado de impureza en el nodo; cuanto mayor es la entropía, mayor es la mezcla de clases dentro del nodo.</p>
</li>
</ul>
</li>
</ol>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del arbol de decisión</strong></p>
<ul class="simple">
<li><p>Los árboles son fáciles de interpretar incluso cuando las relaciones entre los predictores son complejas.</p></li>
<li><p>Los modelos basados en un solo árbol (a diferencia de Random Forest o Boosting) pueden representarse gráficamente, incluso cuando el número de predictores es mayor de 3.</p></li>
<li><p>Pueden manejar tanto predictores numéricos como categóricos sin la necesidad de crear variables dummy o aplicar one-hot encoding. Sin embargo, esto depende de la implementación específica del algoritmo en cada biblioteca.</p></li>
<li><p>Al ser métodos no paramétricos, no requieren que los datos sigan ninguna distribución específica.</p></li>
<li><p>Requieren mucho menos preprocesamiento y limpieza de datos en comparación con otros métodos de aprendizaje estadístico (por ejemplo, no necesitan estandarización).</p></li>
<li><p>No se ven muy influenciados por outliers.</p></li>
<li><p>En el caso de valores faltantes en un predictor, se puede hacer una predicción utilizando todas las observaciones del último nodo alcanzado, aunque con menor precisión.</p></li>
<li><p>Son muy útiles en la exploración de datos, permitiendo identificar rápida y eficientemente las variables más importantes.</p></li>
<li><p>Seleccionan predictores de forma automática.</p></li>
<li><p>Son aplicables tanto a problemas de regresión como de clasificación.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del arbol de decisión</strong></p>
<ul class="simple">
<li><p>La capacidad predictiva de los modelos basados en un solo árbol es inferior a la de otros modelos, debido a su tendencia al overfitting y su alta varianza. Técnicas como el bagging, Random Forest y Boosting, que combinan múltiples árboles, ayudan a mejorar estos problemas.</p></li>
<li><p>Son sensibles a datos de entrenamiento desbalanceados, donde una clase puede dominar sobre las demás.</p></li>
<li><p>Pierden parte de la información al tratar predictores continuos, ya que los categorizan durante la división de los nodos.</p></li>
<li><p>La creación de las ramificaciones de los árboles se basa en el algoritmo de <em>recursive binary splitting</em>, que evalúa las divisiones de cada predictor usando una métrica específica (RSS, Gini, entropía). Los predictores continuos tienen más probabilidades de contener un punto de corte óptimo, lo cual los favorece en la creación del árbol.</p></li>
<li><p>No pueden extrapolar fuera del rango de valores de los predictores observado en los datos de entrenamiento.</p></li>
</ul>
</div>
</section>
<section id="idea-del-arbol-de-decision">
<h4><strong>Idea del arbol de decisión</strong><a class="headerlink" href="#idea-del-arbol-de-decision" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Miremos dos variables independientes en el siguiente gráfico</p></li>
</ul>
<p><img alt="arb decision 1" src="_images/ab1.png" /></p>
<ul class="simple">
<li><p>Primer split</p></li>
</ul>
<p><img alt="arb decision 2" src="_images/ab2.png" /></p>
<ul class="simple">
<li><p>Nuestra primera ramificación nos queda</p></li>
</ul>
<p><img alt="arb decision 3" src="_images/ab3.png" /></p>
<ul class="simple">
<li><p>Segundo split</p></li>
</ul>
<p><img alt="arb decision 4" src="_images/ab4.png" /></p>
<ul class="simple">
<li><p>Segunda ramificación</p></li>
</ul>
<p><img alt="arb decision 5" src="_images/ab5.png" /></p>
<ul class="simple">
<li><p>Tercer split</p></li>
</ul>
<p><img alt="arb decision 6" src="_images/ab6.png" /></p>
<ul class="simple">
<li><p>Tercera ramificación</p></li>
</ul>
<p><img alt="arb decision 7" src="_images/ab7.png" /></p>
<ul class="simple">
<li><p>Cuarto split</p></li>
</ul>
<p><img alt="arb decision 8" src="_images/ab8.png" /></p>
<ul class="simple">
<li><p>Ultima ramificación</p></li>
</ul>
<p><img alt="arb decision 9" src="_images/ab9.png" /></p>
<p>En un arbol de decisión, podemos tener un conjunto de entrenamiento con muchas características, esto hace que tengamos más splits y las ramificaciones sean más masivas.</p>
</section>
<section id="construccion-del-modelo-de-arbol-de-decision-con-sus-metricas">
<h4><strong>Construcción del modelo de arbol de decisión con sus métricas</strong><a class="headerlink" href="#construccion-del-modelo-de-arbol-de-decision-con-sus-metricas" title="Permalink to this heading">#</a></h4>
<p>Los hiperparámetros de Decision Tree Classifier (<code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>)</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">criterion</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Función que mide la calidad de una división.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">str</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'gini'</span></code> (por defecto): usa el índice de Gini.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'entropy'</span></code>: usa la entropía de la información.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">splitter</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Estrategia para dividir cada nodo.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">str</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'best'</span></code> (por defecto): selecciona la mejor división.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'random'</span></code>: selecciona una división al azar.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Profundidad máxima del árbol. Controla el sobreajuste.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">None</span></code> (el árbol crece hasta que todas las hojas son puras o contienen menos muestras que <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número mínimo de muestras necesarias para dividir un nodo.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">2</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número mínimo de muestras requeridas para formar una hoja.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Fracción mínima de peso de muestras requerido en una hoja.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número de características a considerar para encontrar la mejor división.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> (por defecto): usa todas las características.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">int</span></code>: selecciona una cantidad específica de características.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">float</span></code>: selecciona un porcentaje de características.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'auto'</span></code>, <code class="docutils literal notranslate"><span class="pre">'sqrt'</span></code>, <code class="docutils literal notranslate"><span class="pre">'log2'</span></code>.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número máximo de nodos hoja.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Umbral mínimo de reducción de impureza.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Parámetro de complejidad de poda (post-poda).</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diccionario de hiperparámetros para DecisionTreeClassifier</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>  <span class="c1"># Medida de calidad de la división</span>
    <span class="s1">&#39;splitter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;random&#39;</span><span class="p">],</span>  <span class="c1"># Estrategia de división</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>  <span class="c1"># Profundidad máxima del árbol</span>
    <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>  <span class="c1"># Muestras mínimas para dividir un nodo</span>
    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Muestras mínimas para formar una hoja</span>
    <span class="s1">&#39;min_weight_fraction_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>  <span class="c1"># Fracción mínima de peso de muestras en una hoja</span>
    <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">],</span>  <span class="c1"># Características a considerar para la mejor división</span>
    <span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>  <span class="c1"># Número máximo de nodos hoja</span>
    <span class="s1">&#39;min_impurity_decrease&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>  <span class="c1"># Umbral de reducción mínima de impureza</span>
    <span class="s1">&#39;ccp_alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>  <span class="c1"># Parámetro de complejidad de poda</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Encontremos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar paquete</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1"># Crear y entrenar el modelo de Decision Tree</span>
<span class="n">pipeline_tree</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">DecisionTreeClassifier</span><span class="p">())</span>

<span class="c1"># Definir la malla de hiperparámetros para optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;decisiontreeclassifier__criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__splitter&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;best&#39;</span><span class="p">,</span> <span class="s1">&#39;random&#39;</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__min_impurity_decrease&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">&#39;decisiontreeclassifier__ccp_alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_tree</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_tree</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 18432 candidates, totalling 92160 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-19 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-19 {
  color: var(--sklearn-color-text);
}

#sk-container-id-19 pre {
  padding: 0;
}

#sk-container-id-19 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-19 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-19 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-19 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-19 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-19 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-19 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-19 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-19 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-19 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-19 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-19 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-19 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-19 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-19 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-19 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-19 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-19 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-19 div.sk-label label.sk-toggleable__label,
#sk-container-id-19 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-19 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-19 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-19 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-19 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-19 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-19 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-19 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-19 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-19 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-19 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-19" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;decisiontreeclassifier&#x27;,
                                        DecisionTreeClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;decisiontreeclassifier__ccp_alpha&#x27;: [0.0, 0.01, 0.1,
                                                               0.2],
                         &#x27;decisiontreeclassifier__criterion&#x27;: [&#x27;gini&#x27;,
                                                               &#x27;entropy&#x27;],
                         &#x27;decisiontreeclassifier__max_depth&#x27;: [None, 10, 20, 30,
                                                               40, 50],
                         &#x27;decisiontreeclassifier__max_features&#x27;: [None, &#x27;auto&#x27;,
                                                                  &#x27;sqrt&#x27;,
                                                                  &#x27;log2&#x27;],
                         &#x27;decisiontreeclassifier__min_impurity_decrease&#x27;: [0.0,
                                                                           0.01,
                                                                           0.1],
                         &#x27;decisiontreeclassifier__min_samples_leaf&#x27;: [1, 2, 5,
                                                                      10],
                         &#x27;decisiontreeclassifier__min_samples_split&#x27;: [2, 5, 10,
                                                                       20],
                         &#x27;decisiontreeclassifier__splitter&#x27;: [&#x27;best&#x27;,
                                                              &#x27;random&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-64" type="checkbox" ><label for="sk-estimator-id-64" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;decisiontreeclassifier&#x27;,
                                        DecisionTreeClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;decisiontreeclassifier__ccp_alpha&#x27;: [0.0, 0.01, 0.1,
                                                               0.2],
                         &#x27;decisiontreeclassifier__criterion&#x27;: [&#x27;gini&#x27;,
                                                               &#x27;entropy&#x27;],
                         &#x27;decisiontreeclassifier__max_depth&#x27;: [None, 10, 20, 30,
                                                               40, 50],
                         &#x27;decisiontreeclassifier__max_features&#x27;: [None, &#x27;auto&#x27;,
                                                                  &#x27;sqrt&#x27;,
                                                                  &#x27;log2&#x27;],
                         &#x27;decisiontreeclassifier__min_impurity_decrease&#x27;: [0.0,
                                                                           0.01,
                                                                           0.1],
                         &#x27;decisiontreeclassifier__min_samples_leaf&#x27;: [1, 2, 5,
                                                                      10],
                         &#x27;decisiontreeclassifier__min_samples_split&#x27;: [2, 5, 10,
                                                                       20],
                         &#x27;decisiontreeclassifier__splitter&#x27;: [&#x27;best&#x27;,
                                                              &#x27;random&#x27;]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-65" type="checkbox" ><label for="sk-estimator-id-65" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;decisiontreeclassifier&#x27;,
                 DecisionTreeClassifier(ccp_alpha=0.01, max_depth=30,
                                        max_features=&#x27;log2&#x27;,
                                        min_samples_leaf=10,
                                        min_samples_split=10,
                                        splitter=&#x27;random&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-66" type="checkbox" ><label for="sk-estimator-id-66" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-67" type="checkbox" ><label for="sk-estimator-id-67" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;DecisionTreeClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(ccp_alpha=0.01, max_depth=30, max_features=&#x27;log2&#x27;,
                       min_samples_leaf=10, min_samples_split=10,
                       splitter=&#x27;random&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para arbol:&quot;</span><span class="p">,</span> <span class="n">grid_search_tree</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para arbol: {&#39;decisiontreeclassifier__ccp_alpha&#39;: 0.01, &#39;decisiontreeclassifier__criterion&#39;: &#39;gini&#39;, &#39;decisiontreeclassifier__max_depth&#39;: 30, &#39;decisiontreeclassifier__max_features&#39;: &#39;log2&#39;, &#39;decisiontreeclassifier__min_impurity_decrease&#39;: 0.0, &#39;decisiontreeclassifier__min_samples_leaf&#39;: 10, &#39;decisiontreeclassifier__min_samples_split&#39;: 10, &#39;decisiontreeclassifier__splitter&#39;: &#39;random&#39;}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construcción del modelo con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo el arbol de decision</span>
<span class="n">modelo_tree</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                            <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">ccp_alpha</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span><span class="n">criterion</span> <span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">max_features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_impurity_decrease</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                                                   <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">splitter</span> <span class="o">=</span> <span class="s1">&#39;random&#39;</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-20 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-20 {
  color: var(--sklearn-color-text);
}

#sk-container-id-20 pre {
  padding: 0;
}

#sk-container-id-20 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-20 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-20 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-20 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-20 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-20 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-20 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-20 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-20 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-20 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-20 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-20 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-20 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-20 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-20 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-20 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-20 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-20 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-20 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-20 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-20 div.sk-label label.sk-toggleable__label,
#sk-container-id-20 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-20 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-20 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-20 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-20 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-20 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-20 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-20 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-20 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-20 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-20 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-20 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-20" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;decisiontreeclassifier&#x27;,
                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, min_samples_leaf=5,
                                        min_samples_split=5,
                                        splitter=&#x27;random&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-68" type="checkbox" ><label for="sk-estimator-id-68" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;decisiontreeclassifier&#x27;,
                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, min_samples_leaf=5,
                                        min_samples_split=5,
                                        splitter=&#x27;random&#x27;))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-69" type="checkbox" ><label for="sk-estimator-id-69" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-70" type="checkbox" ><label for="sk-estimator-id-70" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;DecisionTreeClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, min_samples_leaf=5,
                       min_samples_split=5, splitter=&#x27;random&#x27;)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Calculemos las métricas del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_tree</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_tree</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el train</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       0.94      0.88      0.91       315
           1       0.86      0.93      0.89       237

    accuracy                           0.90       552
   macro avg       0.90      0.91      0.90       552
weighted avg       0.91      0.90      0.90       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82        68
           1       0.83      0.81      0.82        70

    accuracy                           0.82       138
   macro avg       0.82      0.82      0.82       138
weighted avg       0.82      0.82      0.82       138
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/aaca009186dd7832e624a68e0121a62754c803b172c7e9c7853643d5f983746a.png" src="_images/aaca009186dd7832e624a68e0121a62754c803b172c7e9c7853643d5f983746a.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/bbb472a9294f0233325473f8e0cca8ae69ffcc72d5f0fa4b3b1041afec153077.png" src="_images/bbb472a9294f0233325473f8e0cca8ae69ffcc72d5f0fa4b3b1041afec153077.png" />
</div>
</div>
</section>
</section>
<section id="modelo-random-forest">
<h3><strong>Modelo Random Forest</strong><a class="headerlink" href="#modelo-random-forest" title="Permalink to this heading">#</a></h3>
<p><strong>Random Forest</strong> es un algoritmo de aprendizaje supervisado, ampliamente utilizado tanto en problemas de clasificación como de regresión. Fue desarrollado como una extensión de los árboles de decisión para mejorar su precisión y evitar problemas de sobreajuste, mediante la creación de múltiples árboles de decisión y la combinación de sus resultados.</p>
<p>Random Forest es un conjunto (o bosque) de árboles de decisión que, al combinar sus resultados, proporciona una predicción más precisa y estable que un solo árbol. La técnica detrás de Random Forest utiliza el método de “bagging” (Bootstrap Aggregating), donde se entrenan múltiples árboles independientes usando diferentes subconjuntos aleatorios de datos, y sus predicciones se promedian (regresión) o se eligen por voto mayoritario (clasificación).</p>
<section id="caracteristicas-del-modelo">
<h4><strong>Características del modelo</strong><a class="headerlink" href="#caracteristicas-del-modelo" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Modelo de Ensemble:</strong> Utiliza múltiples árboles de decisión que colaboran para la predicción.</p></li>
<li><p><strong>Aleatorización:</strong> Realiza selección aleatoria tanto de muestras (bootstrap) como de características en cada nodo, lo que contribuye a la reducción del sobreajuste.</p></li>
<li><p><strong>No requiere normalización de datos:</strong> Puede manejar datos de diferentes escalas sin necesidad de estandarización.</p></li>
<li><p><strong>Resistencia al sobreajuste:</strong> El uso de múltiples árboles reduce el riesgo de sobreajuste, aunque un número muy alto de árboles puede incrementar el tiempo de cálculo.</p></li>
<li><p><strong>Adaptable a datos de alta dimensionalidad:</strong> Funciona bien con datos que tienen muchas variables, pero el costo computacional aumenta con el tamaño del bosque.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas de random forest</strong></p>
<ul class="simple">
<li><p><strong>Precisión elevada:</strong> La combinación de predicciones tiende a mejorar la precisión respecto a un único árbol de decisión.</p></li>
<li><p><strong>Reducción del sobreajuste:</strong> La aleatorización ayuda a que el modelo sea menos sensible al ruido.</p></li>
<li><p><strong>Adaptabilidad:</strong> Puede usarse tanto para clasificación como para regresión.</p></li>
<li><p><strong>Robustez frente a valores atípicos y características irrelevantes:</strong> Dado que se considera un subconjunto de características en cada nodo, los efectos de las variables irrelevantes se reducen.</p></li>
<li><p><strong>Buen rendimiento en datos grandes y complejos:</strong> Su estructura permite manejar eficientemente grandes volúmenes de datos y variables.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas de random forest</strong></p>
<ul class="simple">
<li><p><strong>Tiempo de cálculo elevado:</strong> Entrenar múltiples árboles requiere más recursos computacionales y tiempo que un modelo individual.</p></li>
<li><p><strong>Complejidad de interpretación:</strong> La interpretabilidad de Random Forest es menor que la de un árbol de decisión único, ya que se combinan múltiples modelos.</p></li>
<li><p><strong>Propenso a sobreajuste en datasets pequeños:</strong> Aunque en general reduce el sobreajuste, en conjuntos de datos pequeños o muy ruidosos podría sobreajustarse si se configura con muchos árboles.</p></li>
<li><p><strong>Altos requerimientos de almacenamiento:</strong> La necesidad de guardar múltiples árboles hace que el modelo ocupe más espacio en memoria.</p></li>
</ul>
</div>
</section>
<section id="construccion-del-modelo-de-random-forest">
<h4><strong>Construcción del modelo de Random Forest</strong><a class="headerlink" href="#construccion-del-modelo-de-random-forest" title="Permalink to this heading">#</a></h4>
<p>Los hiperparámetros para <strong>Random Forest</strong> son:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número de árboles en el bosque.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code></p></li>
<li><p><strong>Valores posibles</strong>: Valores como <code class="docutils literal notranslate"><span class="pre">10</span></code>, <code class="docutils literal notranslate"><span class="pre">50</span></code>, <code class="docutils literal notranslate"><span class="pre">100</span></code>, <code class="docutils literal notranslate"><span class="pre">200</span></code>, <code class="docutils literal notranslate"><span class="pre">500</span></code> (por defecto es <code class="docutils literal notranslate"><span class="pre">100</span></code>).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">criterion</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Función para medir la calidad de la división.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">str</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'gini'</span></code> (por defecto): usa el índice de Gini.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'entropy'</span></code>: usa la entropía de la información.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'log_loss'</span></code>: usa la pérdida logarítmica para optimización.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Profundidad máxima de cada árbol en el bosque.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">None</span></code> (crece hasta que todas las hojas son puras o contienen menos muestras que <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número mínimo de muestras necesarias para dividir un nodo.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores posibles</strong>: <code class="docutils literal notranslate"><span class="pre">2</span></code> (por defecto) o un porcentaje de muestras si es un <code class="docutils literal notranslate"><span class="pre">float</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número mínimo de muestras requeridas para formar una hoja.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_weight_fraction_leaf</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Fracción mínima de peso de muestras requerida en una hoja.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número de características a considerar al buscar la mejor división.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">str</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> (por defecto): usa todas las características.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'auto'</span></code> o <code class="docutils literal notranslate"><span class="pre">'sqrt'</span></code>: usa la raíz cuadrada del número de características.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'log2'</span></code>: usa el logaritmo en base 2 del número de características.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número máximo de nodos hoja por árbol.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Umbral mínimo de reducción de impureza para permitir una división.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">bootstrap</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Si usar muestreo con reemplazo.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">bool</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Ponderación de clases.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">dict</span></code>, <code class="docutils literal notranslate"><span class="pre">list</span> <span class="pre">of</span> <span class="pre">dict</span></code> o <code class="docutils literal notranslate"><span class="pre">str</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> (por defecto): sin ponderación.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'balanced'</span></code>: ajusta automáticamente el peso de las clases.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'balanced_subsample'</span></code>: ajusta el peso de cada clase según la frecuencia de clases en cada bootstrap.</p></li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Parámetro de complejidad para la poda de post-entrenamiento.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valor por defecto</strong>: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_samples</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número o fracción máxima de muestras usadas para entrenar cada árbol individual.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code> o <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores posibles</strong>: Si <code class="docutils literal notranslate"><span class="pre">float</span></code>, representa un porcentaje del total; si <code class="docutils literal notranslate"><span class="pre">int</span></code>, un número absoluto.</p></li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diccionario de los parámetros de random forest</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>  <span class="c1"># Número de árboles en el bosque</span>
    <span class="s1">&#39;criterion&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="s1">&#39;log_loss&#39;</span><span class="p">],</span>  <span class="c1"># Función para medir la calidad de la división</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>  <span class="c1"># Profundidad máxima de cada árbol</span>
    <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>  <span class="c1"># Mínimo número de muestras para dividir un nodo</span>
    <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="c1"># Mínimo número de muestras en una hoja</span>
    <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>  <span class="c1"># Características consideradas al buscar la mejor división</span>
    <span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>  <span class="c1"># Número máximo de nodos hoja</span>
    <span class="s1">&#39;min_impurity_decrease&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>  <span class="c1"># Umbral para reducir la impureza en una división</span>
    <span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>  <span class="c1"># Si se usa muestreo con reemplazo</span>
    <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="s1">&#39;balanced_subsample&#39;</span><span class="p">],</span>  <span class="c1"># Peso de las clases</span>
    <span class="s1">&#39;ccp_alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>  <span class="c1"># Parámetro de complejidad para la poda</span>
<span class="p">}</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Encontremos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar paquete</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># Crear y entrenar el modelo de Random Forest</span>
<span class="n">pipeline_rf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">RandomForestClassifier</span><span class="p">())</span>

<span class="c1"># Definir la malla de hiperparámetros para optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;randomforestclassifier__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
    <span class="s1">&#39;randomforestclassifier__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
    <span class="s1">&#39;randomforestclassifier__min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="s1">&#39;randomforestclassifier__min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
    <span class="s1">&#39;randomforestclassifier__max_features&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span> <span class="s1">&#39;log2&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="s1">&#39;randomforestclassifier__bootstrap&#39;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_rf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_rf</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 648 candidates, totalling 3240 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-21 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-21 {
  color: var(--sklearn-color-text);
}

#sk-container-id-21 pre {
  padding: 0;
}

#sk-container-id-21 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-21 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-21 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-21 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-21 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-21 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-21 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-21 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-21 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-21 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-21 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-21 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-21 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-21 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-21 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-21 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-21 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-21 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-21 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-21 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-21 div.sk-label label.sk-toggleable__label,
#sk-container-id-21 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-21 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-21 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-21 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-21 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-21 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-21 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-21 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-21 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-21 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-21 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-21 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-21" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;randomforestclassifier&#x27;,
                                        RandomForestClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;randomforestclassifier__bootstrap&#x27;: [True, False],
                         &#x27;randomforestclassifier__max_depth&#x27;: [3, 5, 7, 9],
                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;,
                                                                  &#x27;log2&#x27;,
                                                                  None],
                         &#x27;randomforestclassifier__min_samples_leaf&#x27;: [1, 4, 7],
                         &#x27;randomforestclassifier__min_samples_split&#x27;: [2, 5, 8],
                         &#x27;randomforestclassifier__n_estimators&#x27;: [100, 200,
                                                                  500]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-71" type="checkbox" ><label for="sk-estimator-id-71" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;randomforestclassifier&#x27;,
                                        RandomForestClassifier())]),
             n_jobs=-1,
             param_grid={&#x27;randomforestclassifier__bootstrap&#x27;: [True, False],
                         &#x27;randomforestclassifier__max_depth&#x27;: [3, 5, 7, 9],
                         &#x27;randomforestclassifier__max_features&#x27;: [&#x27;sqrt&#x27;,
                                                                  &#x27;log2&#x27;,
                                                                  None],
                         &#x27;randomforestclassifier__min_samples_leaf&#x27;: [1, 4, 7],
                         &#x27;randomforestclassifier__min_samples_split&#x27;: [2, 5, 8],
                         &#x27;randomforestclassifier__n_estimators&#x27;: [100, 200,
                                                                  500]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-72" type="checkbox" ><label for="sk-estimator-id-72" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;randomforestclassifier&#x27;,
                 RandomForestClassifier(max_depth=5, max_features=None,
                                        min_samples_leaf=7,
                                        min_samples_split=5))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-73" type="checkbox" ><label for="sk-estimator-id-73" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-74" type="checkbox" ><label for="sk-estimator-id-74" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(max_depth=5, max_features=None, min_samples_leaf=7,
                       min_samples_split=5)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para random forest:&quot;</span><span class="p">,</span> <span class="n">grid_search_rf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para random forest: {&#39;randomforestclassifier__bootstrap&#39;: True, &#39;randomforestclassifier__max_depth&#39;: 5, &#39;randomforestclassifier__max_features&#39;: None, &#39;randomforestclassifier__min_samples_leaf&#39;: 7, &#39;randomforestclassifier__min_samples_split&#39;: 5, &#39;randomforestclassifier__n_estimators&#39;: 100}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construcción del modelo con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo el random forest</span>
<span class="n">modelo_rf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> 
                          <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span><span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                                 <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
                                                 <span class="n">max_features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span><span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-22 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-22 {
  color: var(--sklearn-color-text);
}

#sk-container-id-22 pre {
  padding: 0;
}

#sk-container-id-22 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-22 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-22 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-22 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-22 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-22 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-22 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-22 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-22 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-22 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-22 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-22 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-22 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-22 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-22 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-22 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-22 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-22 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-22 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-22 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-22 div.sk-label label.sk-toggleable__label,
#sk-container-id-22 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-22 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-22 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-22 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-22 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-22 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-22 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-22 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-22 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-22 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-22 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-22 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-22" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;randomforestclassifier&#x27;,
                 RandomForestClassifier(max_depth=5, max_features=None,
                                        min_samples_leaf=7, min_samples_split=8,
                                        n_estimators=200))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-75" type="checkbox" ><label for="sk-estimator-id-75" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;randomforestclassifier&#x27;,
                 RandomForestClassifier(max_depth=5, max_features=None,
                                        min_samples_leaf=7, min_samples_split=8,
                                        n_estimators=200))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-76" type="checkbox" ><label for="sk-estimator-id-76" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-77" type="checkbox" ><label for="sk-estimator-id-77" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RandomForestClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>RandomForestClassifier(max_depth=5, max_features=None, min_samples_leaf=7,
                       min_samples_split=8, n_estimators=200)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Calculemos las métricas del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_rf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el train</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       0.93      0.89      0.91       315
           1       0.86      0.91      0.89       237

    accuracy                           0.90       552
   macro avg       0.90      0.90      0.90       552
weighted avg       0.90      0.90      0.90       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.82      0.82      0.82        68
           1       0.83      0.83      0.83        70

    accuracy                           0.83       138
   macro avg       0.83      0.83      0.83       138
weighted avg       0.83      0.83      0.83       138
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6ddaa78f15f3290f35fe51ad9385860685b031323cfe74734ddf7732791a5928.png" src="_images/6ddaa78f15f3290f35fe51ad9385860685b031323cfe74734ddf7732791a5928.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5c79a5d69884d207c83fbec827357aaf56ca1933aab1e827715ff5b6b2e1df46.png" src="_images/5c79a5d69884d207c83fbec827357aaf56ca1933aab1e827715ff5b6b2e1df46.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora, miremo la importancia de las variables predictoras</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extraer el modelo RandomForest del pipeline</span>
<span class="n">modelo_entrenado</span> <span class="o">=</span> <span class="n">modelo_rf</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;randomforestclassifier&#39;</span><span class="p">]</span>

<span class="c1"># Obtener la importancia de los predictores</span>
<span class="n">importancia_predictores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s1">&#39;predictor&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
     <span class="s1">&#39;importancia&#39;</span><span class="p">:</span> <span class="n">modelo_entrenado</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">}</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Importancia de los predictores en el modelo&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">importancia_predictores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importancia&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Importancia de los predictores en el modelo
-------------------------------------------
            predictor  importancia
35     PriorDefault_t     0.737999
4              Income     0.069270
1                Debt     0.049095
2       YearsEmployed     0.037078
3         CreditScore     0.028774
0                 Age     0.023443
36         Employed_t     0.018548
29        Ethnicity_h     0.006981
8           Married_y     0.004969
37          Citizen_p     0.003954
5               Sex_b     0.003419
9      BankCustomer_g     0.002925
33        Ethnicity_v     0.002471
7           Married_u     0.002271
11     BankCustomer_p     0.002119
26       Ethnicity_bb     0.002074
22   EducationLevel_q     0.001707
12   EducationLevel_b     0.000799
24   EducationLevel_w     0.000515
13   EducationLevel_c     0.000502
25   EducationLevel_x     0.000448
15   EducationLevel_d     0.000346
38          Citizen_s     0.000168
28       Ethnicity_ff     0.000061
18   EducationLevel_i     0.000039
20   EducationLevel_k     0.000028
23   EducationLevel_r     0.000000
21   EducationLevel_m     0.000000
27       Ethnicity_dd     0.000000
17  EducationLevel_ff     0.000000
30        Ethnicity_j     0.000000
31        Ethnicity_n     0.000000
32        Ethnicity_o     0.000000
16   EducationLevel_e     0.000000
34        Ethnicity_z     0.000000
14  EducationLevel_cc     0.000000
10    BankCustomer_gg     0.000000
6           Married_l     0.000000
19   EducationLevel_j     0.000000
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Miremos la influencia que tiene cada predictor sobre una determinada métrica de evaluación del modelo (estimada por out-of-bag error o validación cruzada) y su gráfica</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">cpu_count</span>

<span class="c1"># Importancia de los predictores basada en permutación</span>
<span class="c1"># ==============================================================================</span>
<span class="n">importancia</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">estimator</span>    <span class="o">=</span> <span class="n">modelo_entrenado</span><span class="p">,</span>
                <span class="n">X</span>            <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y</span>            <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                <span class="n">n_repeats</span>    <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                <span class="n">scoring</span>      <span class="o">=</span> <span class="s1">&#39;f1&#39;</span><span class="p">,</span>
                <span class="n">n_jobs</span>       <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span>
             <span class="p">)</span>

<span class="c1"># Se almacenan los resultados (media y desviación) en un dataframe</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">importancia</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;importances_std&#39;</span><span class="p">]}</span>
                 <span class="p">)</span>
<span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>importances_mean</th>
      <th>importances_std</th>
      <th>feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35</th>
      <td>0.395687</td>
      <td>0.034392</td>
      <td>PriorDefault_t</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.002315</td>
      <td>0.001590</td>
      <td>BankCustomer_p</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.002315</td>
      <td>0.001590</td>
      <td>Married_u</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.001798</td>
      <td>0.001386</td>
      <td>Debt</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0.001549</td>
      <td>0.002035</td>
      <td>Ethnicity_v</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.001000</td>
      <td>0.000816</td>
      <td>EducationLevel_c</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.000976</td>
      <td>0.001877</td>
      <td>Married_y</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.000976</td>
      <td>0.001877</td>
      <td>BankCustomer_g</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000971</td>
      <td>0.005409</td>
      <td>Income</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000860</td>
      <td>0.003485</td>
      <td>CreditScore</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.000333</td>
      <td>0.000667</td>
      <td>EducationLevel_x</td>
    </tr>
    <tr>
      <th>22</th>
      <td>0.000333</td>
      <td>0.000667</td>
      <td>EducationLevel_q</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.000219</td>
      <td>0.001437</td>
      <td>EducationLevel_w</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.000198</td>
      <td>0.003435</td>
      <td>Employed_t</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_r</td>
    </tr>
    <tr>
      <th>34</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_z</td>
    </tr>
    <tr>
      <th>32</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_o</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_n</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_j</td>
    </tr>
    <tr>
      <th>28</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_ff</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_dd</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Citizen_p</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Age</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_j</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_m</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_k</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_i</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_ff</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_e</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_d</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_cc</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_b</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_gg</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Married_l</td>
    </tr>
    <tr>
      <th>29</th>
      <td>-0.000344</td>
      <td>0.001751</td>
      <td>Ethnicity_h</td>
    </tr>
    <tr>
      <th>26</th>
      <td>-0.001004</td>
      <td>0.000820</td>
      <td>Ethnicity_bb</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.001335</td>
      <td>0.002550</td>
      <td>YearsEmployed</td>
    </tr>
    <tr>
      <th>38</th>
      <td>-0.001792</td>
      <td>0.000896</td>
      <td>Citizen_s</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.003912</td>
      <td>0.004050</td>
      <td>Sex_b</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gráfico</span>
<span class="c1"># ==============================================================================</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">xerr</span><span class="o">=</span><span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_std&#39;</span><span class="p">],</span>
    <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Importancia de los predictores (train)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Incremento del error tras la permutación&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3c85ccb37a4873bc542064d5d997b81dc16f6237f98eb8eea51e1b1bd5ca2a73.png" src="_images/3c85ccb37a4873bc542064d5d997b81dc16f6237f98eb8eea51e1b1bd5ca2a73.png" />
</div>
</div>
<p>La gráfica muestra la importancia de los predictores en un modelo entrenado, medida a través del incremento en el error tras la permutación de cada predictor. Este método evalúa cuánto afecta el desempeño del modelo la aleatorización de cada variable, indicando que los predictores más importantes causan mayores aumentos en el error.</p>
<ul class="simple">
<li><p>El predictor <strong>“PriorDefault”</strong> es el único que parece tener un efecto considerable en el error, ya que su barra es notablemente más larga en comparación con el resto.</p></li>
<li><p>Esto sugiere que el modelo depende principalmente de <strong>“PriorDefault”</strong> para hacer predicciones, mientras que las otras variables tienen una importancia mínima o nula en el rendimiento del modelo.</p></li>
<li><p>La concentración de importancia en un solo predictor podría indicar que <strong>“PriorDefault”</strong> es un factor altamente determinante en el contexto de este modelo.</p></li>
</ul>
</section>
</section>
<section id="modelo-de-xgboost">
<h3><strong>Modelo de XGBoost</strong><a class="headerlink" href="#modelo-de-xgboost" title="Permalink to this heading">#</a></h3>
<p><strong>XGBoost (Extreme Gradient Boosting)</strong> es un algoritmo de aprendizaje supervisado basado en árboles de decisión, diseñado para mejorar el rendimiento y la velocidad de los modelos de boosting. Su característica principal es el uso de gradiente boosting optimizado, lo cual permite crear modelos altamente eficientes y precisos, especialmente adecuado para grandes conjuntos de datos.</p>
<section id="definicion-de-xgboost">
<h4><strong>Definición de XGboost</strong><a class="headerlink" href="#definicion-de-xgboost" title="Permalink to this heading">#</a></h4>
<p>XGBoost es un algoritmo de boosting basado en el principio de <strong>Gradient Boosting</strong>, donde múltiples árboles se entrenan secuencialmente, y cada nuevo árbol corrige los errores de los árboles anteriores. XGBoost introduce optimizaciones para aumentar la velocidad, reducir el uso de memoria y mejorar la precisión en comparación con otros algoritmos de boosting.</p>
<section id="formula-matematica">
<h5><strong>Fórmula matemática</strong><a class="headerlink" href="#formula-matematica" title="Permalink to this heading">#</a></h5>
<p>XGBoost minimiza una función de pérdida usando un enfoque de optimización basado en el gradiente. Para cada paso <span class="math notranslate nohighlight">\(t\)</span> en el modelo, se ajusta un nuevo árbol <span class="math notranslate nohighlight">\(f_t\)</span> para reducir los errores residuales de la predicción anterior. La predicción se actualiza como:</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_i^{(t)} = \hat{y}_i^{(t-1)} + f_t(x_i),
\]</div>
<p>donde:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{y}_i^{(t)}\)</span> es la predicción para el paso <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(f_t(x_i)\)</span> es la corrección que el árbol <span class="math notranslate nohighlight">\(t\)</span> realiza en la predicción del paso anterior.</p></li>
</ul>
<p>La función de pérdida se minimiza mediante la optimización de gradiente, y cada árbol nuevo se entrena para corregir los errores de predicción acumulados de los árboles anteriores.</p>
</section>
</section>
<section id="id5">
<h4><strong>Características del modelo</strong><a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Boosting por gradiente</strong>: Se enfoca en corregir los errores de los árboles previos, agregando árboles secuencialmente.</p></li>
<li><p><strong>Regularización</strong>: Incluye términos de regularización <span class="math notranslate nohighlight">\(L_1\)</span> y <span class="math notranslate nohighlight">\(L_2\)</span> para reducir el sobreajuste.</p></li>
<li><p><strong>Control de crecimiento de árbol</strong>: Permite el ajuste de parámetros como la profundidad del árbol, número de árboles y tasa de aprendizaje para optimizar el modelo.</p></li>
<li><p><strong>Computación en paralelo</strong>: Optimizado para ejecutar operaciones en paralelo, mejorando la velocidad de entrenamiento.</p></li>
<li><p><strong>Manejo eficiente de valores faltantes</strong>: XGBoost puede manejar datos con valores nulos sin necesidad de imputación adicional.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title"><strong>Ventajas del XGboost</strong></p>
<ul class="simple">
<li><p><strong>Alta precisión</strong>: La combinación de boosting y regularización produce modelos precisos y efectivos.</p></li>
<li><p><strong>Reducción de sobreajuste</strong>: El término de regularización ayuda a evitar el sobreajuste, un problema común en otros modelos de boosting.</p></li>
<li><p><strong>Escalabilidad</strong>: Optimizado para trabajar con grandes volúmenes de datos y con múltiples núcleos, acelerando significativamente el proceso de entrenamiento.</p></li>
<li><p><strong>Flexibilidad</strong>: Soporta tanto clasificación como regresión, con varias funciones de pérdida ajustables.</p></li>
<li><p><strong>Capacidad de manejo de datos faltantes</strong>: XGBoost puede hacer inferencias sobre datos faltantes sin pasos adicionales de preprocesamiento.</p></li>
</ul>
</div>
<div class="note admonition">
<p class="admonition-title"><strong>Desventajas del XGboost</strong></p>
<ul class="simple">
<li><p><strong>Requiere ajuste de hiperparámetros</strong>: XGBoost tiene muchos hiperparámetros, y encontrar la configuración óptima puede ser complejo y requerir tiempo.</p></li>
<li><p><strong>Costoso en términos computacionales</strong>: Aunque está optimizado para velocidad, aún es un modelo computacionalmente costoso, especialmente en comparación con algoritmos como Random Forest.</p></li>
<li><p><strong>Complejidad de interpretación</strong>: Los modelos de boosting son menos interpretables que los árboles de decisión individuales.</p></li>
<li><p><strong>Riesgo de sobreajuste en datasets pequeños</strong>: En conjuntos de datos pequeños, la alta capacidad de ajuste puede llevar a un sobreajuste si no se regulan adecuadamente los parámetros.</p></li>
</ul>
</div>
</section>
<section id="construccion-del-modelo-xgboost-con-sus-metricas">
<h4><strong>Construcción del modelo XGboost con sus métricas</strong><a class="headerlink" href="#construccion-del-modelo-xgboost-con-sus-metricas" title="Permalink to this heading">#</a></h4>
<p>Los hiperparámetros para <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> son:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Número de árboles de refuerzo en el modelo. Cada árbol se ajusta secuencialmente.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[50,</span> <span class="pre">100,</span> <span class="pre">200,</span> <span class="pre">500]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Tasa de aprendizaje, controla cuánto contribuye cada árbol al modelo final.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0.01,</span> <span class="pre">0.05,</span> <span class="pre">0.1,</span> <span class="pre">0.2,</span> <span class="pre">0.3]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Profundidad máxima de cada árbol individual. Controla el sobreajuste.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[3,</span> <span class="pre">5,</span> <span class="pre">7,</span> <span class="pre">10,</span> <span class="pre">15]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_child_weight</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Peso mínimo de la suma de instancias en un nodo. Un valor mayor reduce el sobreajuste.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">int</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">3,</span> <span class="pre">5,</span> <span class="pre">10]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">subsample</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Fracción de muestras utilizadas para entrenar cada árbol. Valores más bajos reducen el sobreajuste.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0.5,</span> <span class="pre">0.7,</span> <span class="pre">0.8,</span> <span class="pre">1.0]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colsample_bytree</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Fracción de características utilizadas para construir cada árbol.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0.5,</span> <span class="pre">0.7,</span> <span class="pre">0.8,</span> <span class="pre">1.0]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Reducción mínima de pérdida necesaria para realizar una partición en un nodo del árbol.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0.1,</span> <span class="pre">0.2,</span> <span class="pre">0.3]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">reg_alpha</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Término de regularización L1, que ayuda a hacer la selección de características.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0.01,</span> <span class="pre">0.1,</span> <span class="pre">1]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">reg_lambda</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Término de regularización L2, ayuda a evitar el sobreajuste.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0.01,</span> <span class="pre">0.1,</span> <span class="pre">1]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">scale_pos_weight</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Balancea las clases en problemas de clasificación desequilibrados.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">float</span></code></p></li>
<li><p><strong>Valores comunes</strong>: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">10,</span> <span class="pre">50,</span> <span class="pre">100]</span></code></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">objective</span></code></p>
<ul>
<li><p><strong>Descripción</strong>: Función objetivo a optimizar.</p></li>
<li><p><strong>Tipo</strong>: <code class="docutils literal notranslate"><span class="pre">str</span></code></p></li>
<li><p><strong>Valores posibles</strong>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">'binary:logistic'</span></code> (por defecto para clasificación binaria)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'multi:softmax'</span></code> (para clasificación multiclase)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'multi:softprob'</span></code> (para probabilidades multiclase)</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Diccionario de los parámetros de xgboost</span>
<span class="n">param_grid_xgb</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span>
    <span class="s1">&#39;min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
    <span class="s1">&#39;subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="s1">&#39;colsample_bytree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="s1">&#39;reg_alpha&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;reg_lambda&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
    <span class="s1">&#39;scale_pos_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;binary:logistic&#39;</span><span class="p">,</span> <span class="s1">&#39;multi:softmax&#39;</span><span class="p">,</span> <span class="s1">&#39;multi:softprob&#39;</span><span class="p">]</span>
<span class="p">}</span>

</pre></div>
</div>
<ul class="simple">
<li><p>Hallemos los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar paquetes</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="c1"># Crear y entrenar el modelo de XGBoost</span>
<span class="n">pipeline_xgb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">XGBClassifier</span><span class="p">())</span>

<span class="c1"># Definir la malla de hiperparámetros para optimización</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;xgbclassifier__n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span>
    <span class="s1">&#39;xgbclassifier__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
    <span class="s1">&#39;xgbclassifier__learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="s1">&#39;xgbclassifier__subsample&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="s1">&#39;xgbclassifier__colsample_bytree&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="s1">&#39;xgbclassifier__min_child_weight&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># Definir un KFold para validación cruzada</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Búsqueda de hiperparámetros con validación cruzada, maximizando F1 score</span>
<span class="n">grid_search_xgb</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">pipeline_xgb</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Ajustar el modelo</span>
<span class="n">grid_search_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fitting 5 folds for each of 216 candidates, totalling 1080 fits
</pre></div>
</div>
<div class="output text_html"><style>#sk-container-id-23 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-23 {
  color: var(--sklearn-color-text);
}

#sk-container-id-23 pre {
  padding: 0;
}

#sk-container-id-23 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-23 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-23 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-23 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-23 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-23 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-23 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-23 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-23 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-23 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-23 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-23 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-23 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-23 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-23 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-23 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-23 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-23 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-23 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-23 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-23 div.sk-label label.sk-toggleable__label,
#sk-container-id-23 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-23 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-23 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-23 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-23 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-23 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-23 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-23 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-23 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-23 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-23 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-23 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-23" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;xgbclassifier&#x27;,
                                        XGBClassifier(base_score=None,
                                                      booster=None,
                                                      callbacks=None,
                                                      colsample_bylevel=None,
                                                      colsample_bynode=None,
                                                      colsample_bytree=None,
                                                      device=None,
                                                      early_stopping_rounds=None,
                                                      enable_categorical=False,
                                                      eval_metric=None,
                                                      featur...
                                                      n_jobs=None,
                                                      num_parallel_tree=None,
                                                      random_state=None, ...))]),
             n_jobs=-1,
             param_grid={&#x27;xgbclassifier__colsample_bytree&#x27;: [0.8, 1.0],
                         &#x27;xgbclassifier__learning_rate&#x27;: [0.01, 0.1, 0.2],
                         &#x27;xgbclassifier__max_depth&#x27;: [3, 6, 9],
                         &#x27;xgbclassifier__min_child_weight&#x27;: [1, 5],
                         &#x27;xgbclassifier__n_estimators&#x27;: [100, 300, 500],
                         &#x27;xgbclassifier__subsample&#x27;: [0.8, 1.0]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-78" type="checkbox" ><label for="sk-estimator-id-78" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),
             estimator=Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                                       (&#x27;xgbclassifier&#x27;,
                                        XGBClassifier(base_score=None,
                                                      booster=None,
                                                      callbacks=None,
                                                      colsample_bylevel=None,
                                                      colsample_bynode=None,
                                                      colsample_bytree=None,
                                                      device=None,
                                                      early_stopping_rounds=None,
                                                      enable_categorical=False,
                                                      eval_metric=None,
                                                      featur...
                                                      n_jobs=None,
                                                      num_parallel_tree=None,
                                                      random_state=None, ...))]),
             n_jobs=-1,
             param_grid={&#x27;xgbclassifier__colsample_bytree&#x27;: [0.8, 1.0],
                         &#x27;xgbclassifier__learning_rate&#x27;: [0.01, 0.1, 0.2],
                         &#x27;xgbclassifier__max_depth&#x27;: [3, 6, 9],
                         &#x27;xgbclassifier__min_child_weight&#x27;: [1, 5],
                         &#x27;xgbclassifier__n_estimators&#x27;: [100, 300, 500],
                         &#x27;xgbclassifier__subsample&#x27;: [0.8, 1.0]},
             scoring=&#x27;f1&#x27;, verbose=1)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-79" type="checkbox" ><label for="sk-estimator-id-79" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: Pipeline</label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;xgbclassifier&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=0.8, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=0.1,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=3, max_leaves=None, min_child_weight=5,
                               missing=nan, monotone_constraints=None,
                               multi_strategy=None, n_estimators=100,
                               n_jobs=None, num_parallel_tree=None,
                               random_state=None, ...))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-80" type="checkbox" ><label for="sk-estimator-id-80" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-81" type="checkbox" ><label for="sk-estimator-id-81" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">XGBClassifier</label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.8, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.1, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=3, max_leaves=None,
              min_child_weight=5, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=100, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ver mejores parámetros</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mejores parámetros para xgboost:&quot;</span><span class="p">,</span> <span class="n">grid_search_xgb</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores parámetros para xgboost: {&#39;xgbclassifier__colsample_bytree&#39;: 0.8, &#39;xgbclassifier__learning_rate&#39;: 0.1, &#39;xgbclassifier__max_depth&#39;: 3, &#39;xgbclassifier__min_child_weight&#39;: 5, &#39;xgbclassifier__n_estimators&#39;: 100, &#39;xgbclassifier__subsample&#39;: 0.8}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Realicemos el modelo con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo el random forest</span>
<span class="n">modelo_xgb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> 
                           <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">grid_search_xgb</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>

<span class="c1"># Ajusta logreg al conjunto de entrenamiento</span>
<span class="n">modelo_xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-24 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-24 {
  color: var(--sklearn-color-text);
}

#sk-container-id-24 pre {
  padding: 0;
}

#sk-container-id-24 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-24 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-24 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-24 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-24 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-24 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-24 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-24 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-24 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-24 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-24 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-24 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-24 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-24 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-24 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-24 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-24 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-24 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-24 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-24 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-24 div.sk-label label.sk-toggleable__label,
#sk-container-id-24 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-24 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-24 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-24 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-24 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-24 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-24 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-24 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-24 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-24 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-24 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-24 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-24" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;xgbclassifier&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=None,
                               num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-82" type="checkbox" ><label for="sk-estimator-id-82" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;xgbclassifier&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=None, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None, learning_rate=None,
                               max_bin=None, max_cat_threshold=None,
                               max_cat_to_onehot=None, max_delta_step=None,
                               max_depth=None, max_leaves=None,
                               min_child_weight=None, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=None, n_jobs=None,
                               num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-83" type="checkbox" ><label for="sk-estimator-id-83" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-84" type="checkbox" ><label for="sk-estimator-id-84" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">XGBClassifier</label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_xgb</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calcular el reporte de clasificación para el train</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del train:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">55</span><span class="p">)</span>

<span class="c1"># Calcular el reporte de clasificación para el test</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reporte de Clasificación del test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reporte de Clasificación del train:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       315
           1       1.00      1.00      1.00       237

    accuracy                           1.00       552
   macro avg       1.00      1.00      1.00       552
weighted avg       1.00      1.00      1.00       552

-------------------------------------------------------

Reporte de Clasificación del test:
              precision    recall  f1-score   support

           0       0.81      0.82      0.82        68
           1       0.83      0.81      0.82        70

    accuracy                           0.82       138
   macro avg       0.82      0.82      0.82       138
weighted avg       0.82      0.82      0.82       138
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9954dfe5d2ed0b83e7c5e996ac460309e03ce425039c3d8f98984d8d4f1ffee1.png" src="_images/9954dfe5d2ed0b83e7c5e996ac460309e03ce425039c3d8f98984d8d4f1ffee1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/06fbe235fde5e364ba3f44b77171a4dca70c0218706dccc6d6ee89a6e326b0ba.png" src="_images/06fbe235fde5e364ba3f44b77171a4dca70c0218706dccc6d6ee89a6e326b0ba.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora, miremos las variables predictoras más relevantes</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extraer el modelo xgboost del pipeline</span>
<span class="n">modelo_entrenado</span> <span class="o">=</span> <span class="n">modelo_xgb</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;xgbclassifier&#39;</span><span class="p">]</span>

<span class="c1"># Obtener la importancia de los predictores</span>
<span class="n">importancia_predictores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s1">&#39;predictor&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
     <span class="s1">&#39;importancia&#39;</span><span class="p">:</span> <span class="n">modelo_entrenado</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">}</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Importancia de los predictores en el modelo&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">importancia_predictores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importancia&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Importancia de los predictores en el modelo
-------------------------------------------
            predictor  importancia
35     PriorDefault_t     0.444156
37          Citizen_p     0.062643
26       Ethnicity_bb     0.043933
25   EducationLevel_x     0.039725
3         CreditScore     0.038628
20   EducationLevel_k     0.037405
15   EducationLevel_d     0.033335
7           Married_u     0.030049
4              Income     0.028877
29        Ethnicity_h     0.024952
24   EducationLevel_w     0.023237
14  EducationLevel_cc     0.023005
28       Ethnicity_ff     0.022404
12   EducationLevel_b     0.020018
5               Sex_b     0.017481
1                Debt     0.016799
18   EducationLevel_i     0.015585
2       YearsEmployed     0.013144
22   EducationLevel_q     0.012771
0                 Age     0.011147
13   EducationLevel_c     0.011113
8           Married_y     0.010875
38          Citizen_s     0.009381
33        Ethnicity_v     0.009339
23   EducationLevel_r     0.000000
21   EducationLevel_m     0.000000
17  EducationLevel_ff     0.000000
16   EducationLevel_e     0.000000
27       Ethnicity_dd     0.000000
11     BankCustomer_p     0.000000
10    BankCustomer_gg     0.000000
30        Ethnicity_j     0.000000
31        Ethnicity_n     0.000000
32        Ethnicity_o     0.000000
34        Ethnicity_z     0.000000
9      BankCustomer_g     0.000000
36         Employed_t     0.000000
6           Married_l     0.000000
19   EducationLevel_j     0.000000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">cpu_count</span>

<span class="c1"># Importancia de los predictores basada en permutación</span>
<span class="c1"># ==============================================================================</span>
<span class="n">importancia</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">estimator</span>    <span class="o">=</span> <span class="n">modelo_entrenado</span><span class="p">,</span>
                <span class="n">X</span>            <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y</span>            <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                <span class="n">n_repeats</span>    <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                <span class="n">scoring</span>      <span class="o">=</span> <span class="s1">&#39;f1&#39;</span><span class="p">,</span>
                <span class="n">n_jobs</span>       <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">random_state</span> <span class="o">=</span> <span class="mi">123</span>
             <span class="p">)</span>

<span class="c1"># Se almacenan los resultados (media y desviación) en un dataframe</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">importancia</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;importances_std&#39;</span><span class="p">]}</span>
                 <span class="p">)</span>
<span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>importances_mean</th>
      <th>importances_std</th>
      <th>feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35</th>
      <td>0.379737</td>
      <td>0.011214</td>
      <td>PriorDefault_t</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.006551</td>
      <td>0.002672</td>
      <td>Debt</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.004448</td>
      <td>0.001289</td>
      <td>Married_y</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.003751</td>
      <td>0.002654</td>
      <td>Citizen_p</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.002432</td>
      <td>0.000529</td>
      <td>Income</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.001682</td>
      <td>0.002270</td>
      <td>YearsEmployed</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.000956</td>
      <td>0.000781</td>
      <td>EducationLevel_cc</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.000956</td>
      <td>0.000781</td>
      <td>EducationLevel_x</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000705</td>
      <td>0.003639</td>
      <td>CreditScore</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.000300</td>
      <td>0.001057</td>
      <td>Married_u</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Age</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_w</td>
    </tr>
    <tr>
      <th>26</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_bb</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_dd</td>
    </tr>
    <tr>
      <th>34</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_z</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_j</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_n</td>
    </tr>
    <tr>
      <th>32</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_o</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_m</td>
    </tr>
    <tr>
      <th>36</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Employed_t</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_r</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_j</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_c</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_b</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Married_l</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_g</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_gg</td>
    </tr>
    <tr>
      <th>11</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_p</td>
    </tr>
    <tr>
      <th>38</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Citizen_s</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_d</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_e</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_ff</td>
    </tr>
    <tr>
      <th>18</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_i</td>
    </tr>
    <tr>
      <th>28</th>
      <td>-0.000320</td>
      <td>0.000640</td>
      <td>Ethnicity_ff</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.000320</td>
      <td>0.000640</td>
      <td>EducationLevel_q</td>
    </tr>
    <tr>
      <th>29</th>
      <td>-0.000640</td>
      <td>0.000784</td>
      <td>Ethnicity_h</td>
    </tr>
    <tr>
      <th>33</th>
      <td>-0.001280</td>
      <td>0.000640</td>
      <td>Ethnicity_v</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.001600</td>
      <td>0.000000</td>
      <td>EducationLevel_k</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.001823</td>
      <td>0.000273</td>
      <td>Sex_b</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gráfico de la importancia de cada predictor</span>
<span class="c1"># ==============================================================================</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">xerr</span><span class="o">=</span><span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_std&#39;</span><span class="p">],</span>
    <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Importancia de los predictores (train)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Incremento del error tras la permutación&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fa8bb7e54fc1d227068a6d82bcc642cd131d02af06becf5c9274d04c42f71d0e.png" src="_images/fa8bb7e54fc1d227068a6d82bcc642cd131d02af06becf5c9274d04c42f71d0e.png" />
</div>
</div>
<section id="hiperparametros-con-optimizacion-bayesiana">
<h5><strong>Hiperparámetros con optimización bayesiana</strong><a class="headerlink" href="#hiperparametros-con-optimizacion-bayesiana" title="Permalink to this heading">#</a></h5>
<p>La búsqueda <strong>grid search</strong> y <strong>random search</strong> pueden generar buenos resultados, sobre todo cuando se reduce el rango de exploración. Sin embargo, ninguna de ellas tiene en cuenta los resultados obtenidos hasta el momento, lo que les impide centrar la búsqueda en las regiones de mayor interés y evitar las innecesarias.</p>
<p>Una alternativa es utilizar métodos de optimización bayesiana para buscar hiperparámetros. En términos generales, la optimización bayesiana de hiperparámetros consiste en crear un modelo probabilístico en el que la función objetivo es la métrica de validación del modelo (RMSE, AUC, precisión…). Con esta estrategia, la búsqueda se redirige en cada iteración a las regiones de mayor interés. El objetivo final es reducir el número de combinaciones de hiperparámetros con las que se evalúa el modelo, eligiendo sólo los mejores candidatos. Este enfoque es especialmente ventajoso cuando el espacio de búsqueda es muy grande o la evaluación del modelo es muy lenta.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar paquetes necesarios</span>
<span class="kn">import</span> <span class="nn">optuna</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Función objetivo para la optimización</span>
<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="c1"># Definir el modelo de XGBoost</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
        <span class="n">max_depth</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;max_depth&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">min_child_weight</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;min_child_weight&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
        <span class="n">subsample</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;subsample&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="n">colsample_bytree</span><span class="o">=</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;colsample_bytree&#39;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="c1">#gamma=trial.suggest_float(&#39;gamma&#39;, 0, 0.2),</span>
        <span class="c1">#reg_alpha=trial.suggest_float(&#39;reg_alpha&#39;, 0, 0.1),</span>
        <span class="c1">#reg_lambda=trial.suggest_float(&#39;reg_lambda&#39;, 0, 0.1),</span>
        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Validación cruzada y cálculo de la puntuación F1</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">score</span>

<span class="c1"># Crear un estudio de Optuna para la optimización</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;maximize&#39;</span><span class="p">)</span>
<span class="n">study_opm</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Los mejores parámetros son:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mejores hyperparameters:&#39;</span><span class="p">,</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Mejor score:&#39;</span><span class="p">,</span> <span class="n">study</span><span class="o">.</span><span class="n">best_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mejores hyperparameters: {&#39;n_estimators&#39;: 350, &#39;learning_rate&#39;: 0.028173927312081293, &#39;max_depth&#39;: 5, &#39;min_child_weight&#39;: 2, &#39;subsample&#39;: 0.5063010352453581, &#39;colsample_bytree&#39;: 0.9260058948178456}
Mejor score: 0.8612406111083377
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construyamos el modelo con los mejores parámetros</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Definir parámetros para el modelo el xgboost con opt bayesiana</span>
<span class="n">modelo_xgb_opt</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> 
                           <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">))</span>

<span class="c1"># Ajusta xgb al conjunto de entrenamiento</span>
<span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-25 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-25 {
  color: var(--sklearn-color-text);
}

#sk-container-id-25 pre {
  padding: 0;
}

#sk-container-id-25 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-25 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-25 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-25 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-25 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-25 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-25 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-25 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-25 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-25 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-25 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-25 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-25 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-25 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-25 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-25 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-25 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-25 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-25 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-25 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-25 div.sk-label label.sk-toggleable__label,
#sk-container-id-25 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-25 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-25 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-25 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-25 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-25 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-25 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-25 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-25 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-25 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-25 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-25 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-25" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;xgbclassifier&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=0.9260058948178456, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.028173927312081293, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=5,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=350, n_jobs=None,
                               num_parallel_tree=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-85" type="checkbox" ><label for="sk-estimator-id-85" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;Pipeline<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>Pipeline(steps=[(&#x27;minmaxscaler&#x27;, MinMaxScaler()),
                (&#x27;xgbclassifier&#x27;,
                 XGBClassifier(base_score=None, booster=None, callbacks=None,
                               colsample_bylevel=None, colsample_bynode=None,
                               colsample_bytree=0.9260058948178456, device=None,
                               early_stopping_rounds=None,
                               enable_categorical=False, eval_metric=None,
                               feature_types=None, gamma=None, grow_policy=None,
                               importance_type=None,
                               interaction_constraints=None,
                               learning_rate=0.028173927312081293, max_bin=None,
                               max_cat_threshold=None, max_cat_to_onehot=None,
                               max_delta_step=None, max_depth=5,
                               max_leaves=None, min_child_weight=2, missing=nan,
                               monotone_constraints=None, multi_strategy=None,
                               n_estimators=350, n_jobs=None,
                               num_parallel_tree=None, random_state=None, ...))])</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-86" type="checkbox" ><label for="sk-estimator-id-86" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;MinMaxScaler<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html">?<span>Documentation for MinMaxScaler</span></a></label><div class="sk-toggleable__content fitted"><pre>MinMaxScaler()</pre></div> </div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-87" type="checkbox" ><label for="sk-estimator-id-87" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">XGBClassifier</label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=0.9260058948178456, device=None,
              early_stopping_rounds=None, enable_categorical=False,
              eval_metric=None, feature_types=None, gamma=None,
              grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=0.028173927312081293,
              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=5, max_leaves=None,
              min_child_weight=2, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=350, n_jobs=None,
              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div>
</div>
<ul class="simple">
<li><p>Hallemos las métricas</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Predicciones del modelo con el conjunto train</span>
<span class="n">y_pred_train</span> <span class="o">=</span> <span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_prob_train</span> <span class="o">=</span> <span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_train</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>

<span class="c1"># Predicciones del modelo con el conjunto test</span>
<span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_prob_test</span> <span class="o">=</span> <span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Probabilidad de la clase positiva</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el train</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_prob_train</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fc50507354b578c46a66d51408378f2b6a2dbf21b0cfadfc5dae532cffc7ae9d.png" src="_images/fc50507354b578c46a66d51408378f2b6a2dbf21b0cfadfc5dae532cffc7ae9d.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Graficar la curva ROC para el test</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_prob_test</span><span class="p">)</span>
<span class="n">roc_auc</span> <span class="o">=</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;darkorange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Curva ROC (área = </span><span class="si">%0.2f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">roc_auc</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Falsos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Tasa de Verdaderos Positivos&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Curva ROC del conjunto test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;lower right&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/b647fef9a2c723dab020ffe3aeefeb50a1c9db6e620924eeebd2fb853b84f673.png" src="_images/b647fef9a2c723dab020ffe3aeefeb50a1c9db6e620924eeebd2fb853b84f673.png" />
</div>
</div>
<ul class="simple">
<li><p>Aqui, vamos a ver las variables predictoras que más aportan en el modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Extraer el modelo xgboost con opt bayesiana del pipeline</span>
<span class="n">modelo_entrenado</span> <span class="o">=</span> <span class="n">modelo_xgb_opt</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;xgbclassifier&#39;</span><span class="p">]</span>

<span class="c1"># Obtener la importancia de los predictores</span>
<span class="n">importancia_predictores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s1">&#39;predictor&#39;</span><span class="p">:</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
     <span class="s1">&#39;importancia&#39;</span><span class="p">:</span> <span class="n">modelo_entrenado</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">}</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Importancia de los predictores en el modelo&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-------------------------------------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">importancia_predictores</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importancia&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Importancia de los predictores en el modelo
-------------------------------------------
            predictor  importancia
35     PriorDefault_t     0.317247
17  EducationLevel_ff     0.062302
26       Ethnicity_bb     0.045912
18   EducationLevel_i     0.038947
3         CreditScore     0.038788
11     BankCustomer_p     0.036474
14  EducationLevel_cc     0.035048
38          Citizen_s     0.034752
4              Income     0.034074
8           Married_y     0.033092
28       Ethnicity_ff     0.032910
7           Married_u     0.032899
29        Ethnicity_h     0.032461
36         Employed_t     0.029315
1                Debt     0.025746
20   EducationLevel_k     0.025104
22   EducationLevel_q     0.024069
5               Sex_b     0.023581
2       YearsEmployed     0.022922
0                 Age     0.022349
13   EducationLevel_c     0.019168
33        Ethnicity_v     0.017817
24   EducationLevel_w     0.015023
16   EducationLevel_e     0.000000
31        Ethnicity_n     0.000000
37          Citizen_p     0.000000
6           Married_l     0.000000
9      BankCustomer_g     0.000000
34        Ethnicity_z     0.000000
32        Ethnicity_o     0.000000
10    BankCustomer_gg     0.000000
30        Ethnicity_j     0.000000
21   EducationLevel_m     0.000000
12   EducationLevel_b     0.000000
27       Ethnicity_dd     0.000000
25   EducationLevel_x     0.000000
23   EducationLevel_r     0.000000
15   EducationLevel_d     0.000000
19   EducationLevel_j     0.000000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importancia de los predictores basada en permutación</span>
<span class="c1"># ==============================================================================</span>
<span class="n">importancia</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span>
                <span class="n">estimator</span>    <span class="o">=</span> <span class="n">modelo_entrenado</span><span class="p">,</span>
                <span class="n">X</span>            <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                <span class="n">y</span>            <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                <span class="n">n_repeats</span>    <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                <span class="n">scoring</span>      <span class="o">=</span> <span class="s1">&#39;f1&#39;</span><span class="p">,</span>
                <span class="n">n_jobs</span>       <span class="o">=</span> <span class="n">cpu_count</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span>
             <span class="p">)</span>

<span class="c1"># Se almacenan los resultados (media y desviación) en un dataframe</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                    <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">importancia</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="s1">&#39;importances_std&#39;</span><span class="p">]}</span>
                 <span class="p">)</span>
<span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
<span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>importances_mean</th>
      <th>importances_std</th>
      <th>feature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>35</th>
      <td>0.373932</td>
      <td>0.033008</td>
      <td>PriorDefault_t</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.012854</td>
      <td>0.006563</td>
      <td>Debt</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.007986</td>
      <td>0.001644</td>
      <td>Married_y</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.004295</td>
      <td>0.002050</td>
      <td>Married_u</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.004025</td>
      <td>0.004963</td>
      <td>Income</td>
    </tr>
    <tr>
      <th>29</th>
      <td>0.002329</td>
      <td>0.002478</td>
      <td>Ethnicity_h</td>
    </tr>
    <tr>
      <th>24</th>
      <td>0.001624</td>
      <td>0.001026</td>
      <td>EducationLevel_w</td>
    </tr>
    <tr>
      <th>23</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_r</td>
    </tr>
    <tr>
      <th>25</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_x</td>
    </tr>
    <tr>
      <th>27</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_dd</td>
    </tr>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Age</td>
    </tr>
    <tr>
      <th>30</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_j</td>
    </tr>
    <tr>
      <th>31</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_n</td>
    </tr>
    <tr>
      <th>32</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_o</td>
    </tr>
    <tr>
      <th>34</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Ethnicity_z</td>
    </tr>
    <tr>
      <th>37</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Citizen_p</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_m</td>
    </tr>
    <tr>
      <th>19</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_j</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_g</td>
    </tr>
    <tr>
      <th>16</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_e</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_d</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_cc</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>Married_l</td>
    </tr>
    <tr>
      <th>12</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>EducationLevel_b</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>BankCustomer_gg</td>
    </tr>
    <tr>
      <th>11</th>
      <td>-0.000001</td>
      <td>0.001030</td>
      <td>BankCustomer_p</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.000288</td>
      <td>0.005060</td>
      <td>CreditScore</td>
    </tr>
    <tr>
      <th>28</th>
      <td>-0.000326</td>
      <td>0.000653</td>
      <td>Ethnicity_ff</td>
    </tr>
    <tr>
      <th>17</th>
      <td>-0.000326</td>
      <td>0.000653</td>
      <td>EducationLevel_ff</td>
    </tr>
    <tr>
      <th>33</th>
      <td>-0.000557</td>
      <td>0.001471</td>
      <td>Ethnicity_v</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.000653</td>
      <td>0.000799</td>
      <td>EducationLevel_q</td>
    </tr>
    <tr>
      <th>38</th>
      <td>-0.000979</td>
      <td>0.000799</td>
      <td>Citizen_s</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.000979</td>
      <td>0.000799</td>
      <td>EducationLevel_k</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-0.000980</td>
      <td>0.001307</td>
      <td>EducationLevel_c</td>
    </tr>
    <tr>
      <th>26</th>
      <td>-0.001305</td>
      <td>0.000653</td>
      <td>Ethnicity_bb</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-0.001306</td>
      <td>0.001223</td>
      <td>EducationLevel_i</td>
    </tr>
    <tr>
      <th>36</th>
      <td>-0.001328</td>
      <td>0.002410</td>
      <td>Employed_t</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-0.004055</td>
      <td>0.002038</td>
      <td>Sex_b</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.005255</td>
      <td>0.005230</td>
      <td>YearsEmployed</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gráfico de la importancia de cada predictor</span>
<span class="c1"># ==============================================================================</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">3.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">df_importancia</span> <span class="o">=</span> <span class="n">df_importancia</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">xerr</span><span class="o">=</span><span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_std&#39;</span><span class="p">],</span>
    <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;importances_mean&#39;</span><span class="p">],</span>
    <span class="n">df_importancia</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">],</span>
    <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;D&quot;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Importancia de los predictores (train)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Incremento del error tras la permutación&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c9dc4aa637d447df775f3da2748e07051d6a07f52f228f36049b005263c87588.png" src="_images/c9dc4aa637d447df775f3da2748e07051d6a07f52f228f36049b005263c87588.png" />
</div>
</div>
</section>
</section>
<section id="id6">
<h4><strong>Análisis completo de los modelos</strong><a class="headerlink" href="#id6" title="Permalink to this heading">#</a></h4>
<p>En esta sección se realizará un análisis completo para escoger el mejor modelo.</p>
<ul class="simple">
<li><p>Carguemos las librerias</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importar </span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">GridSearchCV</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>ETL</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Cargar el conjunto de datos</span>
<span class="n">cc_apps</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;C:/Users/cdeor/OneDrive/Documentos/MachineLearningDipSerfinanzas/jbook_ml202430/docs/_data/dataml/cc_approvals.data&quot;</span><span class="p">,</span><span class="n">header</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># Inspeccionar los datos</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">cc_apps</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">5</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b</td>
      <td>30.83</td>
      <td>0.000</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.25</td>
      <td>t</td>
      <td>t</td>
      <td>1</td>
      <td>f</td>
      <td>g</td>
      <td>00202</td>
      <td>0</td>
      <td>+</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a</td>
      <td>58.67</td>
      <td>4.460</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>3.04</td>
      <td>t</td>
      <td>t</td>
      <td>6</td>
      <td>f</td>
      <td>g</td>
      <td>00043</td>
      <td>560</td>
      <td>+</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a</td>
      <td>24.50</td>
      <td>0.500</td>
      <td>u</td>
      <td>g</td>
      <td>q</td>
      <td>h</td>
      <td>1.50</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00280</td>
      <td>824</td>
      <td>+</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b</td>
      <td>27.83</td>
      <td>1.540</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>3.75</td>
      <td>t</td>
      <td>t</td>
      <td>5</td>
      <td>t</td>
      <td>g</td>
      <td>00100</td>
      <td>3</td>
      <td>+</td>
    </tr>
    <tr>
      <th>4</th>
      <td>b</td>
      <td>20.17</td>
      <td>5.625</td>
      <td>u</td>
      <td>g</td>
      <td>w</td>
      <td>v</td>
      <td>1.71</td>
      <td>t</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>s</td>
      <td>00120</td>
      <td>0</td>
      <td>+</td>
    </tr>
    <tr>
      <th>685</th>
      <td>b</td>
      <td>21.08</td>
      <td>10.085</td>
      <td>y</td>
      <td>p</td>
      <td>e</td>
      <td>h</td>
      <td>1.25</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00260</td>
      <td>0</td>
      <td>-</td>
    </tr>
    <tr>
      <th>686</th>
      <td>a</td>
      <td>22.67</td>
      <td>0.750</td>
      <td>u</td>
      <td>g</td>
      <td>c</td>
      <td>v</td>
      <td>2.00</td>
      <td>f</td>
      <td>t</td>
      <td>2</td>
      <td>t</td>
      <td>g</td>
      <td>00200</td>
      <td>394</td>
      <td>-</td>
    </tr>
    <tr>
      <th>687</th>
      <td>a</td>
      <td>25.25</td>
      <td>13.500</td>
      <td>y</td>
      <td>p</td>
      <td>ff</td>
      <td>ff</td>
      <td>2.00</td>
      <td>f</td>
      <td>t</td>
      <td>1</td>
      <td>t</td>
      <td>g</td>
      <td>00200</td>
      <td>1</td>
      <td>-</td>
    </tr>
    <tr>
      <th>688</th>
      <td>b</td>
      <td>17.92</td>
      <td>0.205</td>
      <td>u</td>
      <td>g</td>
      <td>aa</td>
      <td>v</td>
      <td>0.04</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>f</td>
      <td>g</td>
      <td>00280</td>
      <td>750</td>
      <td>-</td>
    </tr>
    <tr>
      <th>689</th>
      <td>b</td>
      <td>35.00</td>
      <td>3.375</td>
      <td>u</td>
      <td>g</td>
      <td>c</td>
      <td>h</td>
      <td>8.29</td>
      <td>f</td>
      <td>f</td>
      <td>0</td>
      <td>t</td>
      <td>g</td>
      <td>00000</td>
      <td>0</td>
      <td>-</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># nombres de las columnas</span>
<span class="n">cc_apps</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Debt&#39;</span><span class="p">,</span><span class="s1">&#39;Married&#39;</span><span class="p">,</span><span class="s1">&#39;BankCustomer&#39;</span><span class="p">,</span><span class="s1">&#39;EducationLevel&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;Ethnicity&#39;</span><span class="p">,</span><span class="s1">&#39;YearsEmployed&#39;</span><span class="p">,</span><span class="s1">&#39;PriorDefault&#39;</span><span class="p">,</span><span class="s1">&#39;Employed&#39;</span><span class="p">,</span><span class="s1">&#39;CreditScore&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;DriversLicense&#39;</span><span class="p">,</span><span class="s1">&#39;Citizen&#39;</span><span class="p">,</span><span class="s1">&#39;ZipCode&#39;</span><span class="p">,</span><span class="s1">&#39;Income&#39;</span><span class="p">,</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span>

<span class="c1"># Replazar los &#39;?&#39;s con NaN en los conjuntos de datos</span>
<span class="n">cc_apps_2</span> <span class="o">=</span> <span class="n">cc_apps</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;?&#39;</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">)</span>

<span class="c1"># Cambiar la variable Age que esta en objeto por float</span>
<span class="n">cc_apps_2</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>

<span class="c1"># Eliminar las variables 11 y 13</span>
<span class="n">cc_apps_3</span> <span class="o">=</span> <span class="n">cc_apps_2</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;DriversLicense&#39;</span><span class="p">,</span> <span class="s1">&#39;ZipCode&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Imputar los valores perdidos con imputación de medias para variables numéricas</span>
<span class="n">cc_apps_3</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Imputación de datos para variables categóricas</span>

<span class="c1"># Iterar sobre cada columna de cc_apps_3</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cc_apps_3</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="c1"># Comprobar si la columna es de tipo objeto</span>
    <span class="k">if</span> <span class="n">cc_apps_3</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span> <span class="o">==</span> <span class="s1">&#39;object&#39;</span><span class="p">:</span>
        <span class="n">cc_apps_3</span> <span class="o">=</span> <span class="n">cc_apps_3</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
<span class="c1"># Supongamos que tu variable está en una columna llamada &#39;variable&#39;</span>
<span class="c1"># + indica aprobado es 1</span>
<span class="c1"># - indica no aprobado es 0</span>
<span class="n">cc_apps_3</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cc_apps_3</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s1">&#39;+&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Separemos el dataset en el conjunto de entrenamiento y prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convertir las variables categóricas en variables dummy</span>
<span class="n">df_dummies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">cc_apps_3</span><span class="p">,</span>
               <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">,</span><span class="s1">&#39;Married&#39;</span><span class="p">,</span><span class="s1">&#39;BankCustomer&#39;</span><span class="p">,</span><span class="s1">&#39;EducationLevel&#39;</span><span class="p">,</span><span class="s1">&#39;Ethnicity&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;PriorDefault&#39;</span><span class="p">,</span><span class="s1">&#39;Employed&#39;</span><span class="p">,</span><span class="s1">&#39;Citizen&#39;</span><span class="p">],</span>
               <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Separar características y objetivo</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_dummies</span><span class="p">[</span><span class="s1">&#39;Approved&#39;</span><span class="p">]</span>

<span class="c1"># Dividir en conjuntos de entrenamiento (80%) y prueba (20%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Hagamos los modelos con los mejores parámetros:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pipeline reg logistica </span>
<span class="n">modelo_reglog_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                   <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                                      <span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l1&#39;</span><span class="p">,</span><span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">))</span>

<span class="c1"># Pipeline knn</span>
<span class="n">modelo_knn_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">leaf_size</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;manhattan&#39;</span><span class="p">,</span>
                                                     <span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span> <span class="s1">&#39;distance&#39;</span><span class="p">))</span>

<span class="c1"># Pipeline naive-bayes </span>
<span class="n">modelo_nb_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                               <span class="n">GaussianNB</span><span class="p">(</span><span class="n">var_smoothing</span> <span class="o">=</span> <span class="mf">1e-06</span><span class="p">))</span>

<span class="c1"># Pipeline de SVC con kernel lineal</span>
<span class="n">modelo_svclineal_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                      <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span><span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span><span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>


<span class="c1"># Pipeline arbol de decision</span>
<span class="n">modelo_tree_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                 <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">ccp_alpha</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
                                                        <span class="n">max_features</span> <span class="o">=</span> <span class="s1">&#39;log2&#39;</span><span class="p">,</span><span class="n">min_impurity_decrease</span> <span class="o">=</span>  <span class="mf">0.0</span><span class="p">,</span>
                                                        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                                                        <span class="n">splitter</span><span class="o">=</span> <span class="s1">&#39;random&#39;</span><span class="p">))</span>

<span class="c1"># Pipeline random forest</span>
<span class="n">modelo_rf_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                               <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">bootstrap</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                                      <span class="n">max_features</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">7</span><span class="p">,</span>
                                                      <span class="n">min_samples_split</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">))</span>

<span class="c1"># Pipeline XGBoost</span>
<span class="n">modelo_xgb_plot</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
                                <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> 
                                              <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">d_weight</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
                                              <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Chequeo de algoritmos</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;Reg. Log.&#39;</span><span class="p">,</span> <span class="n">modelo_reglog_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;KNN&#39;</span><span class="p">,</span> <span class="n">modelo_knn_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;Naive-Bayes&#39;</span><span class="p">,</span> <span class="n">modelo_nb_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;SVC-Linear&#39;</span><span class="p">,</span> <span class="n">modelo_svclineal_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;Arb. de Decisión&#39;</span><span class="p">,</span> <span class="n">modelo_tree_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="n">modelo_rf_plot</span><span class="p">))</span>
<span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="s1">&#39;XGBoost&#39;</span><span class="p">,</span> <span class="n">modelo_xgb_plot</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#ok</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1">#n_jobs = -1 es para que el codigo se ejecute mas rapido</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cv_results</span><span class="p">)</span>
    <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">cv_results</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">,.3f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">cv_results</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">,.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reg. Log.: 0.852 (0.042)
KNN: 0.850 (0.082)
Naive-Bayes: 0.716 (0.074)
SVC-Linear: 0.855 (0.047)
Arb. de Decisión: 0.795 (0.062)
Random Forest: 0.824 (0.053)
XGBoost: 0.827 (0.067)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare Algorithms</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Algorithm Comparison&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">names</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3b14ca808981b8b86444fee2c1ec96215ec7d63c3d98f90c05be5422dc4e12a4.png" src="_images/3b14ca808981b8b86444fee2c1ec96215ec7d63c3d98f90c05be5422dc4e12a4.png" />
</div>
</div>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="modulo_5.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Modulo 5: Introducción a Streamlit</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="modulo_7.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Modulo 7: Despliegue de modelos</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arthur-samuel-pionero-del-aprendizaje-automatico-y-la-inteligencia-artificial"><strong>Arthur Samuel: Pionero del Aprendizaje Automático y la Inteligencia Artificial</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste"><strong>Generalización, sobreajuste y subajuste</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion"><strong>Regresión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-regresion"><strong>Tipos de regresión</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-regresion-lineal"><strong>Modelo de regresión lineal</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-simple"><strong>Regresión lineal simple</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#importemos-las-librerias">1. <strong>Importemos las librerias</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#carguemos-los-datos">2. <strong>Carguemos los datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#eda">3. <strong>EDA</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#datos-faltantes-o-nans">4. <strong>Datos faltantes o NANs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-de-datos">5. <strong>Visualización de datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo">6. <strong>Construcción del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-conjunto-de-entrenamiento-y-prueba">7. <strong>Visualización del conjunto de entrenamiento y prueba</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-del-modelo-de-regresion"><strong>Métricas de evaluacion del modelo de regresión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-medio-mse-mean-squared-error">1. <strong>Error Cuadrático Medio (<span class="math notranslate nohighlight">\(MSE\)</span> - Mean Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-mse"><strong>Interpretación de MSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mse"><strong>Conclusiones de MSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-absoluto-medio-mae-mean-absolute-error">2. <strong>Error Absoluto Medio (<span class="math notranslate nohighlight">\(MAE\)</span> - Mean Absolute Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-mae"><strong>Interpretación de MAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mae"><strong>Conclusiones de MAE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#raiz-del-error-cuadratico-medio-rmse-root-mean-squared-error">3. <strong>Raíz del Error Cuadrático Medio (<span class="math notranslate nohighlight">\(RMSE\)</span> - Root Mean Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rmse"><strong>Interpretación de RMSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rmse"><strong>Conclusiones de RMSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rmse"><strong>Resumen de RMSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#coeficiente-de-determinacion-r-2-r-squared">4. <strong>Coeficiente de Determinación (<span class="math notranslate nohighlight">\(R^2\)</span> - <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-r-2"><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-r-2"><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-si-es-necesario-de-r-2"><strong>Posibles acciones para mejorar (si es necesario) de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-r-2"><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span></strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#r-2-ajustado-adjusted-r-squared">5. <strong><span class="math notranslate nohighlight">\(R^2\)</span> Ajustado (Adjusted <span class="math notranslate nohighlight">\(R\)</span>-squared)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-r-2-ajustado"><strong>Interpretación de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-r-2-ajustado"><strong>Conclusiones de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-r-2-ajustado"><strong>Posibles acciones para mejorar <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-r-2-ajustado"><strong>Resumen de <span class="math notranslate nohighlight">\(R^2\)</span> ajustado</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-medio-proporcional-absoluto-mape-mean-absolute-percentage-error">6. <strong>Error Medio Proporcional Absoluto (<span class="math notranslate nohighlight">\(MAPE\)</span> - Mean Absolute Percentage Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-del-mape"><strong>Interpretación del MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-mape"><strong>Conclusiones de MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-si-es-necesario-de-mape"><strong>Posibles acciones para mejorar (si es necesario) de MAPE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-mape"><strong>Resumen de MAPE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-medio-de-logaritmo-msle-mean-squared-logarithmic-error">7. <strong>Error Cuadrático Medio de Logaritmo (<span class="math notranslate nohighlight">\(MSLE\)</span> - Mean Squared Logarithmic Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-msle"><strong>Interpretación de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-msle"><strong>Conclusiones de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-msle"><strong>Posibles acciones para mejorar de MSLE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-msle"><strong>Resumen de MSLE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-relativo-absoluto-rae-relative-absolute-error">8. <strong>Error Relativo Absoluto (<span class="math notranslate nohighlight">\(RAE\)</span> - Relative Absolute Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rae"><strong>Interpretación de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rae"><strong>Conclusiones de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-rae"><strong>Posibles acciones para mejorar de RAE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rae"><strong>Resumen de RAE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#error-cuadratico-relativo-rse-relative-squared-error">9. <strong>Error Cuadrático Relativo (<span class="math notranslate nohighlight">\(RSE\)</span> - Relative Squared Error)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretacion-de-rse"><strong>Interpretación de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusiones-de-rse"><strong>Conclusiones de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#posibles-acciones-para-mejorar-de-rse"><strong>Posibles acciones para mejorar de RSE</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-de-rse"><strong>Resumen de RSE</strong>:</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-con-la-libreria-statsmodels"><strong>Regresión Lineal con la librería Statsmodels</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#formas-de-entrenar-un-modelo-de-regresion-en-statsmodels"><strong>Formas de entrenar un modelo de regresión en Statsmodels</strong>:</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#resultados-de-la-regresion-lineal-ols"><strong>Resultados de la Regresión Lineal (OLS)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-con-scikit-learn"><strong>Comparación con Scikit-learn</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusión</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lineal-multiple"><strong>Regresión lineal multiple</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-las-librerias-necesarias">1. <strong>Importar las librerías necesarias</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#lectura-de-los-datos">2. <strong>Lectura de los datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">3. <strong>Datos faltantes o NANs</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen-estadistico">4. <strong>Resumen estadístico.</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizacion-del-conjunto-de-datos">5. <strong>Visualización del conjunto de datos</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#correlaciones">6. <strong>Correlaciones</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-regresion">7. <strong>Construcción del modelo de regresión</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-ridge"><strong>Regresión Ridge</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-rigde"><strong>Construcción del modelo Rigde</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-lasso"><strong>Regresión Lasso</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-lasso"><strong>Construcción del modelo Lasso</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-por-k-vecinos"><strong>Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-knn-regression"><strong>¿Cómo funciona KNN Regression?</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#consideraciones-al-usar-knn-regression"><strong>Consideraciones al usar KNN Regression</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-knn"><strong>Construcción del modelo KNN</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-con-support-vector-machine-svr"><strong>Regresión con Support Vector Machine (SVR)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#como-funciona-la-svr"><strong>¿Cómo funciona la SVR?</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#funcion-de-decision"><strong>Función de Decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-del-nucleo"><strong>Definición del Núcleo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-de-un-modelo-de-svr"><strong>Construcción de un Modelo de SVR</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#resumen"><strong>Resumen</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-svr"><strong>Construcción del modelo de SVR</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluacion-de-los-modelos"><strong>Evaluación de los módelos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#validacion-cruzada-cross-validation"><strong>Validación cruzada (Cross-Validation)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-validacion-cruzada"><strong>Tipos de validación cruzada</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#concepto-de-grid-search-busqueda-de-grilla"><strong>Concepto de Grid Search (busqueda de grilla)</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-regresion-que-pueden-usar-grid-search-para-hiperparametrizacion"><strong>Modelos de Regresión que pueden usar Grid Search para hiperparametrización</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grid-search-con-validacion-cruzada"><strong>Grid Search con validación cruzada</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#analisis-completo-de-los-modelos"><strong>Análisis completo de los modelos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-rigde"><strong>Modelo Rigde</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-lasso"><strong>Modelo Lasso</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-k-vecinos"><strong>Modelo por <span class="math notranslate nohighlight">\(k\)</span>-vecinos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-lineal"><strong>Modelo por SVR con kernel lineal</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-polinomial"><strong>Modelo por SVR con kernel polinomial</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-por-svr-con-kernel-rbf"><strong>Modelo por SVR con kernel RBF</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#comparacion-de-rendimiento-de-modelos"><strong>Comparación de rendimiento de modelos</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clasificacion"><strong>Clasificación</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tipos-de-modelos-de-clasificacion"><strong>Tipos de Modelos de Clasificación</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regresion-logistica"><strong>Regresión logística</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-claves"><strong>Características claves</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-de-la-regresion-logistica"><strong>Idea de la regresión logística</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-clasificacion-usando-regresion-logistica-de-entrega-o-no-de-tarjetas-de-creditos"><strong>Modelo de clasificación usando regresión logística de entrega o no de tarjetas de créditos</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#importar-las-librerias">1. <strong>Importar las librerias</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">2. <strong>Lectura de los datos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#datos-faltantes-o-atipicos">3. <strong>Datos faltantes o atípicos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#etl-conjunto-de-entrenamiento-y-prueba"><strong>4. ETL, conjunto de entrenamiento y prueba</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocesamiento-de-los-datos">5. <strong>Preprocesamiento de los datos</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">6. <strong>Construcción del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-de-un-modelo"><strong>Métricas de evaluación de un modelo</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#matriz-de-confunsion"><strong>Matriz de confunsión</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#exactitud-accuracy"><strong>Exactitud (Accuracy)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-precision"><strong>Precisión (Precision)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#recall-sensibilidad"><strong>Recall (Sensibilidad)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#especificidad-specificity"><strong>Especificidad (Specificity)</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score"><strong>F1-Score</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#curva-roc-y-auc-roc"><strong>Curva ROC y AUC-ROC</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-evaluacion-del-modelo-de-regresion-logistica"><strong>Metricas de evaluación del modelo de regresión logística</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-clasificacion-de-knn"><strong>Modelo de clasificación de KNN</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas"><strong>Características</strong>:</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#metricas-de-distancia"><strong>Métricas de distancia</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-knn"><strong>Idea del KNN</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-knn-con-sus-metricas"><strong>Construcción del modelo de KNN con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-maquina-de-soporte-vectorial"><strong>Modelo de Máquina de Soporte Vectorial</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-de-los-modelos-svm"><strong>Características de los Modelos SVM</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-de-maquina-de-soporte-vectorial"><strong>Idea de maquina de soporte vectorial</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-kernel-de-maquina-de-soporte-vectorial"><strong>Idea del kernel de maquina de soporte vectorial</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-svm-con-sus-metricas"><strong>Construcción del modelo de SVM con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-naives-bayes"><strong>Modelo de Naives-Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-la-regla-de-bayes"><strong>Definición de la Regla de Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplo-de-la-regla-de-bayes"><strong>Ejemplo de la regla de Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#clasificador-naive-bayes"><strong>Clasificador Naive Bayes</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modelos-de-naive-bayes-para-clasificacion"><strong>Modelos de Naive Bayes para clasificación</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4"><strong>Construcción del modelo</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-arbol-de-decision"><strong>Modelo de arbol de decisión</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#componentes-de-un-arbol-de-decision"><strong>Componentes de un árbol de decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-arbol"><strong>Construcción del arbol</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#idea-del-arbol-de-decision"><strong>Idea del arbol de decisión</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-arbol-de-decision-con-sus-metricas"><strong>Construcción del modelo de arbol de decisión con sus métricas</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-random-forest"><strong>Modelo Random Forest</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#caracteristicas-del-modelo"><strong>Características del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-de-random-forest"><strong>Construcción del modelo de Random Forest</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modelo-de-xgboost"><strong>Modelo de XGBoost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#definicion-de-xgboost"><strong>Definición de XGboost</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#formula-matematica"><strong>Fórmula matemática</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5"><strong>Características del modelo</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#construccion-del-modelo-xgboost-con-sus-metricas"><strong>Construcción del modelo XGboost con sus métricas</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros-con-optimizacion-bayesiana"><strong>Hiperparámetros con optimización bayesiana</strong></a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6"><strong>Análisis completo de los modelos</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Centro de Estudios e Investigación en Análisis y Ciencia de datos - Data Invest -
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>